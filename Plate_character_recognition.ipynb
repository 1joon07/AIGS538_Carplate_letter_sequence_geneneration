{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, CenterCrop, Grayscale\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dataset as data\n",
    "import model as md\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "Batch_size = 128\n",
    "Optimizer_type = 'ADAM'\n",
    "Learning_rate = 1e-4\n",
    "Weight_decay = 0\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Sample_visualize(dataloader) :\n",
    "  ## Visualize some preprocess images\n",
    "  ##\n",
    "  ## Input : dataloader of image dataset\n",
    "  ## Output : image plots\n",
    "\n",
    " dataiter = iter(dataloader)\n",
    " images, labels = next(dataiter)\n",
    " # images = images.numpy()\n",
    " for i in range (2) :\n",
    "   plt.subplot(1,4,i+1)\n",
    "   plt.imshow(images[i].reshape((64, 64)), cmap='gray')\n",
    "   plt.xticks([])\n",
    "   plt.yticks([])\n",
    "   print(labels[i])\n",
    "\n",
    "# def visualize_dataset(dataset):\n",
    "#   ## Visualize some preprocess images\n",
    "#   ##\n",
    "#   ## Input : DATASET of image dataset\n",
    "#   ## Output : image plots\n",
    "#   images, labels = dataset[0]\n",
    "#   print(images.size())\n",
    "#   images = images.numpy()\n",
    "#   plt.imshow(images.reshape((64, 192)), cmap='gray')\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])\n",
    "#   print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform_set = Compose([Resize((64, 64)),\n",
    "                Grayscale(),\n",
    "                ToTensor(),\n",
    "                Normalize((0.5), (0.5))])\n",
    "train_data = datasets.ImageFolder(root = \"./CNN_letter_dataset\", transform=transform_set)\n",
    "val_data = datasets.ImageFolder(root = \"./CNN_letter_dataset_val\", transform=transform_set)\n",
    "test_data = datasets.ImageFolder(root = \"./CNN_letter_dataset_test\", transform=transform_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=Batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=Batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=Batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(17)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize_dataset(full_dataset)\n",
    "Sample_visualize(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 48, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(48, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=9216, out_features=100, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=100, out_features=6, bias=True)\n",
      "    (16): ReLU()\n",
      "  )\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (output0): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=36, bias=True)\n",
      "    (5): Softmax(dim=1)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = md.CNN(init_weights=True)\n",
    "model.to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import torchsummary\n",
    "#\n",
    "# torchsummary.summary(model,input_size=(1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m Optimizer_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mADAM\u001b[39m\u001b[39m'\u001b[39m :\n\u001b[0;32m----> 4\u001b[0m   optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m Learning_rate, weight_decay \u001b[39m=\u001b[39m Weight_decay)\n\u001b[1;32m      5\u001b[0m \u001b[39melif\u001b[39;00m Optimizer_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSGD\u001b[39m\u001b[39m'\u001b[39m :\n\u001b[1;32m      6\u001b[0m   optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m Learning_rate, weight_decay \u001b[39m=\u001b[39m Weight_decay)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "if Optimizer_type == 'ADAM' :\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)\n",
    "elif Optimizer_type == 'SGD' :\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Training function ##\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  for batch_idx, (X,y) in enumerate(dataloader):\n",
    "\n",
    "    X = X.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 10 == 0:\n",
    "      print('loss: {:.6f} [{}/{}]'.format(loss.item(), batch_idx*len(X), len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Validation function ##\n",
    "def validation(model, valdata):\n",
    "  ## Input : trained model, validation data\n",
    "  ## Output : validation loss\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in valdata:\n",
    "      X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "      output = model(X)\n",
    "      val_loss += nn.functional.cross_entropy(output, y, reduction='sum').item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "  val_loss /= len(valdata.dataset)\n",
    "  print('\\n***Validation Result***\\nAverage loss: {:.6f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(val_loss, correct, len(valdata.dataset), 100*correct/len(valdata.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(model, testdata):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in testdata:\n",
    "      X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "      output = model(X)\n",
    "      test_loss += nn.functional.cross_entropy(output, y, reduction='sum').item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "  test_loss /= len(testdata.dataset)\n",
    "  print('\\n***Test Result***\\nAverage loss: {:.6f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(test_loss, correct, len(testdata.dataset), 100*correct/len(testdata.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1]\n",
      "loss: 3.583456 [0/28137]\n",
      "loss: 3.581937 [1280/28137]\n",
      "loss: 3.580296 [2560/28137]\n",
      "loss: 3.574789 [3840/28137]\n",
      "loss: 3.553074 [5120/28137]\n",
      "loss: 3.561317 [6400/28137]\n",
      "loss: 3.517924 [7680/28137]\n",
      "loss: 3.422583 [8960/28137]\n",
      "loss: 3.406873 [10240/28137]\n",
      "loss: 3.357132 [11520/28137]\n",
      "loss: 3.309019 [12800/28137]\n",
      "loss: 3.231928 [14080/28137]\n",
      "loss: 3.204044 [15360/28137]\n",
      "loss: 3.125409 [16640/28137]\n",
      "loss: 3.054138 [17920/28137]\n",
      "loss: 3.056072 [19200/28137]\n",
      "loss: 2.988724 [20480/28137]\n",
      "loss: 2.952680 [21760/28137]\n",
      "loss: 3.022579 [23040/28137]\n",
      "loss: 2.960729 [24320/28137]\n",
      "loss: 2.986450 [25600/28137]\n",
      "loss: 2.976393 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.950520, Accuracy: 2608/3725 (70.0%)\n",
      "\n",
      "\n",
      "[Epoch 2]\n",
      "loss: 3.019421 [0/28137]\n",
      "loss: 2.954722 [1280/28137]\n",
      "loss: 2.884555 [2560/28137]\n",
      "loss: 3.030730 [3840/28137]\n",
      "loss: 2.958452 [5120/28137]\n",
      "loss: 2.920346 [6400/28137]\n",
      "loss: 2.900079 [7680/28137]\n",
      "loss: 2.919972 [8960/28137]\n",
      "loss: 2.912784 [10240/28137]\n",
      "loss: 2.932488 [11520/28137]\n",
      "loss: 2.886800 [12800/28137]\n",
      "loss: 2.814093 [14080/28137]\n",
      "loss: 2.865043 [15360/28137]\n",
      "loss: 2.850131 [16640/28137]\n",
      "loss: 2.893934 [17920/28137]\n",
      "loss: 2.944741 [19200/28137]\n",
      "loss: 2.967465 [20480/28137]\n",
      "loss: 2.884052 [21760/28137]\n",
      "loss: 2.867746 [23040/28137]\n",
      "loss: 2.966356 [24320/28137]\n",
      "loss: 2.846508 [25600/28137]\n",
      "loss: 2.853329 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.888695, Accuracy: 2771/3725 (74.4%)\n",
      "\n",
      "\n",
      "[Epoch 3]\n",
      "loss: 2.903482 [0/28137]\n",
      "loss: 2.820941 [1280/28137]\n",
      "loss: 2.906704 [2560/28137]\n",
      "loss: 2.897191 [3840/28137]\n",
      "loss: 2.869168 [5120/28137]\n",
      "loss: 2.880783 [6400/28137]\n",
      "loss: 2.899401 [7680/28137]\n",
      "loss: 2.840990 [8960/28137]\n",
      "loss: 2.899153 [10240/28137]\n",
      "loss: 2.851241 [11520/28137]\n",
      "loss: 2.813651 [12800/28137]\n",
      "loss: 2.860834 [14080/28137]\n",
      "loss: 2.848791 [15360/28137]\n",
      "loss: 2.857989 [16640/28137]\n",
      "loss: 2.837467 [17920/28137]\n",
      "loss: 2.850530 [19200/28137]\n",
      "loss: 2.880674 [20480/28137]\n",
      "loss: 2.912458 [21760/28137]\n",
      "loss: 2.857944 [23040/28137]\n",
      "loss: 2.857522 [24320/28137]\n",
      "loss: 2.843245 [25600/28137]\n",
      "loss: 2.900459 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.861823, Accuracy: 2876/3725 (77.2%)\n",
      "\n",
      "\n",
      "[Epoch 4]\n",
      "loss: 2.865678 [0/28137]\n",
      "loss: 2.804760 [1280/28137]\n",
      "loss: 2.909314 [2560/28137]\n",
      "loss: 2.888559 [3840/28137]\n",
      "loss: 2.816385 [5120/28137]\n",
      "loss: 2.898830 [6400/28137]\n",
      "loss: 2.888501 [7680/28137]\n",
      "loss: 2.902429 [8960/28137]\n",
      "loss: 2.969570 [10240/28137]\n",
      "loss: 2.908548 [11520/28137]\n",
      "loss: 2.862315 [12800/28137]\n",
      "loss: 2.922379 [14080/28137]\n",
      "loss: 2.846122 [15360/28137]\n",
      "loss: 2.828088 [16640/28137]\n",
      "loss: 2.823675 [17920/28137]\n",
      "loss: 2.863627 [19200/28137]\n",
      "loss: 2.814215 [20480/28137]\n",
      "loss: 2.833409 [21760/28137]\n",
      "loss: 2.842393 [23040/28137]\n",
      "loss: 2.876488 [24320/28137]\n",
      "loss: 2.927988 [25600/28137]\n",
      "loss: 2.907780 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.855715, Accuracy: 2890/3725 (77.6%)\n",
      "\n",
      "\n",
      "[Epoch 5]\n",
      "loss: 2.867235 [0/28137]\n",
      "loss: 2.887210 [1280/28137]\n",
      "loss: 2.818027 [2560/28137]\n",
      "loss: 2.826123 [3840/28137]\n",
      "loss: 2.904341 [5120/28137]\n",
      "loss: 2.840413 [6400/28137]\n",
      "loss: 2.832671 [7680/28137]\n",
      "loss: 2.835662 [8960/28137]\n",
      "loss: 2.864237 [10240/28137]\n",
      "loss: 2.864661 [11520/28137]\n",
      "loss: 2.888954 [12800/28137]\n",
      "loss: 2.896357 [14080/28137]\n",
      "loss: 2.816955 [15360/28137]\n",
      "loss: 2.856391 [16640/28137]\n",
      "loss: 2.803767 [17920/28137]\n",
      "loss: 2.796595 [19200/28137]\n",
      "loss: 2.949944 [20480/28137]\n",
      "loss: 2.848594 [21760/28137]\n",
      "loss: 2.865152 [23040/28137]\n",
      "loss: 2.903319 [24320/28137]\n",
      "loss: 2.832639 [25600/28137]\n",
      "loss: 2.832716 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.852176, Accuracy: 2897/3725 (77.8%)\n",
      "\n",
      "\n",
      "[Epoch 6]\n",
      "loss: 2.848246 [0/28137]\n",
      "loss: 2.833201 [1280/28137]\n",
      "loss: 2.903107 [2560/28137]\n",
      "loss: 2.888056 [3840/28137]\n",
      "loss: 2.928719 [5120/28137]\n",
      "loss: 2.809724 [6400/28137]\n",
      "loss: 2.827636 [7680/28137]\n",
      "loss: 2.864009 [8960/28137]\n",
      "loss: 2.801461 [10240/28137]\n",
      "loss: 2.887007 [11520/28137]\n",
      "loss: 2.801817 [12800/28137]\n",
      "loss: 2.840854 [14080/28137]\n",
      "loss: 2.886908 [15360/28137]\n",
      "loss: 2.849449 [16640/28137]\n",
      "loss: 2.804399 [17920/28137]\n",
      "loss: 2.888039 [19200/28137]\n",
      "loss: 2.834988 [20480/28137]\n",
      "loss: 2.860116 [21760/28137]\n",
      "loss: 2.840300 [23040/28137]\n",
      "loss: 2.856735 [24320/28137]\n",
      "loss: 2.840308 [25600/28137]\n",
      "loss: 2.864893 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.852273, Accuracy: 2898/3725 (77.8%)\n",
      "\n",
      "\n",
      "[Epoch 7]\n",
      "loss: 2.840403 [0/28137]\n",
      "loss: 2.825103 [1280/28137]\n",
      "loss: 2.895182 [2560/28137]\n",
      "loss: 2.927735 [3840/28137]\n",
      "loss: 2.933813 [5120/28137]\n",
      "loss: 2.816651 [6400/28137]\n",
      "loss: 2.827375 [7680/28137]\n",
      "loss: 2.914317 [8960/28137]\n",
      "loss: 2.871436 [10240/28137]\n",
      "loss: 2.840450 [11520/28137]\n",
      "loss: 2.863686 [12800/28137]\n",
      "loss: 2.915060 [14080/28137]\n",
      "loss: 2.824672 [15360/28137]\n",
      "loss: 2.844927 [16640/28137]\n",
      "loss: 2.880044 [17920/28137]\n",
      "loss: 2.840256 [19200/28137]\n",
      "loss: 2.880329 [20480/28137]\n",
      "loss: 2.838191 [21760/28137]\n",
      "loss: 2.840268 [23040/28137]\n",
      "loss: 2.925722 [24320/28137]\n",
      "loss: 2.871476 [25600/28137]\n",
      "loss: 2.918139 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.850711, Accuracy: 2903/3725 (77.9%)\n",
      "\n",
      "\n",
      "[Epoch 8]\n",
      "loss: 2.903506 [0/28137]\n",
      "loss: 2.821601 [1280/28137]\n",
      "loss: 2.882194 [2560/28137]\n",
      "loss: 2.833138 [3840/28137]\n",
      "loss: 2.872044 [5120/28137]\n",
      "loss: 2.915656 [6400/28137]\n",
      "loss: 2.832235 [7680/28137]\n",
      "loss: 2.840273 [8960/28137]\n",
      "loss: 2.902572 [10240/28137]\n",
      "loss: 2.824995 [11520/28137]\n",
      "loss: 2.801181 [12800/28137]\n",
      "loss: 2.872972 [14080/28137]\n",
      "loss: 2.865457 [15360/28137]\n",
      "loss: 2.879426 [16640/28137]\n",
      "loss: 2.856236 [17920/28137]\n",
      "loss: 2.871561 [19200/28137]\n",
      "loss: 2.886887 [20480/28137]\n",
      "loss: 2.832721 [21760/28137]\n",
      "loss: 2.828876 [23040/28137]\n",
      "loss: 2.918766 [24320/28137]\n",
      "loss: 2.813167 [25600/28137]\n",
      "loss: 2.887522 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.850010, Accuracy: 2904/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 9]\n",
      "loss: 2.847889 [0/28137]\n",
      "loss: 2.769912 [1280/28137]\n",
      "loss: 2.904747 [2560/28137]\n",
      "loss: 2.888562 [3840/28137]\n",
      "loss: 2.863482 [5120/28137]\n",
      "loss: 2.871051 [6400/28137]\n",
      "loss: 2.840212 [7680/28137]\n",
      "loss: 2.933236 [8960/28137]\n",
      "loss: 2.816832 [10240/28137]\n",
      "loss: 2.871135 [11520/28137]\n",
      "loss: 2.816514 [12800/28137]\n",
      "loss: 2.816591 [14080/28137]\n",
      "loss: 2.800910 [15360/28137]\n",
      "loss: 2.839729 [16640/28137]\n",
      "loss: 2.785466 [17920/28137]\n",
      "loss: 2.878978 [19200/28137]\n",
      "loss: 2.886729 [20480/28137]\n",
      "loss: 2.847700 [21760/28137]\n",
      "loss: 2.847842 [23040/28137]\n",
      "loss: 2.903052 [24320/28137]\n",
      "loss: 2.878728 [25600/28137]\n",
      "loss: 2.820427 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.849847, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 10]\n",
      "loss: 2.855488 [0/28137]\n",
      "loss: 2.839886 [1280/28137]\n",
      "loss: 2.855962 [2560/28137]\n",
      "loss: 2.793249 [3840/28137]\n",
      "loss: 2.818948 [5120/28137]\n",
      "loss: 2.894879 [6400/28137]\n",
      "loss: 2.863884 [7680/28137]\n",
      "loss: 2.911508 [8960/28137]\n",
      "loss: 2.863427 [10240/28137]\n",
      "loss: 2.878283 [11520/28137]\n",
      "loss: 2.933979 [12800/28137]\n",
      "loss: 2.903628 [14080/28137]\n",
      "loss: 2.826122 [15360/28137]\n",
      "loss: 2.791759 [16640/28137]\n",
      "loss: 2.887366 [17920/28137]\n",
      "loss: 2.833482 [19200/28137]\n",
      "loss: 2.840781 [20480/28137]\n",
      "loss: 2.837514 [21760/28137]\n",
      "loss: 2.864120 [23040/28137]\n",
      "loss: 2.886861 [24320/28137]\n",
      "loss: 2.878721 [25600/28137]\n",
      "loss: 2.832087 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.849697, Accuracy: 2902/3725 (77.9%)\n",
      "\n",
      "\n",
      "[Epoch 11]\n",
      "loss: 2.808933 [0/28137]\n",
      "loss: 2.923514 [1280/28137]\n",
      "loss: 2.932823 [2560/28137]\n",
      "loss: 2.816764 [3840/28137]\n",
      "loss: 2.855540 [5120/28137]\n",
      "loss: 2.855790 [6400/28137]\n",
      "loss: 2.800941 [7680/28137]\n",
      "loss: 2.777808 [8960/28137]\n",
      "loss: 2.886347 [10240/28137]\n",
      "loss: 2.824612 [11520/28137]\n",
      "loss: 2.856146 [12800/28137]\n",
      "loss: 2.886414 [14080/28137]\n",
      "loss: 2.816603 [15360/28137]\n",
      "loss: 2.893945 [16640/28137]\n",
      "loss: 2.862867 [17920/28137]\n",
      "loss: 2.832453 [19200/28137]\n",
      "loss: 2.911126 [20480/28137]\n",
      "loss: 2.887613 [21760/28137]\n",
      "loss: 2.887130 [23040/28137]\n",
      "loss: 2.824683 [24320/28137]\n",
      "loss: 2.870697 [25600/28137]\n",
      "loss: 2.862991 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848985, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 12]\n",
      "loss: 2.886297 [0/28137]\n",
      "loss: 2.855146 [1280/28137]\n",
      "loss: 2.824345 [2560/28137]\n",
      "loss: 2.886095 [3840/28137]\n",
      "loss: 2.839768 [5120/28137]\n",
      "loss: 2.824240 [6400/28137]\n",
      "loss: 2.816462 [7680/28137]\n",
      "loss: 2.832365 [8960/28137]\n",
      "loss: 2.948172 [10240/28137]\n",
      "loss: 2.871528 [11520/28137]\n",
      "loss: 2.847196 [12800/28137]\n",
      "loss: 2.823905 [14080/28137]\n",
      "loss: 2.901002 [15360/28137]\n",
      "loss: 2.862266 [16640/28137]\n",
      "loss: 2.793204 [17920/28137]\n",
      "loss: 2.820988 [19200/28137]\n",
      "loss: 2.898697 [20480/28137]\n",
      "loss: 2.855203 [21760/28137]\n",
      "loss: 2.855896 [23040/28137]\n",
      "loss: 2.886477 [24320/28137]\n",
      "loss: 2.809013 [25600/28137]\n",
      "loss: 2.831924 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.849097, Accuracy: 2904/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 13]\n",
      "loss: 2.854835 [0/28137]\n",
      "loss: 2.831387 [1280/28137]\n",
      "loss: 2.885494 [2560/28137]\n",
      "loss: 2.916943 [3840/28137]\n",
      "loss: 2.839371 [5120/28137]\n",
      "loss: 2.862534 [6400/28137]\n",
      "loss: 2.832262 [7680/28137]\n",
      "loss: 2.862669 [8960/28137]\n",
      "loss: 2.785223 [10240/28137]\n",
      "loss: 2.932606 [11520/28137]\n",
      "loss: 2.854865 [12800/28137]\n",
      "loss: 2.909371 [14080/28137]\n",
      "loss: 2.785200 [15360/28137]\n",
      "loss: 2.862730 [16640/28137]\n",
      "loss: 2.808346 [17920/28137]\n",
      "loss: 2.886093 [19200/28137]\n",
      "loss: 2.909438 [20480/28137]\n",
      "loss: 2.872084 [21760/28137]\n",
      "loss: 2.847121 [23040/28137]\n",
      "loss: 2.769908 [24320/28137]\n",
      "loss: 2.823936 [25600/28137]\n",
      "loss: 2.909117 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848487, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 14]\n",
      "loss: 2.870141 [0/28137]\n",
      "loss: 2.886098 [1280/28137]\n",
      "loss: 2.854771 [2560/28137]\n",
      "loss: 2.862781 [3840/28137]\n",
      "loss: 2.870224 [5120/28137]\n",
      "loss: 2.877919 [6400/28137]\n",
      "loss: 2.862612 [7680/28137]\n",
      "loss: 2.893512 [8960/28137]\n",
      "loss: 2.839843 [10240/28137]\n",
      "loss: 2.885823 [11520/28137]\n",
      "loss: 2.862785 [12800/28137]\n",
      "loss: 2.870290 [14080/28137]\n",
      "loss: 2.916719 [15360/28137]\n",
      "loss: 2.800899 [16640/28137]\n",
      "loss: 2.932125 [17920/28137]\n",
      "loss: 2.854815 [19200/28137]\n",
      "loss: 2.831835 [20480/28137]\n",
      "loss: 2.808204 [21760/28137]\n",
      "loss: 2.893519 [23040/28137]\n",
      "loss: 2.870223 [24320/28137]\n",
      "loss: 2.892974 [25600/28137]\n",
      "loss: 2.846915 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848391, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 15]\n",
      "loss: 2.831322 [0/28137]\n",
      "loss: 2.831952 [1280/28137]\n",
      "loss: 2.800402 [2560/28137]\n",
      "loss: 2.862456 [3840/28137]\n",
      "loss: 2.816008 [5120/28137]\n",
      "loss: 2.800574 [6400/28137]\n",
      "loss: 2.816063 [7680/28137]\n",
      "loss: 2.824029 [8960/28137]\n",
      "loss: 2.854832 [10240/28137]\n",
      "loss: 2.862168 [11520/28137]\n",
      "loss: 2.823625 [12800/28137]\n",
      "loss: 2.924272 [14080/28137]\n",
      "loss: 2.839219 [15360/28137]\n",
      "loss: 2.854402 [16640/28137]\n",
      "loss: 2.854740 [17920/28137]\n",
      "loss: 2.901207 [19200/28137]\n",
      "loss: 2.877654 [20480/28137]\n",
      "loss: 2.870193 [21760/28137]\n",
      "loss: 2.885633 [23040/28137]\n",
      "loss: 2.878072 [24320/28137]\n",
      "loss: 2.877808 [25600/28137]\n",
      "loss: 2.955490 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848293, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 16]\n",
      "loss: 2.862148 [0/28137]\n",
      "loss: 2.823833 [1280/28137]\n",
      "loss: 2.854190 [2560/28137]\n",
      "loss: 2.839508 [3840/28137]\n",
      "loss: 2.893211 [5120/28137]\n",
      "loss: 2.823638 [6400/28137]\n",
      "loss: 2.846841 [7680/28137]\n",
      "loss: 2.862314 [8960/28137]\n",
      "loss: 2.807961 [10240/28137]\n",
      "loss: 2.808229 [11520/28137]\n",
      "loss: 2.807988 [12800/28137]\n",
      "loss: 2.870030 [14080/28137]\n",
      "loss: 2.831315 [15360/28137]\n",
      "loss: 2.831244 [16640/28137]\n",
      "loss: 2.854680 [17920/28137]\n",
      "loss: 2.838917 [19200/28137]\n",
      "loss: 2.947197 [20480/28137]\n",
      "loss: 2.877731 [21760/28137]\n",
      "loss: 2.869936 [23040/28137]\n",
      "loss: 2.862633 [24320/28137]\n",
      "loss: 2.869988 [25600/28137]\n",
      "loss: 2.839129 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848367, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 17]\n",
      "loss: 2.885677 [0/28137]\n",
      "loss: 2.862252 [1280/28137]\n",
      "loss: 2.885484 [2560/28137]\n",
      "loss: 2.823802 [3840/28137]\n",
      "loss: 2.815743 [5120/28137]\n",
      "loss: 2.823337 [6400/28137]\n",
      "loss: 2.862235 [7680/28137]\n",
      "loss: 2.831031 [8960/28137]\n",
      "loss: 2.862221 [10240/28137]\n",
      "loss: 2.924016 [11520/28137]\n",
      "loss: 2.893254 [12800/28137]\n",
      "loss: 2.808115 [14080/28137]\n",
      "loss: 2.877324 [15360/28137]\n",
      "loss: 2.862127 [16640/28137]\n",
      "loss: 2.823479 [17920/28137]\n",
      "loss: 2.839094 [19200/28137]\n",
      "loss: 2.846881 [20480/28137]\n",
      "loss: 2.900707 [21760/28137]\n",
      "loss: 2.846716 [23040/28137]\n",
      "loss: 2.900951 [24320/28137]\n",
      "loss: 2.846556 [25600/28137]\n",
      "loss: 2.885413 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848062, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 18]\n",
      "loss: 2.823555 [0/28137]\n",
      "loss: 2.823329 [1280/28137]\n",
      "loss: 2.838752 [2560/28137]\n",
      "loss: 2.884974 [3840/28137]\n",
      "loss: 2.808256 [5120/28137]\n",
      "loss: 2.823322 [6400/28137]\n",
      "loss: 2.854324 [7680/28137]\n",
      "loss: 2.939032 [8960/28137]\n",
      "loss: 2.854280 [10240/28137]\n",
      "loss: 2.924041 [11520/28137]\n",
      "loss: 2.846620 [12800/28137]\n",
      "loss: 2.869539 [14080/28137]\n",
      "loss: 2.877572 [15360/28137]\n",
      "loss: 2.838841 [16640/28137]\n",
      "loss: 2.838856 [17920/28137]\n",
      "loss: 2.831241 [19200/28137]\n",
      "loss: 2.815765 [20480/28137]\n",
      "loss: 2.831186 [21760/28137]\n",
      "loss: 2.916239 [23040/28137]\n",
      "loss: 2.854169 [24320/28137]\n",
      "loss: 2.846399 [25600/28137]\n",
      "loss: 2.815779 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848074, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 19]\n",
      "loss: 2.807832 [0/28137]\n",
      "loss: 2.792594 [1280/28137]\n",
      "loss: 2.800028 [2560/28137]\n",
      "loss: 2.785264 [3840/28137]\n",
      "loss: 2.831291 [5120/28137]\n",
      "loss: 2.939016 [6400/28137]\n",
      "loss: 2.862197 [7680/28137]\n",
      "loss: 2.908376 [8960/28137]\n",
      "loss: 2.792613 [10240/28137]\n",
      "loss: 2.900869 [11520/28137]\n",
      "loss: 2.800220 [12800/28137]\n",
      "loss: 2.885271 [14080/28137]\n",
      "loss: 2.862185 [15360/28137]\n",
      "loss: 2.885327 [16640/28137]\n",
      "loss: 2.823288 [17920/28137]\n",
      "loss: 2.892735 [19200/28137]\n",
      "loss: 2.869733 [20480/28137]\n",
      "loss: 2.908431 [21760/28137]\n",
      "loss: 2.823460 [23040/28137]\n",
      "loss: 2.877264 [24320/28137]\n",
      "loss: 2.931459 [25600/28137]\n",
      "loss: 2.800148 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.847971, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 20]\n",
      "loss: 2.838722 [0/28137]\n",
      "loss: 2.800122 [1280/28137]\n",
      "loss: 2.915942 [2560/28137]\n",
      "loss: 2.846792 [3840/28137]\n",
      "loss: 2.854222 [5120/28137]\n",
      "loss: 2.838669 [6400/28137]\n",
      "loss: 2.885089 [7680/28137]\n",
      "loss: 2.869776 [8960/28137]\n",
      "loss: 2.807934 [10240/28137]\n",
      "loss: 2.846298 [11520/28137]\n",
      "loss: 2.838923 [12800/28137]\n",
      "loss: 2.831192 [14080/28137]\n",
      "loss: 2.800022 [15360/28137]\n",
      "loss: 2.877430 [16640/28137]\n",
      "loss: 2.869650 [17920/28137]\n",
      "loss: 2.831062 [19200/28137]\n",
      "loss: 2.885358 [20480/28137]\n",
      "loss: 2.853943 [21760/28137]\n",
      "loss: 2.885355 [23040/28137]\n",
      "loss: 2.908178 [24320/28137]\n",
      "loss: 2.838869 [25600/28137]\n",
      "loss: 2.792508 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.847952, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 21]\n",
      "loss: 2.885220 [0/28137]\n",
      "loss: 2.838678 [1280/28137]\n",
      "loss: 2.792478 [2560/28137]\n",
      "loss: 2.831154 [3840/28137]\n",
      "loss: 2.838649 [5120/28137]\n",
      "loss: 2.900472 [6400/28137]\n",
      "loss: 2.892708 [7680/28137]\n",
      "loss: 2.838953 [8960/28137]\n",
      "loss: 2.869715 [10240/28137]\n",
      "loss: 2.915640 [11520/28137]\n",
      "loss: 2.846303 [12800/28137]\n",
      "loss: 2.908375 [14080/28137]\n",
      "loss: 2.892669 [15360/28137]\n",
      "loss: 2.846519 [16640/28137]\n",
      "loss: 2.831023 [17920/28137]\n",
      "loss: 2.815556 [19200/28137]\n",
      "loss: 2.861964 [20480/28137]\n",
      "loss: 2.869614 [21760/28137]\n",
      "loss: 2.923584 [23040/28137]\n",
      "loss: 2.823218 [24320/28137]\n",
      "loss: 2.885133 [25600/28137]\n",
      "loss: 2.831032 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.847815, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 22]\n",
      "loss: 2.877136 [0/28137]\n",
      "loss: 2.846506 [1280/28137]\n",
      "loss: 2.885266 [2560/28137]\n",
      "loss: 2.807952 [3840/28137]\n",
      "loss: 2.869411 [5120/28137]\n",
      "loss: 2.931290 [6400/28137]\n",
      "loss: 2.846468 [7680/28137]\n",
      "loss: 2.861855 [8960/28137]\n",
      "loss: 2.861665 [10240/28137]\n",
      "loss: 2.841197 [11520/28137]\n",
      "loss: 2.893979 [12800/28137]\n",
      "loss: 2.856746 [14080/28137]\n",
      "loss: 2.847511 [15360/28137]\n",
      "loss: 2.855499 [16640/28137]\n",
      "loss: 2.832307 [17920/28137]\n",
      "loss: 2.913478 [19200/28137]\n",
      "loss: 2.866840 [20480/28137]\n",
      "loss: 2.813846 [21760/28137]\n",
      "loss: 2.913081 [23040/28137]\n",
      "loss: 2.793785 [24320/28137]\n",
      "loss: 2.824860 [25600/28137]\n",
      "loss: 2.877251 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.853890, Accuracy: 2891/3725 (77.6%)\n",
      "\n",
      "\n",
      "[Epoch 23]\n",
      "loss: 2.879967 [0/28137]\n",
      "loss: 2.849922 [1280/28137]\n",
      "loss: 2.793185 [2560/28137]\n",
      "loss: 2.871017 [3840/28137]\n",
      "loss: 2.844340 [5120/28137]\n",
      "loss: 2.893327 [6400/28137]\n",
      "loss: 2.893646 [7680/28137]\n",
      "loss: 2.823768 [8960/28137]\n",
      "loss: 2.847262 [10240/28137]\n",
      "loss: 2.886460 [11520/28137]\n",
      "loss: 2.847776 [12800/28137]\n",
      "loss: 2.862867 [14080/28137]\n",
      "loss: 2.807941 [15360/28137]\n",
      "loss: 2.893531 [16640/28137]\n",
      "loss: 2.846625 [17920/28137]\n",
      "loss: 2.885299 [19200/28137]\n",
      "loss: 2.870023 [20480/28137]\n",
      "loss: 2.838846 [21760/28137]\n",
      "loss: 2.815812 [23040/28137]\n",
      "loss: 2.846570 [24320/28137]\n",
      "loss: 2.892929 [25600/28137]\n",
      "loss: 2.831102 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.847798, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 24]\n",
      "loss: 2.800020 [0/28137]\n",
      "loss: 2.846834 [1280/28137]\n",
      "loss: 2.946786 [2560/28137]\n",
      "loss: 2.823398 [3840/28137]\n",
      "loss: 2.862016 [5120/28137]\n",
      "loss: 2.846633 [6400/28137]\n",
      "loss: 2.892857 [7680/28137]\n",
      "loss: 2.846583 [8960/28137]\n",
      "loss: 2.862034 [10240/28137]\n",
      "loss: 2.838849 [11520/28137]\n",
      "loss: 2.869710 [12800/28137]\n",
      "loss: 2.777138 [14080/28137]\n",
      "loss: 2.885102 [15360/28137]\n",
      "loss: 2.869616 [16640/28137]\n",
      "loss: 2.854103 [17920/28137]\n",
      "loss: 2.842762 [19200/28137]\n",
      "loss: 2.748926 [20480/28137]\n",
      "loss: 2.862951 [21760/28137]\n",
      "loss: 2.873729 [23040/28137]\n",
      "loss: 2.863570 [24320/28137]\n",
      "loss: 2.785720 [25600/28137]\n",
      "loss: 2.763812 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.819601, Accuracy: 3015/3725 (80.9%)\n",
      "\n",
      "\n",
      "[Epoch 25]\n",
      "loss: 2.835980 [0/28137]\n",
      "loss: 2.839315 [1280/28137]\n",
      "loss: 2.831779 [2560/28137]\n",
      "loss: 2.754349 [3840/28137]\n",
      "loss: 2.840628 [5120/28137]\n",
      "loss: 2.792885 [6400/28137]\n",
      "loss: 2.831151 [7680/28137]\n",
      "loss: 2.815539 [8960/28137]\n",
      "loss: 2.761575 [10240/28137]\n",
      "loss: 2.831277 [11520/28137]\n",
      "loss: 2.846302 [12800/28137]\n",
      "loss: 2.846344 [14080/28137]\n",
      "loss: 2.815481 [15360/28137]\n",
      "loss: 2.792510 [16640/28137]\n",
      "loss: 2.815675 [17920/28137]\n",
      "loss: 2.808021 [19200/28137]\n",
      "loss: 2.823635 [20480/28137]\n",
      "loss: 2.839218 [21760/28137]\n",
      "loss: 2.808083 [23040/28137]\n",
      "loss: 2.892691 [24320/28137]\n",
      "loss: 2.854404 [25600/28137]\n",
      "loss: 2.800239 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.818016, Accuracy: 3018/3725 (81.0%)\n",
      "\n",
      "\n",
      "[Epoch 26]\n",
      "loss: 2.854323 [0/28137]\n",
      "loss: 2.746174 [1280/28137]\n",
      "loss: 2.846368 [2560/28137]\n",
      "loss: 2.846489 [3840/28137]\n",
      "loss: 2.885199 [5120/28137]\n",
      "loss: 2.846419 [6400/28137]\n",
      "loss: 2.764632 [7680/28137]\n",
      "loss: 2.810659 [8960/28137]\n",
      "loss: 2.803333 [10240/28137]\n",
      "loss: 2.826007 [11520/28137]\n",
      "loss: 2.785225 [12800/28137]\n",
      "loss: 2.855184 [14080/28137]\n",
      "loss: 2.762049 [15360/28137]\n",
      "loss: 2.741706 [16640/28137]\n",
      "loss: 2.871912 [17920/28137]\n",
      "loss: 2.800391 [19200/28137]\n",
      "loss: 2.797039 [20480/28137]\n",
      "loss: 2.754919 [21760/28137]\n",
      "loss: 2.763388 [23040/28137]\n",
      "loss: 2.792800 [24320/28137]\n",
      "loss: 2.831654 [25600/28137]\n",
      "loss: 2.813515 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.792357, Accuracy: 3118/3725 (83.7%)\n",
      "\n",
      "\n",
      "[Epoch 27]\n",
      "loss: 2.808732 [0/28137]\n",
      "loss: 2.870881 [1280/28137]\n",
      "loss: 2.801103 [2560/28137]\n",
      "loss: 2.800581 [3840/28137]\n",
      "loss: 2.824528 [5120/28137]\n",
      "loss: 2.762024 [6400/28137]\n",
      "loss: 2.808544 [7680/28137]\n",
      "loss: 2.785351 [8960/28137]\n",
      "loss: 2.777580 [10240/28137]\n",
      "loss: 2.816417 [11520/28137]\n",
      "loss: 2.800570 [12800/28137]\n",
      "loss: 2.808558 [14080/28137]\n",
      "loss: 2.808151 [15360/28137]\n",
      "loss: 2.816005 [16640/28137]\n",
      "loss: 2.808475 [17920/28137]\n",
      "loss: 2.816185 [19200/28137]\n",
      "loss: 2.801733 [20480/28137]\n",
      "loss: 2.869758 [21760/28137]\n",
      "loss: 2.777518 [23040/28137]\n",
      "loss: 2.746348 [24320/28137]\n",
      "loss: 2.823567 [25600/28137]\n",
      "loss: 2.831280 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.791140, Accuracy: 3120/3725 (83.8%)\n",
      "\n",
      "\n",
      "[Epoch 28]\n",
      "loss: 2.831218 [0/28137]\n",
      "loss: 2.785162 [1280/28137]\n",
      "loss: 2.823694 [2560/28137]\n",
      "loss: 2.769771 [3840/28137]\n",
      "loss: 2.792772 [5120/28137]\n",
      "loss: 2.808227 [6400/28137]\n",
      "loss: 2.746220 [7680/28137]\n",
      "loss: 2.815876 [8960/28137]\n",
      "loss: 2.831435 [10240/28137]\n",
      "loss: 2.785002 [11520/28137]\n",
      "loss: 2.769137 [12800/28137]\n",
      "loss: 2.800584 [14080/28137]\n",
      "loss: 2.831579 [15360/28137]\n",
      "loss: 2.808105 [16640/28137]\n",
      "loss: 2.793204 [17920/28137]\n",
      "loss: 2.800378 [19200/28137]\n",
      "loss: 2.761885 [20480/28137]\n",
      "loss: 2.777084 [21760/28137]\n",
      "loss: 2.846765 [23040/28137]\n",
      "loss: 2.792857 [24320/28137]\n",
      "loss: 2.792613 [25600/28137]\n",
      "loss: 2.808178 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.791117, Accuracy: 3120/3725 (83.8%)\n",
      "\n",
      "\n",
      "[Epoch 29]\n",
      "loss: 2.761787 [0/28137]\n",
      "loss: 2.808502 [1280/28137]\n",
      "loss: 2.815621 [2560/28137]\n",
      "loss: 2.792530 [3840/28137]\n",
      "loss: 2.754192 [5120/28137]\n",
      "loss: 2.792490 [6400/28137]\n",
      "loss: 2.777065 [7680/28137]\n",
      "loss: 2.823806 [8960/28137]\n",
      "loss: 2.792848 [10240/28137]\n",
      "loss: 2.846336 [11520/28137]\n",
      "loss: 2.792572 [12800/28137]\n",
      "loss: 2.807848 [14080/28137]\n",
      "loss: 2.777444 [15360/28137]\n",
      "loss: 2.776913 [16640/28137]\n",
      "loss: 2.800463 [17920/28137]\n",
      "loss: 2.769236 [19200/28137]\n",
      "loss: 2.769978 [20480/28137]\n",
      "loss: 2.769363 [21760/28137]\n",
      "loss: 2.792418 [23040/28137]\n",
      "loss: 2.792452 [24320/28137]\n",
      "loss: 2.777279 [25600/28137]\n",
      "loss: 2.854838 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.791001, Accuracy: 3120/3725 (83.8%)\n",
      "\n",
      "\n",
      "[Epoch 30]\n",
      "loss: 2.746290 [0/28137]\n",
      "loss: 2.761765 [1280/28137]\n",
      "loss: 2.838654 [2560/28137]\n",
      "loss: 2.769427 [3840/28137]\n",
      "loss: 2.831141 [5120/28137]\n",
      "loss: 2.769681 [6400/28137]\n",
      "loss: 2.738490 [7680/28137]\n",
      "loss: 2.807947 [8960/28137]\n",
      "loss: 2.823832 [10240/28137]\n",
      "loss: 2.846468 [11520/28137]\n",
      "loss: 2.761383 [12800/28137]\n",
      "loss: 2.846566 [14080/28137]\n",
      "loss: 2.807981 [15360/28137]\n",
      "loss: 2.808105 [16640/28137]\n",
      "loss: 2.823423 [17920/28137]\n",
      "loss: 2.838841 [19200/28137]\n",
      "loss: 2.815897 [20480/28137]\n",
      "loss: 2.784780 [21760/28137]\n",
      "loss: 2.792367 [23040/28137]\n",
      "loss: 2.839304 [24320/28137]\n",
      "loss: 2.799837 [25600/28137]\n",
      "loss: 2.800515 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.791017, Accuracy: 3120/3725 (83.8%)\n",
      "\n",
      "\n",
      "[Epoch 31]\n",
      "loss: 2.769234 [0/28137]\n",
      "loss: 2.846673 [1280/28137]\n",
      "loss: 2.792439 [2560/28137]\n",
      "loss: 2.823517 [3840/28137]\n",
      "loss: 2.792377 [5120/28137]\n",
      "loss: 2.771570 [6400/28137]\n",
      "loss: 2.747705 [7680/28137]\n",
      "loss: 2.794374 [8960/28137]\n",
      "loss: 2.809065 [10240/28137]\n",
      "loss: 2.771234 [11520/28137]\n",
      "loss: 2.787129 [12800/28137]\n",
      "loss: 2.708211 [14080/28137]\n",
      "loss: 2.793258 [15360/28137]\n",
      "loss: 2.771049 [16640/28137]\n",
      "loss: 2.785255 [17920/28137]\n",
      "loss: 2.762262 [19200/28137]\n",
      "loss: 2.823953 [20480/28137]\n",
      "loss: 2.738851 [21760/28137]\n",
      "loss: 2.774077 [23040/28137]\n",
      "loss: 2.738608 [24320/28137]\n",
      "loss: 2.785071 [25600/28137]\n",
      "loss: 2.792766 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.764166, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 32]\n",
      "loss: 2.754154 [0/28137]\n",
      "loss: 2.715559 [1280/28137]\n",
      "loss: 2.777159 [2560/28137]\n",
      "loss: 2.761902 [3840/28137]\n",
      "loss: 2.777633 [5120/28137]\n",
      "loss: 2.723573 [6400/28137]\n",
      "loss: 2.784965 [7680/28137]\n",
      "loss: 2.815545 [8960/28137]\n",
      "loss: 2.791730 [10240/28137]\n",
      "loss: 2.785005 [11520/28137]\n",
      "loss: 2.808096 [12800/28137]\n",
      "loss: 2.831605 [14080/28137]\n",
      "loss: 2.746607 [15360/28137]\n",
      "loss: 2.785239 [16640/28137]\n",
      "loss: 2.723198 [17920/28137]\n",
      "loss: 2.801144 [19200/28137]\n",
      "loss: 2.761729 [20480/28137]\n",
      "loss: 2.730915 [21760/28137]\n",
      "loss: 2.769624 [23040/28137]\n",
      "loss: 2.808249 [24320/28137]\n",
      "loss: 2.823446 [25600/28137]\n",
      "loss: 2.715301 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763998, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 33]\n",
      "loss: 2.769804 [0/28137]\n",
      "loss: 2.769306 [1280/28137]\n",
      "loss: 2.753514 [2560/28137]\n",
      "loss: 2.746139 [3840/28137]\n",
      "loss: 2.785025 [5120/28137]\n",
      "loss: 2.785029 [6400/28137]\n",
      "loss: 2.730712 [7680/28137]\n",
      "loss: 2.838737 [8960/28137]\n",
      "loss: 2.784801 [10240/28137]\n",
      "loss: 2.785133 [11520/28137]\n",
      "loss: 2.761947 [12800/28137]\n",
      "loss: 2.769526 [14080/28137]\n",
      "loss: 2.746138 [15360/28137]\n",
      "loss: 2.792417 [16640/28137]\n",
      "loss: 2.792896 [17920/28137]\n",
      "loss: 2.815793 [19200/28137]\n",
      "loss: 2.723011 [20480/28137]\n",
      "loss: 2.753814 [21760/28137]\n",
      "loss: 2.823603 [23040/28137]\n",
      "loss: 2.800092 [24320/28137]\n",
      "loss: 2.769634 [25600/28137]\n",
      "loss: 2.792413 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763932, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 34]\n",
      "loss: 2.785032 [0/28137]\n",
      "loss: 2.761408 [1280/28137]\n",
      "loss: 2.730614 [2560/28137]\n",
      "loss: 2.823302 [3840/28137]\n",
      "loss: 2.746427 [5120/28137]\n",
      "loss: 2.730711 [6400/28137]\n",
      "loss: 2.792156 [7680/28137]\n",
      "loss: 2.776950 [8960/28137]\n",
      "loss: 2.722975 [10240/28137]\n",
      "loss: 2.800424 [11520/28137]\n",
      "loss: 2.730780 [12800/28137]\n",
      "loss: 2.753906 [14080/28137]\n",
      "loss: 2.769392 [15360/28137]\n",
      "loss: 2.784990 [16640/28137]\n",
      "loss: 2.784487 [17920/28137]\n",
      "loss: 2.776913 [19200/28137]\n",
      "loss: 2.831382 [20480/28137]\n",
      "loss: 2.777208 [21760/28137]\n",
      "loss: 2.754097 [23040/28137]\n",
      "loss: 2.769421 [24320/28137]\n",
      "loss: 2.792462 [25600/28137]\n",
      "loss: 2.792550 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763841, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 35]\n",
      "loss: 2.830858 [0/28137]\n",
      "loss: 2.746029 [1280/28137]\n",
      "loss: 2.753953 [2560/28137]\n",
      "loss: 2.785074 [3840/28137]\n",
      "loss: 2.784905 [5120/28137]\n",
      "loss: 2.792864 [6400/28137]\n",
      "loss: 2.761527 [7680/28137]\n",
      "loss: 2.807947 [8960/28137]\n",
      "loss: 2.730477 [10240/28137]\n",
      "loss: 2.777279 [11520/28137]\n",
      "loss: 2.816062 [12800/28137]\n",
      "loss: 2.822990 [14080/28137]\n",
      "loss: 2.738349 [15360/28137]\n",
      "loss: 2.776742 [16640/28137]\n",
      "loss: 2.761853 [17920/28137]\n",
      "loss: 2.776894 [19200/28137]\n",
      "loss: 2.776682 [20480/28137]\n",
      "loss: 2.792047 [21760/28137]\n",
      "loss: 2.738413 [23040/28137]\n",
      "loss: 2.792701 [24320/28137]\n",
      "loss: 2.815959 [25600/28137]\n",
      "loss: 2.730644 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763795, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 36]\n",
      "loss: 2.738885 [0/28137]\n",
      "loss: 2.745973 [1280/28137]\n",
      "loss: 2.761315 [2560/28137]\n",
      "loss: 2.715089 [3840/28137]\n",
      "loss: 2.831257 [5120/28137]\n",
      "loss: 2.815921 [6400/28137]\n",
      "loss: 2.792236 [7680/28137]\n",
      "loss: 2.761795 [8960/28137]\n",
      "loss: 2.808225 [10240/28137]\n",
      "loss: 2.722627 [11520/28137]\n",
      "loss: 2.799884 [12800/28137]\n",
      "loss: 2.792488 [14080/28137]\n",
      "loss: 2.792800 [15360/28137]\n",
      "loss: 2.730608 [16640/28137]\n",
      "loss: 2.776757 [17920/28137]\n",
      "loss: 2.807981 [19200/28137]\n",
      "loss: 2.792099 [20480/28137]\n",
      "loss: 2.754071 [21760/28137]\n",
      "loss: 2.792251 [23040/28137]\n",
      "loss: 2.730528 [24320/28137]\n",
      "loss: 2.823483 [25600/28137]\n",
      "loss: 2.791994 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763794, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 37]\n",
      "loss: 2.776934 [0/28137]\n",
      "loss: 2.745952 [1280/28137]\n",
      "loss: 2.753702 [2560/28137]\n",
      "loss: 2.769269 [3840/28137]\n",
      "loss: 2.769495 [5120/28137]\n",
      "loss: 2.784602 [6400/28137]\n",
      "loss: 2.753422 [7680/28137]\n",
      "loss: 2.800266 [8960/28137]\n",
      "loss: 2.769258 [10240/28137]\n",
      "loss: 2.753698 [11520/28137]\n",
      "loss: 2.776817 [12800/28137]\n",
      "loss: 2.777191 [14080/28137]\n",
      "loss: 2.776854 [15360/28137]\n",
      "loss: 2.746306 [16640/28137]\n",
      "loss: 2.738107 [17920/28137]\n",
      "loss: 2.769245 [19200/28137]\n",
      "loss: 2.761346 [20480/28137]\n",
      "loss: 2.800302 [21760/28137]\n",
      "loss: 2.769232 [23040/28137]\n",
      "loss: 2.776705 [24320/28137]\n",
      "loss: 2.776817 [25600/28137]\n",
      "loss: 2.722828 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763781, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 38]\n",
      "loss: 2.761091 [0/28137]\n",
      "loss: 2.761430 [1280/28137]\n",
      "loss: 2.792471 [2560/28137]\n",
      "loss: 2.761211 [3840/28137]\n",
      "loss: 2.761697 [5120/28137]\n",
      "loss: 2.746296 [6400/28137]\n",
      "loss: 2.792438 [7680/28137]\n",
      "loss: 2.761227 [8960/28137]\n",
      "loss: 2.761325 [10240/28137]\n",
      "loss: 2.800021 [11520/28137]\n",
      "loss: 2.722948 [12800/28137]\n",
      "loss: 2.792405 [14080/28137]\n",
      "loss: 2.768919 [15360/28137]\n",
      "loss: 2.753568 [16640/28137]\n",
      "loss: 2.838507 [17920/28137]\n",
      "loss: 2.846813 [19200/28137]\n",
      "loss: 2.753757 [20480/28137]\n",
      "loss: 2.800234 [21760/28137]\n",
      "loss: 2.699695 [23040/28137]\n",
      "loss: 2.746203 [24320/28137]\n",
      "loss: 2.807651 [25600/28137]\n",
      "loss: 2.815351 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763633, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 39]\n",
      "loss: 2.699572 [0/28137]\n",
      "loss: 2.722944 [1280/28137]\n",
      "loss: 2.738083 [2560/28137]\n",
      "loss: 2.730711 [3840/28137]\n",
      "loss: 2.761246 [5120/28137]\n",
      "loss: 2.730603 [6400/28137]\n",
      "loss: 2.799873 [7680/28137]\n",
      "loss: 2.792312 [8960/28137]\n",
      "loss: 2.776725 [10240/28137]\n",
      "loss: 2.784469 [11520/28137]\n",
      "loss: 2.776896 [12800/28137]\n",
      "loss: 2.745950 [14080/28137]\n",
      "loss: 2.792198 [15360/28137]\n",
      "loss: 2.761320 [16640/28137]\n",
      "loss: 2.753521 [17920/28137]\n",
      "loss: 2.730529 [19200/28137]\n",
      "loss: 2.807604 [20480/28137]\n",
      "loss: 2.738118 [21760/28137]\n",
      "loss: 2.730624 [23040/28137]\n",
      "loss: 2.784670 [24320/28137]\n",
      "loss: 2.784282 [25600/28137]\n",
      "loss: 2.800327 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763595, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 40]\n",
      "loss: 2.784395 [0/28137]\n",
      "loss: 2.761178 [1280/28137]\n",
      "loss: 2.761337 [2560/28137]\n",
      "loss: 2.745909 [3840/28137]\n",
      "loss: 2.753464 [5120/28137]\n",
      "loss: 2.777209 [6400/28137]\n",
      "loss: 2.807529 [7680/28137]\n",
      "loss: 2.768893 [8960/28137]\n",
      "loss: 2.776645 [10240/28137]\n",
      "loss: 2.815049 [11520/28137]\n",
      "loss: 2.745829 [12800/28137]\n",
      "loss: 2.761343 [14080/28137]\n",
      "loss: 2.784229 [15360/28137]\n",
      "loss: 2.761061 [16640/28137]\n",
      "loss: 2.738084 [17920/28137]\n",
      "loss: 2.799664 [19200/28137]\n",
      "loss: 2.730440 [20480/28137]\n",
      "loss: 2.753511 [21760/28137]\n",
      "loss: 2.738106 [23040/28137]\n",
      "loss: 2.791983 [24320/28137]\n",
      "loss: 2.792190 [25600/28137]\n",
      "loss: 2.799940 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763473, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 41]\n",
      "loss: 2.807364 [0/28137]\n",
      "loss: 2.738145 [1280/28137]\n",
      "loss: 2.722598 [2560/28137]\n",
      "loss: 2.730263 [3840/28137]\n",
      "loss: 2.769079 [5120/28137]\n",
      "loss: 2.801363 [6400/28137]\n",
      "loss: 2.765095 [7680/28137]\n",
      "loss: 2.787759 [8960/28137]\n",
      "loss: 2.768025 [10240/28137]\n",
      "loss: 2.733991 [11520/28137]\n",
      "loss: 2.740330 [12800/28137]\n",
      "loss: 2.739015 [14080/28137]\n",
      "loss: 2.715746 [15360/28137]\n",
      "loss: 2.793217 [16640/28137]\n",
      "loss: 2.686271 [17920/28137]\n",
      "loss: 2.715388 [19200/28137]\n",
      "loss: 2.731350 [20480/28137]\n",
      "loss: 2.732800 [21760/28137]\n",
      "loss: 2.692401 [23040/28137]\n",
      "loss: 2.746142 [24320/28137]\n",
      "loss: 2.715151 [25600/28137]\n",
      "loss: 2.709795 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.738616, Accuracy: 3319/3725 (89.1%)\n",
      "\n",
      "\n",
      "[Epoch 42]\n",
      "loss: 2.723215 [0/28137]\n",
      "loss: 2.700665 [1280/28137]\n",
      "loss: 2.730603 [2560/28137]\n",
      "loss: 2.724671 [3840/28137]\n",
      "loss: 2.762182 [5120/28137]\n",
      "loss: 2.738616 [6400/28137]\n",
      "loss: 2.768947 [7680/28137]\n",
      "loss: 2.730735 [8960/28137]\n",
      "loss: 2.738835 [10240/28137]\n",
      "loss: 2.784751 [11520/28137]\n",
      "loss: 2.769322 [12800/28137]\n",
      "loss: 2.723026 [14080/28137]\n",
      "loss: 2.754178 [15360/28137]\n",
      "loss: 2.761581 [16640/28137]\n",
      "loss: 2.784943 [17920/28137]\n",
      "loss: 2.776899 [19200/28137]\n",
      "loss: 2.707565 [20480/28137]\n",
      "loss: 2.730868 [21760/28137]\n",
      "loss: 2.722642 [23040/28137]\n",
      "loss: 2.755521 [24320/28137]\n",
      "loss: 2.753732 [25600/28137]\n",
      "loss: 2.676581 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.737242, Accuracy: 3323/3725 (89.2%)\n",
      "\n",
      "\n",
      "[Epoch 43]\n",
      "loss: 2.761749 [0/28137]\n",
      "loss: 2.784734 [1280/28137]\n",
      "loss: 2.831011 [2560/28137]\n",
      "loss: 2.746683 [3840/28137]\n",
      "loss: 2.784518 [5120/28137]\n",
      "loss: 2.768839 [6400/28137]\n",
      "loss: 2.784665 [7680/28137]\n",
      "loss: 2.776786 [8960/28137]\n",
      "loss: 2.738108 [10240/28137]\n",
      "loss: 2.769006 [11520/28137]\n",
      "loss: 2.745008 [12800/28137]\n",
      "loss: 2.753615 [14080/28137]\n",
      "loss: 2.723100 [15360/28137]\n",
      "loss: 2.745788 [16640/28137]\n",
      "loss: 2.738013 [17920/28137]\n",
      "loss: 2.776793 [19200/28137]\n",
      "loss: 2.730509 [20480/28137]\n",
      "loss: 2.784425 [21760/28137]\n",
      "loss: 2.753366 [23040/28137]\n",
      "loss: 2.730545 [24320/28137]\n",
      "loss: 2.699582 [25600/28137]\n",
      "loss: 2.745776 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.736546, Accuracy: 3324/3725 (89.2%)\n",
      "\n",
      "\n",
      "[Epoch 44]\n",
      "loss: 2.707261 [0/28137]\n",
      "loss: 2.730457 [1280/28137]\n",
      "loss: 2.768917 [2560/28137]\n",
      "loss: 2.722771 [3840/28137]\n",
      "loss: 2.707178 [5120/28137]\n",
      "loss: 2.730343 [6400/28137]\n",
      "loss: 2.753539 [7680/28137]\n",
      "loss: 2.745835 [8960/28137]\n",
      "loss: 2.722584 [10240/28137]\n",
      "loss: 2.768832 [11520/28137]\n",
      "loss: 2.745796 [12800/28137]\n",
      "loss: 2.730250 [14080/28137]\n",
      "loss: 2.807342 [15360/28137]\n",
      "loss: 2.784106 [16640/28137]\n",
      "loss: 2.738036 [17920/28137]\n",
      "loss: 2.761581 [19200/28137]\n",
      "loss: 2.722769 [20480/28137]\n",
      "loss: 2.692002 [21760/28137]\n",
      "loss: 2.730568 [23040/28137]\n",
      "loss: 2.799812 [24320/28137]\n",
      "loss: 2.753483 [25600/28137]\n",
      "loss: 2.761477 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.736437, Accuracy: 3324/3725 (89.2%)\n",
      "\n",
      "\n",
      "[Epoch 45]\n",
      "loss: 2.745696 [0/28137]\n",
      "loss: 2.745781 [1280/28137]\n",
      "loss: 2.722559 [2560/28137]\n",
      "loss: 2.707173 [3840/28137]\n",
      "loss: 2.814980 [5120/28137]\n",
      "loss: 2.794098 [6400/28137]\n",
      "loss: 2.709646 [7680/28137]\n",
      "loss: 2.738775 [8960/28137]\n",
      "loss: 2.730652 [10240/28137]\n",
      "loss: 2.707520 [11520/28137]\n",
      "loss: 2.753492 [12800/28137]\n",
      "loss: 2.691967 [14080/28137]\n",
      "loss: 2.730248 [15360/28137]\n",
      "loss: 2.714933 [16640/28137]\n",
      "loss: 2.715007 [17920/28137]\n",
      "loss: 2.687296 [19200/28137]\n",
      "loss: 2.730465 [20480/28137]\n",
      "loss: 2.699448 [21760/28137]\n",
      "loss: 2.730509 [23040/28137]\n",
      "loss: 2.699579 [24320/28137]\n",
      "loss: 2.684016 [25600/28137]\n",
      "loss: 2.707191 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.717488, Accuracy: 3396/3725 (91.2%)\n",
      "\n",
      "\n",
      "[Epoch 46]\n",
      "loss: 2.676341 [0/28137]\n",
      "loss: 2.745721 [1280/28137]\n",
      "loss: 2.722511 [2560/28137]\n",
      "loss: 2.714773 [3840/28137]\n",
      "loss: 2.707158 [5120/28137]\n",
      "loss: 2.699447 [6400/28137]\n",
      "loss: 2.691842 [7680/28137]\n",
      "loss: 2.676314 [8960/28137]\n",
      "loss: 2.769083 [10240/28137]\n",
      "loss: 2.753351 [11520/28137]\n",
      "loss: 2.722744 [12800/28137]\n",
      "loss: 2.768771 [14080/28137]\n",
      "loss: 2.684096 [15360/28137]\n",
      "loss: 2.699483 [16640/28137]\n",
      "loss: 2.707124 [17920/28137]\n",
      "loss: 2.761062 [19200/28137]\n",
      "loss: 2.738080 [20480/28137]\n",
      "loss: 2.760880 [21760/28137]\n",
      "loss: 2.660917 [23040/28137]\n",
      "loss: 2.684150 [24320/28137]\n",
      "loss: 2.722607 [25600/28137]\n",
      "loss: 2.714969 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.717412, Accuracy: 3396/3725 (91.2%)\n",
      "\n",
      "\n",
      "[Epoch 47]\n",
      "loss: 2.722666 [0/28137]\n",
      "loss: 2.714887 [1280/28137]\n",
      "loss: 2.722548 [2560/28137]\n",
      "loss: 2.707103 [3840/28137]\n",
      "loss: 2.691741 [5120/28137]\n",
      "loss: 2.714817 [6400/28137]\n",
      "loss: 2.691710 [7680/28137]\n",
      "loss: 2.738067 [8960/28137]\n",
      "loss: 2.714799 [10240/28137]\n",
      "loss: 2.707205 [11520/28137]\n",
      "loss: 2.676363 [12800/28137]\n",
      "loss: 2.722568 [14080/28137]\n",
      "loss: 2.745664 [15360/28137]\n",
      "loss: 2.684056 [16640/28137]\n",
      "loss: 2.691682 [17920/28137]\n",
      "loss: 2.684039 [19200/28137]\n",
      "loss: 2.691751 [20480/28137]\n",
      "loss: 2.753383 [21760/28137]\n",
      "loss: 2.691769 [23040/28137]\n",
      "loss: 2.722584 [24320/28137]\n",
      "loss: 2.722478 [25600/28137]\n",
      "loss: 2.707176 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.717329, Accuracy: 3396/3725 (91.2%)\n",
      "\n",
      "\n",
      "[Epoch 48]\n",
      "loss: 2.699413 [0/28137]\n",
      "loss: 2.699408 [1280/28137]\n",
      "loss: 2.691855 [2560/28137]\n",
      "loss: 2.722498 [3840/28137]\n",
      "loss: 2.730260 [5120/28137]\n",
      "loss: 2.737863 [6400/28137]\n",
      "loss: 2.691650 [7680/28137]\n",
      "loss: 2.753231 [8960/28137]\n",
      "loss: 2.753444 [10240/28137]\n",
      "loss: 2.683990 [11520/28137]\n",
      "loss: 2.676346 [12800/28137]\n",
      "loss: 2.691678 [14080/28137]\n",
      "loss: 2.707264 [15360/28137]\n",
      "loss: 2.768699 [16640/28137]\n",
      "loss: 2.707070 [17920/28137]\n",
      "loss: 2.691753 [19200/28137]\n",
      "loss: 2.707083 [20480/28137]\n",
      "loss: 2.707119 [21760/28137]\n",
      "loss: 2.722527 [23040/28137]\n",
      "loss: 2.722460 [24320/28137]\n",
      "loss: 2.684038 [25600/28137]\n",
      "loss: 2.707075 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.717325, Accuracy: 3396/3725 (91.2%)\n",
      "\n",
      "\n",
      "[Epoch 49]\n",
      "loss: 2.691777 [0/28137]\n",
      "loss: 2.699432 [1280/28137]\n",
      "loss: 2.722459 [2560/28137]\n",
      "loss: 2.712009 [3840/28137]\n",
      "loss: 2.687134 [5120/28137]\n",
      "loss: 2.666481 [6400/28137]\n",
      "loss: 2.655529 [7680/28137]\n",
      "loss: 2.655025 [8960/28137]\n",
      "loss: 2.677771 [10240/28137]\n",
      "loss: 2.654957 [11520/28137]\n",
      "loss: 2.669204 [12800/28137]\n",
      "loss: 2.664906 [14080/28137]\n",
      "loss: 2.662598 [15360/28137]\n",
      "loss: 2.645780 [16640/28137]\n",
      "loss: 2.669075 [17920/28137]\n",
      "loss: 2.668797 [19200/28137]\n",
      "loss: 2.669343 [20480/28137]\n",
      "loss: 2.670242 [21760/28137]\n",
      "loss: 2.653609 [23040/28137]\n",
      "loss: 2.638149 [24320/28137]\n",
      "loss: 2.692616 [25600/28137]\n",
      "loss: 2.647068 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660400, Accuracy: 3612/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 50]\n",
      "loss: 2.669016 [0/28137]\n",
      "loss: 2.645958 [1280/28137]\n",
      "loss: 2.654444 [2560/28137]\n",
      "loss: 2.677363 [3840/28137]\n",
      "loss: 2.653359 [5120/28137]\n",
      "loss: 2.668882 [6400/28137]\n",
      "loss: 2.653493 [7680/28137]\n",
      "loss: 2.661220 [8960/28137]\n",
      "loss: 2.653470 [10240/28137]\n",
      "loss: 2.637927 [11520/28137]\n",
      "loss: 2.660958 [12800/28137]\n",
      "loss: 2.668855 [14080/28137]\n",
      "loss: 2.668853 [15360/28137]\n",
      "loss: 2.645579 [16640/28137]\n",
      "loss: 2.661035 [17920/28137]\n",
      "loss: 2.637882 [19200/28137]\n",
      "loss: 2.707629 [20480/28137]\n",
      "loss: 2.676515 [21760/28137]\n",
      "loss: 2.653498 [23040/28137]\n",
      "loss: 2.668810 [24320/28137]\n",
      "loss: 2.637902 [25600/28137]\n",
      "loss: 2.645575 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660016, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 51]\n",
      "loss: 2.661002 [0/28137]\n",
      "loss: 2.707418 [1280/28137]\n",
      "loss: 2.661146 [2560/28137]\n",
      "loss: 2.661143 [3840/28137]\n",
      "loss: 2.715219 [5120/28137]\n",
      "loss: 2.661123 [6400/28137]\n",
      "loss: 2.669393 [7680/28137]\n",
      "loss: 2.661030 [8960/28137]\n",
      "loss: 2.668807 [10240/28137]\n",
      "loss: 2.699684 [11520/28137]\n",
      "loss: 2.668875 [12800/28137]\n",
      "loss: 2.653335 [14080/28137]\n",
      "loss: 2.676590 [15360/28137]\n",
      "loss: 2.661050 [16640/28137]\n",
      "loss: 2.684157 [17920/28137]\n",
      "loss: 2.684235 [19200/28137]\n",
      "loss: 2.661081 [20480/28137]\n",
      "loss: 2.653397 [21760/28137]\n",
      "loss: 2.645605 [23040/28137]\n",
      "loss: 2.668702 [24320/28137]\n",
      "loss: 2.668813 [25600/28137]\n",
      "loss: 2.653294 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659930, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 52]\n",
      "loss: 2.668830 [0/28137]\n",
      "loss: 2.660951 [1280/28137]\n",
      "loss: 2.661154 [2560/28137]\n",
      "loss: 2.630150 [3840/28137]\n",
      "loss: 2.661001 [5120/28137]\n",
      "loss: 2.660998 [6400/28137]\n",
      "loss: 2.637848 [7680/28137]\n",
      "loss: 2.668897 [8960/28137]\n",
      "loss: 2.653258 [10240/28137]\n",
      "loss: 2.691793 [11520/28137]\n",
      "loss: 2.661043 [12800/28137]\n",
      "loss: 2.645569 [14080/28137]\n",
      "loss: 2.645677 [15360/28137]\n",
      "loss: 2.645588 [16640/28137]\n",
      "loss: 2.668856 [17920/28137]\n",
      "loss: 2.637855 [19200/28137]\n",
      "loss: 2.645569 [20480/28137]\n",
      "loss: 2.661003 [21760/28137]\n",
      "loss: 2.637889 [23040/28137]\n",
      "loss: 2.645633 [24320/28137]\n",
      "loss: 2.676423 [25600/28137]\n",
      "loss: 2.653280 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659917, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 53]\n",
      "loss: 2.660965 [0/28137]\n",
      "loss: 2.637854 [1280/28137]\n",
      "loss: 2.637969 [2560/28137]\n",
      "loss: 2.638032 [3840/28137]\n",
      "loss: 2.676650 [5120/28137]\n",
      "loss: 2.668930 [6400/28137]\n",
      "loss: 2.637856 [7680/28137]\n",
      "loss: 2.692234 [8960/28137]\n",
      "loss: 2.645744 [10240/28137]\n",
      "loss: 2.684228 [11520/28137]\n",
      "loss: 2.645723 [12800/28137]\n",
      "loss: 2.645579 [14080/28137]\n",
      "loss: 2.653391 [15360/28137]\n",
      "loss: 2.664163 [16640/28137]\n",
      "loss: 2.684719 [17920/28137]\n",
      "loss: 2.661462 [19200/28137]\n",
      "loss: 2.666072 [20480/28137]\n",
      "loss: 2.684109 [21760/28137]\n",
      "loss: 2.676871 [23040/28137]\n",
      "loss: 2.653554 [24320/28137]\n",
      "loss: 2.698188 [25600/28137]\n",
      "loss: 2.661104 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660907, Accuracy: 3612/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 54]\n",
      "loss: 2.661028 [0/28137]\n",
      "loss: 2.648880 [1280/28137]\n",
      "loss: 2.654197 [2560/28137]\n",
      "loss: 2.653671 [3840/28137]\n",
      "loss: 2.637932 [5120/28137]\n",
      "loss: 2.676671 [6400/28137]\n",
      "loss: 2.637953 [7680/28137]\n",
      "loss: 2.637990 [8960/28137]\n",
      "loss: 2.669130 [10240/28137]\n",
      "loss: 2.661158 [11520/28137]\n",
      "loss: 2.653296 [12800/28137]\n",
      "loss: 2.653327 [14080/28137]\n",
      "loss: 2.645593 [15360/28137]\n",
      "loss: 2.676708 [16640/28137]\n",
      "loss: 2.653552 [17920/28137]\n",
      "loss: 2.637866 [19200/28137]\n",
      "loss: 2.645677 [20480/28137]\n",
      "loss: 2.676538 [21760/28137]\n",
      "loss: 2.645803 [23040/28137]\n",
      "loss: 2.668996 [24320/28137]\n",
      "loss: 2.669073 [25600/28137]\n",
      "loss: 2.676672 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660512, Accuracy: 3611/3725 (96.9%)\n",
      "\n",
      "\n",
      "[Epoch 55]\n",
      "loss: 2.637943 [0/28137]\n",
      "loss: 2.668813 [1280/28137]\n",
      "loss: 2.645607 [2560/28137]\n",
      "loss: 2.669021 [3840/28137]\n",
      "loss: 2.661061 [5120/28137]\n",
      "loss: 2.668816 [6400/28137]\n",
      "loss: 2.653330 [7680/28137]\n",
      "loss: 2.676394 [8960/28137]\n",
      "loss: 2.653270 [10240/28137]\n",
      "loss: 2.661170 [11520/28137]\n",
      "loss: 2.676436 [12800/28137]\n",
      "loss: 2.676445 [14080/28137]\n",
      "loss: 2.645576 [15360/28137]\n",
      "loss: 2.661426 [16640/28137]\n",
      "loss: 2.692003 [17920/28137]\n",
      "loss: 2.684107 [19200/28137]\n",
      "loss: 2.645615 [20480/28137]\n",
      "loss: 2.653318 [21760/28137]\n",
      "loss: 2.645746 [23040/28137]\n",
      "loss: 2.668673 [24320/28137]\n",
      "loss: 2.661222 [25600/28137]\n",
      "loss: 2.660965 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659963, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 56]\n",
      "loss: 2.637865 [0/28137]\n",
      "loss: 2.676606 [1280/28137]\n",
      "loss: 2.653242 [2560/28137]\n",
      "loss: 2.660984 [3840/28137]\n",
      "loss: 2.645699 [5120/28137]\n",
      "loss: 2.645528 [6400/28137]\n",
      "loss: 2.668650 [7680/28137]\n",
      "loss: 2.645537 [8960/28137]\n",
      "loss: 2.660944 [10240/28137]\n",
      "loss: 2.653260 [11520/28137]\n",
      "loss: 2.668612 [12800/28137]\n",
      "loss: 2.684039 [14080/28137]\n",
      "loss: 2.668629 [15360/28137]\n",
      "loss: 2.668694 [16640/28137]\n",
      "loss: 2.668621 [17920/28137]\n",
      "loss: 2.699579 [19200/28137]\n",
      "loss: 2.676573 [20480/28137]\n",
      "loss: 2.645551 [21760/28137]\n",
      "loss: 2.653239 [23040/28137]\n",
      "loss: 2.645587 [24320/28137]\n",
      "loss: 2.660933 [25600/28137]\n",
      "loss: 2.645535 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659847, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 57]\n",
      "loss: 2.668638 [0/28137]\n",
      "loss: 2.653236 [1280/28137]\n",
      "loss: 2.645659 [2560/28137]\n",
      "loss: 2.645548 [3840/28137]\n",
      "loss: 2.660917 [5120/28137]\n",
      "loss: 2.668658 [6400/28137]\n",
      "loss: 2.660904 [7680/28137]\n",
      "loss: 2.653237 [8960/28137]\n",
      "loss: 2.653237 [10240/28137]\n",
      "loss: 2.684004 [11520/28137]\n",
      "loss: 2.645540 [12800/28137]\n",
      "loss: 2.645549 [14080/28137]\n",
      "loss: 2.653277 [15360/28137]\n",
      "loss: 2.660933 [16640/28137]\n",
      "loss: 2.668750 [17920/28137]\n",
      "loss: 2.661055 [19200/28137]\n",
      "loss: 2.707312 [20480/28137]\n",
      "loss: 2.676338 [21760/28137]\n",
      "loss: 2.684112 [23040/28137]\n",
      "loss: 2.660926 [24320/28137]\n",
      "loss: 2.691921 [25600/28137]\n",
      "loss: 2.653310 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659839, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 58]\n",
      "loss: 2.653229 [0/28137]\n",
      "loss: 2.676353 [1280/28137]\n",
      "loss: 2.637848 [2560/28137]\n",
      "loss: 2.645540 [3840/28137]\n",
      "loss: 2.645535 [5120/28137]\n",
      "loss: 2.660985 [6400/28137]\n",
      "loss: 2.653233 [7680/28137]\n",
      "loss: 2.668696 [8960/28137]\n",
      "loss: 2.660926 [10240/28137]\n",
      "loss: 2.653226 [11520/28137]\n",
      "loss: 2.661045 [12800/28137]\n",
      "loss: 2.653288 [14080/28137]\n",
      "loss: 2.668709 [15360/28137]\n",
      "loss: 2.691838 [16640/28137]\n",
      "loss: 2.668610 [17920/28137]\n",
      "loss: 2.707338 [19200/28137]\n",
      "loss: 2.637842 [20480/28137]\n",
      "loss: 2.653247 [21760/28137]\n",
      "loss: 2.645554 [23040/28137]\n",
      "loss: 2.637845 [24320/28137]\n",
      "loss: 2.676446 [25600/28137]\n",
      "loss: 2.668813 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659823, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 59]\n",
      "loss: 2.676440 [0/28137]\n",
      "loss: 2.637840 [1280/28137]\n",
      "loss: 2.661006 [2560/28137]\n",
      "loss: 2.668617 [3840/28137]\n",
      "loss: 2.645550 [5120/28137]\n",
      "loss: 2.668609 [6400/28137]\n",
      "loss: 2.668646 [7680/28137]\n",
      "loss: 2.668597 [8960/28137]\n",
      "loss: 2.660908 [10240/28137]\n",
      "loss: 2.645557 [11520/28137]\n",
      "loss: 2.668607 [12800/28137]\n",
      "loss: 2.660906 [14080/28137]\n",
      "loss: 2.660940 [15360/28137]\n",
      "loss: 2.637842 [16640/28137]\n",
      "loss: 2.645544 [17920/28137]\n",
      "loss: 2.691770 [19200/28137]\n",
      "loss: 2.637838 [20480/28137]\n",
      "loss: 2.668649 [21760/28137]\n",
      "loss: 2.668627 [23040/28137]\n",
      "loss: 2.676284 [24320/28137]\n",
      "loss: 2.645652 [25600/28137]\n",
      "loss: 2.676310 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659815, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 60]\n",
      "loss: 2.668624 [0/28137]\n",
      "loss: 2.653233 [1280/28137]\n",
      "loss: 2.645542 [2560/28137]\n",
      "loss: 2.653229 [3840/28137]\n",
      "loss: 2.637844 [5120/28137]\n",
      "loss: 2.676297 [6400/28137]\n",
      "loss: 2.653212 [7680/28137]\n",
      "loss: 2.668614 [8960/28137]\n",
      "loss: 2.660937 [10240/28137]\n",
      "loss: 2.637869 [11520/28137]\n",
      "loss: 2.661015 [12800/28137]\n",
      "loss: 2.699371 [14080/28137]\n",
      "loss: 2.645591 [15360/28137]\n",
      "loss: 2.661050 [16640/28137]\n",
      "loss: 2.653228 [17920/28137]\n",
      "loss: 2.668602 [19200/28137]\n",
      "loss: 2.676306 [20480/28137]\n",
      "loss: 2.660949 [21760/28137]\n",
      "loss: 2.645560 [23040/28137]\n",
      "loss: 2.683985 [24320/28137]\n",
      "loss: 2.645547 [25600/28137]\n",
      "loss: 2.707045 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659809, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 61]\n",
      "loss: 2.645522 [0/28137]\n",
      "loss: 2.660909 [1280/28137]\n",
      "loss: 2.660924 [2560/28137]\n",
      "loss: 2.684129 [3840/28137]\n",
      "loss: 2.660910 [5120/28137]\n",
      "loss: 2.684010 [6400/28137]\n",
      "loss: 2.699420 [7680/28137]\n",
      "loss: 2.676303 [8960/28137]\n",
      "loss: 2.676280 [10240/28137]\n",
      "loss: 2.653223 [11520/28137]\n",
      "loss: 2.660907 [12800/28137]\n",
      "loss: 2.660905 [14080/28137]\n",
      "loss: 2.668628 [15360/28137]\n",
      "loss: 2.660906 [16640/28137]\n",
      "loss: 2.645529 [17920/28137]\n",
      "loss: 2.653215 [19200/28137]\n",
      "loss: 2.676291 [20480/28137]\n",
      "loss: 2.645533 [21760/28137]\n",
      "loss: 2.660924 [23040/28137]\n",
      "loss: 2.660928 [24320/28137]\n",
      "loss: 2.684002 [25600/28137]\n",
      "loss: 2.676293 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659807, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 62]\n",
      "loss: 2.668696 [0/28137]\n",
      "loss: 2.668838 [1280/28137]\n",
      "loss: 2.668721 [2560/28137]\n",
      "loss: 2.676280 [3840/28137]\n",
      "loss: 2.661153 [5120/28137]\n",
      "loss: 2.630146 [6400/28137]\n",
      "loss: 2.668652 [7680/28137]\n",
      "loss: 2.645539 [8960/28137]\n",
      "loss: 2.668756 [10240/28137]\n",
      "loss: 2.653236 [11520/28137]\n",
      "loss: 2.645538 [12800/28137]\n",
      "loss: 2.637833 [14080/28137]\n",
      "loss: 2.653213 [15360/28137]\n",
      "loss: 2.645532 [16640/28137]\n",
      "loss: 2.660918 [17920/28137]\n",
      "loss: 2.660898 [19200/28137]\n",
      "loss: 2.691673 [20480/28137]\n",
      "loss: 2.684006 [21760/28137]\n",
      "loss: 2.637837 [23040/28137]\n",
      "loss: 2.668612 [24320/28137]\n",
      "loss: 2.653217 [25600/28137]\n",
      "loss: 2.653214 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659805, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 63]\n",
      "loss: 2.653344 [0/28137]\n",
      "loss: 2.653229 [1280/28137]\n",
      "loss: 2.660965 [2560/28137]\n",
      "loss: 2.676268 [3840/28137]\n",
      "loss: 2.645533 [5120/28137]\n",
      "loss: 2.668613 [6400/28137]\n",
      "loss: 2.668609 [7680/28137]\n",
      "loss: 2.645530 [8960/28137]\n",
      "loss: 2.660924 [10240/28137]\n",
      "loss: 2.661051 [11520/28137]\n",
      "loss: 2.653226 [12800/28137]\n",
      "loss: 2.637857 [14080/28137]\n",
      "loss: 2.660911 [15360/28137]\n",
      "loss: 2.645543 [16640/28137]\n",
      "loss: 2.660906 [17920/28137]\n",
      "loss: 2.668854 [19200/28137]\n",
      "loss: 2.668619 [20480/28137]\n",
      "loss: 2.676290 [21760/28137]\n",
      "loss: 2.653337 [23040/28137]\n",
      "loss: 2.645526 [24320/28137]\n",
      "loss: 2.660927 [25600/28137]\n",
      "loss: 2.645525 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659802, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 64]\n",
      "loss: 2.660901 [0/28137]\n",
      "loss: 2.676338 [1280/28137]\n",
      "loss: 2.653245 [2560/28137]\n",
      "loss: 2.653212 [3840/28137]\n",
      "loss: 2.660919 [5120/28137]\n",
      "loss: 2.683997 [6400/28137]\n",
      "loss: 2.660962 [7680/28137]\n",
      "loss: 2.645523 [8960/28137]\n",
      "loss: 2.653338 [10240/28137]\n",
      "loss: 2.668604 [11520/28137]\n",
      "loss: 2.653229 [12800/28137]\n",
      "loss: 2.637842 [14080/28137]\n",
      "loss: 2.645533 [15360/28137]\n",
      "loss: 2.653213 [16640/28137]\n",
      "loss: 2.645656 [17920/28137]\n",
      "loss: 2.683965 [19200/28137]\n",
      "loss: 2.668598 [20480/28137]\n",
      "loss: 2.668716 [21760/28137]\n",
      "loss: 2.668600 [23040/28137]\n",
      "loss: 2.691658 [24320/28137]\n",
      "loss: 2.676284 [25600/28137]\n",
      "loss: 2.668589 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659799, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 65]\n",
      "loss: 2.637830 [0/28137]\n",
      "loss: 2.660910 [1280/28137]\n",
      "loss: 2.668595 [2560/28137]\n",
      "loss: 2.676274 [3840/28137]\n",
      "loss: 2.668614 [5120/28137]\n",
      "loss: 2.661015 [6400/28137]\n",
      "loss: 2.660929 [7680/28137]\n",
      "loss: 2.653366 [8960/28137]\n",
      "loss: 2.660898 [10240/28137]\n",
      "loss: 2.653214 [11520/28137]\n",
      "loss: 2.653211 [12800/28137]\n",
      "loss: 2.653216 [14080/28137]\n",
      "loss: 2.660916 [15360/28137]\n",
      "loss: 2.653216 [16640/28137]\n",
      "loss: 2.683971 [17920/28137]\n",
      "loss: 2.676273 [19200/28137]\n",
      "loss: 2.707400 [20480/28137]\n",
      "loss: 2.653211 [21760/28137]\n",
      "loss: 2.660905 [23040/28137]\n",
      "loss: 2.660905 [24320/28137]\n",
      "loss: 2.668583 [25600/28137]\n",
      "loss: 2.683958 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659792, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 66]\n",
      "loss: 2.660890 [0/28137]\n",
      "loss: 2.660902 [1280/28137]\n",
      "loss: 2.645531 [2560/28137]\n",
      "loss: 2.668597 [3840/28137]\n",
      "loss: 2.630146 [5120/28137]\n",
      "loss: 2.683991 [6400/28137]\n",
      "loss: 2.645652 [7680/28137]\n",
      "loss: 2.637833 [8960/28137]\n",
      "loss: 2.645520 [10240/28137]\n",
      "loss: 2.676301 [11520/28137]\n",
      "loss: 2.676278 [12800/28137]\n",
      "loss: 2.660895 [14080/28137]\n",
      "loss: 2.653208 [15360/28137]\n",
      "loss: 2.661030 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.668603 [19200/28137]\n",
      "loss: 2.660906 [20480/28137]\n",
      "loss: 2.660913 [21760/28137]\n",
      "loss: 2.653208 [23040/28137]\n",
      "loss: 2.653211 [24320/28137]\n",
      "loss: 2.653219 [25600/28137]\n",
      "loss: 2.660902 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659800, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 67]\n",
      "loss: 2.668588 [0/28137]\n",
      "loss: 2.660896 [1280/28137]\n",
      "loss: 2.645532 [2560/28137]\n",
      "loss: 2.645523 [3840/28137]\n",
      "loss: 2.645521 [5120/28137]\n",
      "loss: 2.637899 [6400/28137]\n",
      "loss: 2.637832 [7680/28137]\n",
      "loss: 2.683965 [8960/28137]\n",
      "loss: 2.676293 [10240/28137]\n",
      "loss: 2.668574 [11520/28137]\n",
      "loss: 2.653211 [12800/28137]\n",
      "loss: 2.684110 [14080/28137]\n",
      "loss: 2.676412 [15360/28137]\n",
      "loss: 2.668595 [16640/28137]\n",
      "loss: 2.653336 [17920/28137]\n",
      "loss: 2.630147 [19200/28137]\n",
      "loss: 2.660895 [20480/28137]\n",
      "loss: 2.676535 [21760/28137]\n",
      "loss: 2.676277 [23040/28137]\n",
      "loss: 2.653208 [24320/28137]\n",
      "loss: 2.653212 [25600/28137]\n",
      "loss: 2.661027 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659794, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 68]\n",
      "loss: 2.668581 [0/28137]\n",
      "loss: 2.645523 [1280/28137]\n",
      "loss: 2.683961 [2560/28137]\n",
      "loss: 2.645647 [3840/28137]\n",
      "loss: 2.645522 [5120/28137]\n",
      "loss: 2.645534 [6400/28137]\n",
      "loss: 2.668593 [7680/28137]\n",
      "loss: 2.637835 [8960/28137]\n",
      "loss: 2.707022 [10240/28137]\n",
      "loss: 2.630146 [11520/28137]\n",
      "loss: 2.645520 [12800/28137]\n",
      "loss: 2.653208 [14080/28137]\n",
      "loss: 2.707031 [15360/28137]\n",
      "loss: 2.668582 [16640/28137]\n",
      "loss: 2.645523 [17920/28137]\n",
      "loss: 2.684097 [19200/28137]\n",
      "loss: 2.660900 [20480/28137]\n",
      "loss: 2.645523 [21760/28137]\n",
      "loss: 2.637838 [23040/28137]\n",
      "loss: 2.653204 [24320/28137]\n",
      "loss: 2.661030 [25600/28137]\n",
      "loss: 2.637832 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659806, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 69]\n",
      "loss: 2.637833 [0/28137]\n",
      "loss: 2.691644 [1280/28137]\n",
      "loss: 2.668595 [2560/28137]\n",
      "loss: 2.668584 [3840/28137]\n",
      "loss: 2.668581 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.653209 [7680/28137]\n",
      "loss: 2.660899 [8960/28137]\n",
      "loss: 2.668604 [10240/28137]\n",
      "loss: 2.668580 [11520/28137]\n",
      "loss: 2.676267 [12800/28137]\n",
      "loss: 2.683959 [14080/28137]\n",
      "loss: 2.660978 [15360/28137]\n",
      "loss: 2.645527 [16640/28137]\n",
      "loss: 2.637838 [17920/28137]\n",
      "loss: 2.653230 [19200/28137]\n",
      "loss: 2.645531 [20480/28137]\n",
      "loss: 2.668585 [21760/28137]\n",
      "loss: 2.668582 [23040/28137]\n",
      "loss: 2.653213 [24320/28137]\n",
      "loss: 2.645523 [25600/28137]\n",
      "loss: 2.645530 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659805, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 70]\n",
      "loss: 2.653226 [0/28137]\n",
      "loss: 2.630146 [1280/28137]\n",
      "loss: 2.668580 [2560/28137]\n",
      "loss: 2.637831 [3840/28137]\n",
      "loss: 2.653204 [5120/28137]\n",
      "loss: 2.637842 [6400/28137]\n",
      "loss: 2.653203 [7680/28137]\n",
      "loss: 2.676265 [8960/28137]\n",
      "loss: 2.660894 [10240/28137]\n",
      "loss: 2.653213 [11520/28137]\n",
      "loss: 2.660889 [12800/28137]\n",
      "loss: 2.653214 [14080/28137]\n",
      "loss: 2.645524 [15360/28137]\n",
      "loss: 2.668590 [16640/28137]\n",
      "loss: 2.660896 [17920/28137]\n",
      "loss: 2.637833 [19200/28137]\n",
      "loss: 2.660895 [20480/28137]\n",
      "loss: 2.668681 [21760/28137]\n",
      "loss: 2.660904 [23040/28137]\n",
      "loss: 2.661143 [24320/28137]\n",
      "loss: 2.645530 [25600/28137]\n",
      "loss: 2.653217 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659806, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 71]\n",
      "loss: 2.645525 [0/28137]\n",
      "loss: 2.637834 [1280/28137]\n",
      "loss: 2.653209 [2560/28137]\n",
      "loss: 2.676272 [3840/28137]\n",
      "loss: 2.637831 [5120/28137]\n",
      "loss: 2.660888 [6400/28137]\n",
      "loss: 2.676391 [7680/28137]\n",
      "loss: 2.653334 [8960/28137]\n",
      "loss: 2.668581 [10240/28137]\n",
      "loss: 2.676265 [11520/28137]\n",
      "loss: 2.684089 [12800/28137]\n",
      "loss: 2.668583 [14080/28137]\n",
      "loss: 2.653332 [15360/28137]\n",
      "loss: 2.668592 [16640/28137]\n",
      "loss: 2.660902 [17920/28137]\n",
      "loss: 2.660894 [19200/28137]\n",
      "loss: 2.645521 [20480/28137]\n",
      "loss: 2.676281 [21760/28137]\n",
      "loss: 2.660949 [23040/28137]\n",
      "loss: 2.637835 [24320/28137]\n",
      "loss: 2.661017 [25600/28137]\n",
      "loss: 2.653217 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659837, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 72]\n",
      "loss: 2.645647 [0/28137]\n",
      "loss: 2.653203 [1280/28137]\n",
      "loss: 2.645517 [2560/28137]\n",
      "loss: 2.660891 [3840/28137]\n",
      "loss: 2.653206 [5120/28137]\n",
      "loss: 2.645518 [6400/28137]\n",
      "loss: 2.660888 [7680/28137]\n",
      "loss: 2.691631 [8960/28137]\n",
      "loss: 2.660890 [10240/28137]\n",
      "loss: 2.683949 [11520/28137]\n",
      "loss: 2.653340 [12800/28137]\n",
      "loss: 2.676274 [14080/28137]\n",
      "loss: 2.653218 [15360/28137]\n",
      "loss: 2.637836 [16640/28137]\n",
      "loss: 2.653206 [17920/28137]\n",
      "loss: 2.660890 [19200/28137]\n",
      "loss: 2.676388 [20480/28137]\n",
      "loss: 2.645518 [21760/28137]\n",
      "loss: 2.653206 [23040/28137]\n",
      "loss: 2.676269 [24320/28137]\n",
      "loss: 2.668583 [25600/28137]\n",
      "loss: 2.653206 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659816, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 73]\n",
      "loss: 2.645517 [0/28137]\n",
      "loss: 2.676263 [1280/28137]\n",
      "loss: 2.661019 [2560/28137]\n",
      "loss: 2.660919 [3840/28137]\n",
      "loss: 2.676261 [5120/28137]\n",
      "loss: 2.637831 [6400/28137]\n",
      "loss: 2.653207 [7680/28137]\n",
      "loss: 2.676386 [8960/28137]\n",
      "loss: 2.637958 [10240/28137]\n",
      "loss: 2.668576 [11520/28137]\n",
      "loss: 2.668701 [12800/28137]\n",
      "loss: 2.645517 [14080/28137]\n",
      "loss: 2.645532 [15360/28137]\n",
      "loss: 2.683948 [16640/28137]\n",
      "loss: 2.668586 [17920/28137]\n",
      "loss: 2.660901 [19200/28137]\n",
      "loss: 2.653208 [20480/28137]\n",
      "loss: 2.676264 [21760/28137]\n",
      "loss: 2.653210 [23040/28137]\n",
      "loss: 2.660894 [24320/28137]\n",
      "loss: 2.653211 [25600/28137]\n",
      "loss: 2.660897 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659801, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 74]\n",
      "loss: 2.660896 [0/28137]\n",
      "loss: 2.660892 [1280/28137]\n",
      "loss: 2.653334 [2560/28137]\n",
      "loss: 2.668576 [3840/28137]\n",
      "loss: 2.676265 [5120/28137]\n",
      "loss: 2.668579 [6400/28137]\n",
      "loss: 2.645519 [7680/28137]\n",
      "loss: 2.653215 [8960/28137]\n",
      "loss: 2.668577 [10240/28137]\n",
      "loss: 2.637832 [11520/28137]\n",
      "loss: 2.660899 [12800/28137]\n",
      "loss: 2.676274 [14080/28137]\n",
      "loss: 2.676257 [15360/28137]\n",
      "loss: 2.707004 [16640/28137]\n",
      "loss: 2.683957 [17920/28137]\n",
      "loss: 2.660893 [19200/28137]\n",
      "loss: 2.668578 [20480/28137]\n",
      "loss: 2.660891 [21760/28137]\n",
      "loss: 2.637832 [23040/28137]\n",
      "loss: 2.653202 [24320/28137]\n",
      "loss: 2.668826 [25600/28137]\n",
      "loss: 2.676392 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659792, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 75]\n",
      "loss: 2.668576 [0/28137]\n",
      "loss: 2.653202 [1280/28137]\n",
      "loss: 2.683960 [2560/28137]\n",
      "loss: 2.653203 [3840/28137]\n",
      "loss: 2.653202 [5120/28137]\n",
      "loss: 2.699318 [6400/28137]\n",
      "loss: 2.653203 [7680/28137]\n",
      "loss: 2.661017 [8960/28137]\n",
      "loss: 2.668583 [10240/28137]\n",
      "loss: 2.645519 [11520/28137]\n",
      "loss: 2.660895 [12800/28137]\n",
      "loss: 2.653204 [14080/28137]\n",
      "loss: 2.660891 [15360/28137]\n",
      "loss: 2.668576 [16640/28137]\n",
      "loss: 2.653206 [17920/28137]\n",
      "loss: 2.660893 [19200/28137]\n",
      "loss: 2.645518 [20480/28137]\n",
      "loss: 2.653205 [21760/28137]\n",
      "loss: 2.676265 [23040/28137]\n",
      "loss: 2.676278 [24320/28137]\n",
      "loss: 2.653202 [25600/28137]\n",
      "loss: 2.660894 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659791, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 76]\n",
      "loss: 2.653203 [0/28137]\n",
      "loss: 2.653203 [1280/28137]\n",
      "loss: 2.676262 [2560/28137]\n",
      "loss: 2.645516 [3840/28137]\n",
      "loss: 2.668579 [5120/28137]\n",
      "loss: 2.645521 [6400/28137]\n",
      "loss: 2.676394 [7680/28137]\n",
      "loss: 2.645520 [8960/28137]\n",
      "loss: 2.661017 [10240/28137]\n",
      "loss: 2.653203 [11520/28137]\n",
      "loss: 2.676385 [12800/28137]\n",
      "loss: 2.676387 [14080/28137]\n",
      "loss: 2.668577 [15360/28137]\n",
      "loss: 2.676264 [16640/28137]\n",
      "loss: 2.653203 [17920/28137]\n",
      "loss: 2.691633 [19200/28137]\n",
      "loss: 2.653203 [20480/28137]\n",
      "loss: 2.645515 [21760/28137]\n",
      "loss: 2.645520 [23040/28137]\n",
      "loss: 2.660890 [24320/28137]\n",
      "loss: 2.660887 [25600/28137]\n",
      "loss: 2.668828 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659784, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 77]\n",
      "loss: 2.668582 [0/28137]\n",
      "loss: 2.676259 [1280/28137]\n",
      "loss: 2.668573 [2560/28137]\n",
      "loss: 2.668700 [3840/28137]\n",
      "loss: 2.653332 [5120/28137]\n",
      "loss: 2.653204 [6400/28137]\n",
      "loss: 2.645526 [7680/28137]\n",
      "loss: 2.661015 [8960/28137]\n",
      "loss: 2.660890 [10240/28137]\n",
      "loss: 2.676261 [11520/28137]\n",
      "loss: 2.645518 [12800/28137]\n",
      "loss: 2.637830 [14080/28137]\n",
      "loss: 2.645517 [15360/28137]\n",
      "loss: 2.653202 [16640/28137]\n",
      "loss: 2.645517 [17920/28137]\n",
      "loss: 2.660888 [19200/28137]\n",
      "loss: 2.676404 [20480/28137]\n",
      "loss: 2.660889 [21760/28137]\n",
      "loss: 2.637831 [23040/28137]\n",
      "loss: 2.653205 [24320/28137]\n",
      "loss: 2.630146 [25600/28137]\n",
      "loss: 2.637833 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659798, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 78]\n",
      "loss: 2.653337 [0/28137]\n",
      "loss: 2.645517 [1280/28137]\n",
      "loss: 2.661024 [2560/28137]\n",
      "loss: 2.683950 [3840/28137]\n",
      "loss: 2.668578 [5120/28137]\n",
      "loss: 2.660888 [6400/28137]\n",
      "loss: 2.691644 [7680/28137]\n",
      "loss: 2.653205 [8960/28137]\n",
      "loss: 2.653206 [10240/28137]\n",
      "loss: 2.660892 [11520/28137]\n",
      "loss: 2.653211 [12800/28137]\n",
      "loss: 2.653204 [14080/28137]\n",
      "loss: 2.645645 [15360/28137]\n",
      "loss: 2.691640 [16640/28137]\n",
      "loss: 2.661019 [17920/28137]\n",
      "loss: 2.661024 [19200/28137]\n",
      "loss: 2.668701 [20480/28137]\n",
      "loss: 2.676267 [21760/28137]\n",
      "loss: 2.668573 [23040/28137]\n",
      "loss: 2.645520 [24320/28137]\n",
      "loss: 2.684329 [25600/28137]\n",
      "loss: 2.645645 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659780, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 79]\n",
      "loss: 2.637832 [0/28137]\n",
      "loss: 2.653203 [1280/28137]\n",
      "loss: 2.660894 [2560/28137]\n",
      "loss: 2.653203 [3840/28137]\n",
      "loss: 2.653208 [5120/28137]\n",
      "loss: 2.653207 [6400/28137]\n",
      "loss: 2.653202 [7680/28137]\n",
      "loss: 2.668572 [8960/28137]\n",
      "loss: 2.653200 [10240/28137]\n",
      "loss: 2.645515 [11520/28137]\n",
      "loss: 2.653328 [12800/28137]\n",
      "loss: 2.653202 [14080/28137]\n",
      "loss: 2.645519 [15360/28137]\n",
      "loss: 2.660887 [16640/28137]\n",
      "loss: 2.660889 [17920/28137]\n",
      "loss: 2.637830 [19200/28137]\n",
      "loss: 2.684078 [20480/28137]\n",
      "loss: 2.653203 [21760/28137]\n",
      "loss: 2.645516 [23040/28137]\n",
      "loss: 2.653329 [24320/28137]\n",
      "loss: 2.645518 [25600/28137]\n",
      "loss: 2.653205 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659804, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 80]\n",
      "loss: 2.653204 [0/28137]\n",
      "loss: 2.630147 [1280/28137]\n",
      "loss: 2.653202 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.668573 [5120/28137]\n",
      "loss: 2.668574 [6400/28137]\n",
      "loss: 2.645517 [7680/28137]\n",
      "loss: 2.660889 [8960/28137]\n",
      "loss: 2.645518 [10240/28137]\n",
      "loss: 2.668581 [11520/28137]\n",
      "loss: 2.645516 [12800/28137]\n",
      "loss: 2.660890 [14080/28137]\n",
      "loss: 2.683946 [15360/28137]\n",
      "loss: 2.645519 [16640/28137]\n",
      "loss: 2.661015 [17920/28137]\n",
      "loss: 2.668574 [19200/28137]\n",
      "loss: 2.668579 [20480/28137]\n",
      "loss: 2.691630 [21760/28137]\n",
      "loss: 2.645517 [23040/28137]\n",
      "loss: 2.660894 [24320/28137]\n",
      "loss: 2.660888 [25600/28137]\n",
      "loss: 2.683953 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659792, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 81]\n",
      "loss: 2.660887 [0/28137]\n",
      "loss: 2.653203 [1280/28137]\n",
      "loss: 2.660889 [2560/28137]\n",
      "loss: 2.653204 [3840/28137]\n",
      "loss: 2.645519 [5120/28137]\n",
      "loss: 2.645645 [6400/28137]\n",
      "loss: 2.645516 [7680/28137]\n",
      "loss: 2.676394 [8960/28137]\n",
      "loss: 2.645519 [10240/28137]\n",
      "loss: 2.661014 [11520/28137]\n",
      "loss: 2.645521 [12800/28137]\n",
      "loss: 2.668571 [14080/28137]\n",
      "loss: 2.661015 [15360/28137]\n",
      "loss: 2.660887 [16640/28137]\n",
      "loss: 2.645517 [17920/28137]\n",
      "loss: 2.668573 [19200/28137]\n",
      "loss: 2.691758 [20480/28137]\n",
      "loss: 2.653206 [21760/28137]\n",
      "loss: 2.676259 [23040/28137]\n",
      "loss: 2.645518 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.668722 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659789, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 82]\n",
      "loss: 2.676263 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.676257 [2560/28137]\n",
      "loss: 2.668575 [3840/28137]\n",
      "loss: 2.676261 [5120/28137]\n",
      "loss: 2.645516 [6400/28137]\n",
      "loss: 2.660887 [7680/28137]\n",
      "loss: 2.645516 [8960/28137]\n",
      "loss: 2.645516 [10240/28137]\n",
      "loss: 2.653202 [11520/28137]\n",
      "loss: 2.653204 [12800/28137]\n",
      "loss: 2.645519 [14080/28137]\n",
      "loss: 2.637830 [15360/28137]\n",
      "loss: 2.653204 [16640/28137]\n",
      "loss: 2.668576 [17920/28137]\n",
      "loss: 2.645519 [19200/28137]\n",
      "loss: 2.676258 [20480/28137]\n",
      "loss: 2.660892 [21760/28137]\n",
      "loss: 2.653201 [23040/28137]\n",
      "loss: 2.676258 [24320/28137]\n",
      "loss: 2.668699 [25600/28137]\n",
      "loss: 2.676386 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659792, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 83]\n",
      "loss: 2.660887 [0/28137]\n",
      "loss: 2.660887 [1280/28137]\n",
      "loss: 2.645517 [2560/28137]\n",
      "loss: 2.691628 [3840/28137]\n",
      "loss: 2.645515 [5120/28137]\n",
      "loss: 2.645516 [6400/28137]\n",
      "loss: 2.653202 [7680/28137]\n",
      "loss: 2.637836 [8960/28137]\n",
      "loss: 2.668573 [10240/28137]\n",
      "loss: 2.645515 [11520/28137]\n",
      "loss: 2.668573 [12800/28137]\n",
      "loss: 2.668573 [14080/28137]\n",
      "loss: 2.645643 [15360/28137]\n",
      "loss: 2.653203 [16640/28137]\n",
      "loss: 2.660885 [17920/28137]\n",
      "loss: 2.645515 [19200/28137]\n",
      "loss: 2.653204 [20480/28137]\n",
      "loss: 2.660886 [21760/28137]\n",
      "loss: 2.637830 [23040/28137]\n",
      "loss: 2.653205 [24320/28137]\n",
      "loss: 2.637830 [25600/28137]\n",
      "loss: 2.668571 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659780, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 84]\n",
      "loss: 2.668571 [0/28137]\n",
      "loss: 2.668571 [1280/28137]\n",
      "loss: 2.668701 [2560/28137]\n",
      "loss: 2.691753 [3840/28137]\n",
      "loss: 2.683941 [5120/28137]\n",
      "loss: 2.653201 [6400/28137]\n",
      "loss: 2.676256 [7680/28137]\n",
      "loss: 2.699311 [8960/28137]\n",
      "loss: 2.676256 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.653205 [12800/28137]\n",
      "loss: 2.653203 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.660886 [16640/28137]\n",
      "loss: 2.637831 [17920/28137]\n",
      "loss: 2.645515 [19200/28137]\n",
      "loss: 2.676258 [20480/28137]\n",
      "loss: 2.653200 [21760/28137]\n",
      "loss: 2.637831 [23040/28137]\n",
      "loss: 2.668698 [24320/28137]\n",
      "loss: 2.683942 [25600/28137]\n",
      "loss: 2.653202 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659794, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 85]\n",
      "loss: 2.668574 [0/28137]\n",
      "loss: 2.668573 [1280/28137]\n",
      "loss: 2.660886 [2560/28137]\n",
      "loss: 2.660885 [3840/28137]\n",
      "loss: 2.653327 [5120/28137]\n",
      "loss: 2.668570 [6400/28137]\n",
      "loss: 2.637827 [7680/28137]\n",
      "loss: 2.668571 [8960/28137]\n",
      "loss: 2.645516 [10240/28137]\n",
      "loss: 2.653201 [11520/28137]\n",
      "loss: 2.676260 [12800/28137]\n",
      "loss: 2.668574 [14080/28137]\n",
      "loss: 2.668576 [15360/28137]\n",
      "loss: 2.653204 [16640/28137]\n",
      "loss: 2.645515 [17920/28137]\n",
      "loss: 2.645515 [19200/28137]\n",
      "loss: 2.660888 [20480/28137]\n",
      "loss: 2.653202 [21760/28137]\n",
      "loss: 2.668571 [23040/28137]\n",
      "loss: 2.668699 [24320/28137]\n",
      "loss: 2.676257 [25600/28137]\n",
      "loss: 2.637831 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659779, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 86]\n",
      "loss: 2.668575 [0/28137]\n",
      "loss: 2.653201 [1280/28137]\n",
      "loss: 2.691629 [2560/28137]\n",
      "loss: 2.660891 [3840/28137]\n",
      "loss: 2.668577 [5120/28137]\n",
      "loss: 2.653200 [6400/28137]\n",
      "loss: 2.653330 [7680/28137]\n",
      "loss: 2.645516 [8960/28137]\n",
      "loss: 2.668701 [10240/28137]\n",
      "loss: 2.653202 [11520/28137]\n",
      "loss: 2.637830 [12800/28137]\n",
      "loss: 2.676258 [14080/28137]\n",
      "loss: 2.637830 [15360/28137]\n",
      "loss: 2.676256 [16640/28137]\n",
      "loss: 2.645515 [17920/28137]\n",
      "loss: 2.645515 [19200/28137]\n",
      "loss: 2.683942 [20480/28137]\n",
      "loss: 2.661014 [21760/28137]\n",
      "loss: 2.653329 [23040/28137]\n",
      "loss: 2.660889 [24320/28137]\n",
      "loss: 2.660886 [25600/28137]\n",
      "loss: 2.676383 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659791, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 87]\n",
      "loss: 2.660887 [0/28137]\n",
      "loss: 2.660886 [1280/28137]\n",
      "loss: 2.668571 [2560/28137]\n",
      "loss: 2.645516 [3840/28137]\n",
      "loss: 2.645517 [5120/28137]\n",
      "loss: 2.645521 [6400/28137]\n",
      "loss: 2.684106 [7680/28137]\n",
      "loss: 2.676657 [8960/28137]\n",
      "loss: 2.647411 [10240/28137]\n",
      "loss: 2.663480 [11520/28137]\n",
      "loss: 2.704969 [12800/28137]\n",
      "loss: 2.678689 [14080/28137]\n",
      "loss: 2.646655 [15360/28137]\n",
      "loss: 2.668830 [16640/28137]\n",
      "loss: 2.656999 [17920/28137]\n",
      "loss: 2.692085 [19200/28137]\n",
      "loss: 2.654458 [20480/28137]\n",
      "loss: 2.653444 [21760/28137]\n",
      "loss: 2.661345 [23040/28137]\n",
      "loss: 2.676466 [24320/28137]\n",
      "loss: 2.645880 [25600/28137]\n",
      "loss: 2.692102 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.661351, Accuracy: 3608/3725 (96.9%)\n",
      "\n",
      "\n",
      "[Epoch 88]\n",
      "loss: 2.653589 [0/28137]\n",
      "loss: 2.660958 [1280/28137]\n",
      "loss: 2.668814 [2560/28137]\n",
      "loss: 2.653390 [3840/28137]\n",
      "loss: 2.668835 [5120/28137]\n",
      "loss: 2.676403 [6400/28137]\n",
      "loss: 2.676364 [7680/28137]\n",
      "loss: 2.653237 [8960/28137]\n",
      "loss: 2.676548 [10240/28137]\n",
      "loss: 2.653252 [11520/28137]\n",
      "loss: 2.630160 [12800/28137]\n",
      "loss: 2.653230 [14080/28137]\n",
      "loss: 2.660958 [15360/28137]\n",
      "loss: 2.653265 [16640/28137]\n",
      "loss: 2.653236 [17920/28137]\n",
      "loss: 2.660992 [19200/28137]\n",
      "loss: 2.645536 [20480/28137]\n",
      "loss: 2.660933 [21760/28137]\n",
      "loss: 2.653262 [23040/28137]\n",
      "loss: 2.669006 [24320/28137]\n",
      "loss: 2.637862 [25600/28137]\n",
      "loss: 2.668609 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660031, Accuracy: 3612/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 89]\n",
      "loss: 2.660914 [0/28137]\n",
      "loss: 2.653227 [1280/28137]\n",
      "loss: 2.645524 [2560/28137]\n",
      "loss: 2.653245 [3840/28137]\n",
      "loss: 2.683989 [5120/28137]\n",
      "loss: 2.630524 [6400/28137]\n",
      "loss: 2.630944 [7680/28137]\n",
      "loss: 2.630166 [8960/28137]\n",
      "loss: 2.637958 [10240/28137]\n",
      "loss: 2.630165 [11520/28137]\n",
      "loss: 2.638335 [12800/28137]\n",
      "loss: 2.630163 [14080/28137]\n",
      "loss: 2.637645 [15360/28137]\n",
      "loss: 2.630167 [16640/28137]\n",
      "loss: 2.634135 [17920/28137]\n",
      "loss: 2.630242 [19200/28137]\n",
      "loss: 2.630148 [20480/28137]\n",
      "loss: 2.630150 [21760/28137]\n",
      "loss: 2.630153 [23040/28137]\n",
      "loss: 2.630202 [24320/28137]\n",
      "loss: 2.637756 [25600/28137]\n",
      "loss: 2.630151 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631842, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 90]\n",
      "loss: 2.630167 [0/28137]\n",
      "loss: 2.630231 [1280/28137]\n",
      "loss: 2.630152 [2560/28137]\n",
      "loss: 2.630152 [3840/28137]\n",
      "loss: 2.637971 [5120/28137]\n",
      "loss: 2.630146 [6400/28137]\n",
      "loss: 2.630157 [7680/28137]\n",
      "loss: 2.630166 [8960/28137]\n",
      "loss: 2.630150 [10240/28137]\n",
      "loss: 2.630162 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.637960 [14080/28137]\n",
      "loss: 2.630155 [15360/28137]\n",
      "loss: 2.630150 [16640/28137]\n",
      "loss: 2.630449 [17920/28137]\n",
      "loss: 2.630150 [19200/28137]\n",
      "loss: 2.630177 [20480/28137]\n",
      "loss: 2.630150 [21760/28137]\n",
      "loss: 2.630336 [23040/28137]\n",
      "loss: 2.636147 [24320/28137]\n",
      "loss: 2.630453 [25600/28137]\n",
      "loss: 2.630174 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.632157, Accuracy: 3718/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 91]\n",
      "loss: 2.637958 [0/28137]\n",
      "loss: 2.630382 [1280/28137]\n",
      "loss: 2.630167 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.630146 [5120/28137]\n",
      "loss: 2.630151 [6400/28137]\n",
      "loss: 2.637960 [7680/28137]\n",
      "loss: 2.630150 [8960/28137]\n",
      "loss: 2.630146 [10240/28137]\n",
      "loss: 2.630147 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.630149 [14080/28137]\n",
      "loss: 2.630148 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630147 [17920/28137]\n",
      "loss: 2.630152 [19200/28137]\n",
      "loss: 2.637959 [20480/28137]\n",
      "loss: 2.630156 [21760/28137]\n",
      "loss: 2.630146 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630146 [25600/28137]\n",
      "loss: 2.634600 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.632048, Accuracy: 3718/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 92]\n",
      "loss: 2.630156 [0/28137]\n",
      "loss: 2.630156 [1280/28137]\n",
      "loss: 2.630196 [2560/28137]\n",
      "loss: 2.638203 [3840/28137]\n",
      "loss: 2.630153 [5120/28137]\n",
      "loss: 2.630147 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630146 [8960/28137]\n",
      "loss: 2.630147 [10240/28137]\n",
      "loss: 2.630157 [11520/28137]\n",
      "loss: 2.637961 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630149 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630149 [17920/28137]\n",
      "loss: 2.630146 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630178 [23040/28137]\n",
      "loss: 2.630146 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630151 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631792, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 93]\n",
      "loss: 2.637959 [0/28137]\n",
      "loss: 2.637957 [1280/28137]\n",
      "loss: 2.637959 [2560/28137]\n",
      "loss: 2.630146 [3840/28137]\n",
      "loss: 2.630145 [5120/28137]\n",
      "loss: 2.630165 [6400/28137]\n",
      "loss: 2.630147 [7680/28137]\n",
      "loss: 2.630149 [8960/28137]\n",
      "loss: 2.637959 [10240/28137]\n",
      "loss: 2.630151 [11520/28137]\n",
      "loss: 2.637958 [12800/28137]\n",
      "loss: 2.630150 [14080/28137]\n",
      "loss: 2.630150 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630145 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630146 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630147 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631756, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 94]\n",
      "loss: 2.630150 [0/28137]\n",
      "loss: 2.630147 [1280/28137]\n",
      "loss: 2.630147 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.630145 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.637962 [7680/28137]\n",
      "loss: 2.630146 [8960/28137]\n",
      "loss: 2.630145 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.630148 [12800/28137]\n",
      "loss: 2.630151 [14080/28137]\n",
      "loss: 2.630146 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630150 [19200/28137]\n",
      "loss: 2.630146 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.637963 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631741, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 95]\n",
      "loss: 2.630146 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.630146 [2560/28137]\n",
      "loss: 2.637958 [3840/28137]\n",
      "loss: 2.630148 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.637957 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.630146 [12800/28137]\n",
      "loss: 2.637957 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630146 [17920/28137]\n",
      "loss: 2.637962 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.637958 [21760/28137]\n",
      "loss: 2.630153 [23040/28137]\n",
      "loss: 2.630146 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630146 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631706, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "[Epoch 96]\n",
      "loss: 2.630146 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.637957 [5120/28137]\n",
      "loss: 2.630146 [6400/28137]\n",
      "loss: 2.645770 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.630147 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.637961 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630147 [19200/28137]\n",
      "loss: 2.637957 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630146 [24320/28137]\n",
      "loss: 2.630148 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631699, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "[Epoch 97]\n",
      "loss: 2.630145 [0/28137]\n",
      "loss: 2.630146 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630148 [3840/28137]\n",
      "loss: 2.630147 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.630147 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630147 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630146 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631697, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "[Epoch 98]\n",
      "loss: 2.630145 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.637957 [5120/28137]\n",
      "loss: 2.637959 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.637957 [10240/28137]\n",
      "loss: 2.630148 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630145 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630149 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631717, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 99]\n",
      "loss: 2.630145 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.630145 [5120/28137]\n",
      "loss: 2.637957 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.630145 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630146 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.637958 [17920/28137]\n",
      "loss: 2.637957 [19200/28137]\n",
      "loss: 2.630146 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630149 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631673, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "[Epoch 100]\n",
      "loss: 2.630145 [0/28137]\n",
      "loss: 2.630147 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.630145 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.645770 [8960/28137]\n",
      "loss: 2.630145 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.637957 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630147 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.637958 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631676, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "Done!\n",
      "Training time: 1996.3672\n"
     ]
    }
   ],
   "source": [
    "## Training Operation ##\n",
    "start = time.time()\n",
    "for t in range(epochs):\n",
    "  print(f\"\\n[Epoch {t+1}]\")\n",
    "  train(train_dataloader, model, loss_fn, optimizer)\n",
    "  validation(model, val_dataloader)\n",
    "print(\"\\nDone!\")\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: {:.4f}\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Test Result***\n",
      "Average loss: 2.631368, Accuracy: 3556/3560 (99.9%)\n",
      "\n",
      "Test time: 2.5128\n"
     ]
    }
   ],
   "source": [
    "## Test operation ##\n",
    "start = time.time()\n",
    "test(model, test_dataloader)\n",
    "end = time.time()\n",
    "print(\"Test time: {:.4f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(model, './model_231204_64x64.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Test Result***\n",
      "Average loss: 2.631369, Accuracy: 3556/3560 (99.9%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model(test_dataloader, model_path='./model_231204_64x64.pt'):\n",
    "    model = torch.load(model_path)\n",
    "    test(model, test_dataloader)\n",
    "\n",
    "\n",
    "test_model(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
