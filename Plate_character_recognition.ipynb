{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wonjoon_LAB\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Wonjoon_LAB\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, CenterCrop, Grayscale\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dataset as data\n",
    "import model as md\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "Batch_size = 128\n",
    "Optimizer_type = 'ADAM'\n",
    "Learning_rate = 1e-4\n",
    "Weight_decay = 0\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Sample_visualize(dataloader) :\n",
    "  ## Visualize some preprocess images\n",
    "  ##\n",
    "  ## Input : dataloader of image dataset\n",
    "  ## Output : image plots\n",
    "\n",
    " dataiter = iter(dataloader)\n",
    " images, labels = next(dataiter)\n",
    " # images = images.numpy()\n",
    " for i in range (2) :\n",
    "   plt.subplot(1,4,i+1)\n",
    "   plt.imshow(images[i].reshape((64, 64)), cmap='gray')\n",
    "   plt.xticks([])\n",
    "   plt.yticks([])\n",
    "   print(labels[i])\n",
    "\n",
    "# def visualize_dataset(dataset):\n",
    "#   ## Visualize some preprocess images\n",
    "#   ##\n",
    "#   ## Input : DATASET of image dataset\n",
    "#   ## Output : image plots\n",
    "#   images, labels = dataset[0]\n",
    "#   print(images.size())\n",
    "#   images = images.numpy()\n",
    "#   plt.imshow(images.reshape((64, 192)), cmap='gray')\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])\n",
    "#   print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform_set = Compose([Resize((64, 64)),\n",
    "                Grayscale(),\n",
    "                ToTensor(),\n",
    "                Normalize((0.5), (0.5))])\n",
    "train_data = datasets.ImageFolder(root = \"./CNN_letter_dataset\", transform=transform_set)\n",
    "val_data = datasets.ImageFolder(root = \"./CNN_letter_dataset_val\", transform=transform_set)\n",
    "test_data = datasets.ImageFolder(root = \"./CNN_letter_dataset_test\", transform=transform_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=Batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=Batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=Batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "tensor(27)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize_dataset(full_dataset)\n",
    "Sample_visualize(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 48, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(48, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=9216, out_features=100, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=100, out_features=6, bias=True)\n",
      "    (16): ReLU()\n",
      "  )\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (output0): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=36, bias=True)\n",
      "    (5): Softmax(dim=1)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = md.CNN(init_weights=True)\n",
    "model.to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# import torchsummary\n",
    "#\n",
    "# torchsummary.summary(model,input_size=(1,128,128))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "if Optimizer_type == 'ADAM' :\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)\n",
    "elif Optimizer_type == 'SGD' :\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "## Training function ##\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  for batch_idx, (X,y) in enumerate(dataloader):\n",
    "\n",
    "    X = X.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 10 == 0:\n",
    "      print('loss: {:.6f} [{}/{}]'.format(loss.item(), batch_idx*len(X), len(dataloader.dataset)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "## Validation function ##\n",
    "def validation(model, valdata):\n",
    "  ## Input : trained model, validation data\n",
    "  ## Output : validation loss\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in valdata:\n",
    "      X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "      output = model(X)\n",
    "      val_loss += nn.functional.cross_entropy(output, y, reduction='sum').item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "  val_loss /= len(valdata.dataset)\n",
    "  print('\\n***Validation Result***\\nAverage loss: {:.6f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(val_loss, correct, len(valdata.dataset), 100*correct/len(valdata.dataset)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def test(model, testdata):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in testdata:\n",
    "      X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "      output = model(X)\n",
    "      test_loss += nn.functional.cross_entropy(output, y, reduction='sum').item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "  test_loss /= len(testdata.dataset)\n",
    "  print('\\n***Test Result***\\nAverage loss: {:.6f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(test_loss, correct, len(testdata.dataset), 100*correct/len(testdata.dataset)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1]\n",
      "loss: 3.583456 [0/28137]\n",
      "loss: 3.581937 [1280/28137]\n",
      "loss: 3.580296 [2560/28137]\n",
      "loss: 3.574789 [3840/28137]\n",
      "loss: 3.553074 [5120/28137]\n",
      "loss: 3.561317 [6400/28137]\n",
      "loss: 3.517924 [7680/28137]\n",
      "loss: 3.422583 [8960/28137]\n",
      "loss: 3.406873 [10240/28137]\n",
      "loss: 3.357132 [11520/28137]\n",
      "loss: 3.309019 [12800/28137]\n",
      "loss: 3.231928 [14080/28137]\n",
      "loss: 3.204044 [15360/28137]\n",
      "loss: 3.125409 [16640/28137]\n",
      "loss: 3.054138 [17920/28137]\n",
      "loss: 3.056072 [19200/28137]\n",
      "loss: 2.988724 [20480/28137]\n",
      "loss: 2.952680 [21760/28137]\n",
      "loss: 3.022579 [23040/28137]\n",
      "loss: 2.960729 [24320/28137]\n",
      "loss: 2.986450 [25600/28137]\n",
      "loss: 2.976393 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.950520, Accuracy: 2608/3725 (70.0%)\n",
      "\n",
      "\n",
      "[Epoch 2]\n",
      "loss: 3.019421 [0/28137]\n",
      "loss: 2.954722 [1280/28137]\n",
      "loss: 2.884555 [2560/28137]\n",
      "loss: 3.030730 [3840/28137]\n",
      "loss: 2.958452 [5120/28137]\n",
      "loss: 2.920346 [6400/28137]\n",
      "loss: 2.900079 [7680/28137]\n",
      "loss: 2.919972 [8960/28137]\n",
      "loss: 2.912784 [10240/28137]\n",
      "loss: 2.932488 [11520/28137]\n",
      "loss: 2.886800 [12800/28137]\n",
      "loss: 2.814093 [14080/28137]\n",
      "loss: 2.865043 [15360/28137]\n",
      "loss: 2.850131 [16640/28137]\n",
      "loss: 2.893934 [17920/28137]\n",
      "loss: 2.944741 [19200/28137]\n",
      "loss: 2.967465 [20480/28137]\n",
      "loss: 2.884052 [21760/28137]\n",
      "loss: 2.867746 [23040/28137]\n",
      "loss: 2.966356 [24320/28137]\n",
      "loss: 2.846508 [25600/28137]\n",
      "loss: 2.853329 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.888695, Accuracy: 2771/3725 (74.4%)\n",
      "\n",
      "\n",
      "[Epoch 3]\n",
      "loss: 2.903482 [0/28137]\n",
      "loss: 2.820941 [1280/28137]\n",
      "loss: 2.906704 [2560/28137]\n",
      "loss: 2.897191 [3840/28137]\n",
      "loss: 2.869168 [5120/28137]\n",
      "loss: 2.880783 [6400/28137]\n",
      "loss: 2.899401 [7680/28137]\n",
      "loss: 2.840990 [8960/28137]\n",
      "loss: 2.899153 [10240/28137]\n",
      "loss: 2.851241 [11520/28137]\n",
      "loss: 2.813651 [12800/28137]\n",
      "loss: 2.860834 [14080/28137]\n",
      "loss: 2.848791 [15360/28137]\n",
      "loss: 2.857989 [16640/28137]\n",
      "loss: 2.837467 [17920/28137]\n",
      "loss: 2.850530 [19200/28137]\n",
      "loss: 2.880674 [20480/28137]\n",
      "loss: 2.912458 [21760/28137]\n",
      "loss: 2.857944 [23040/28137]\n",
      "loss: 2.857522 [24320/28137]\n",
      "loss: 2.843245 [25600/28137]\n",
      "loss: 2.900459 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.861823, Accuracy: 2876/3725 (77.2%)\n",
      "\n",
      "\n",
      "[Epoch 4]\n",
      "loss: 2.865678 [0/28137]\n",
      "loss: 2.804760 [1280/28137]\n",
      "loss: 2.909314 [2560/28137]\n",
      "loss: 2.888559 [3840/28137]\n",
      "loss: 2.816385 [5120/28137]\n",
      "loss: 2.898830 [6400/28137]\n",
      "loss: 2.888501 [7680/28137]\n",
      "loss: 2.902429 [8960/28137]\n",
      "loss: 2.969570 [10240/28137]\n",
      "loss: 2.908548 [11520/28137]\n",
      "loss: 2.862315 [12800/28137]\n",
      "loss: 2.922379 [14080/28137]\n",
      "loss: 2.846122 [15360/28137]\n",
      "loss: 2.828088 [16640/28137]\n",
      "loss: 2.823675 [17920/28137]\n",
      "loss: 2.863627 [19200/28137]\n",
      "loss: 2.814215 [20480/28137]\n",
      "loss: 2.833409 [21760/28137]\n",
      "loss: 2.842393 [23040/28137]\n",
      "loss: 2.876488 [24320/28137]\n",
      "loss: 2.927988 [25600/28137]\n",
      "loss: 2.907780 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.855715, Accuracy: 2890/3725 (77.6%)\n",
      "\n",
      "\n",
      "[Epoch 5]\n",
      "loss: 2.867235 [0/28137]\n",
      "loss: 2.887210 [1280/28137]\n",
      "loss: 2.818027 [2560/28137]\n",
      "loss: 2.826123 [3840/28137]\n",
      "loss: 2.904341 [5120/28137]\n",
      "loss: 2.840413 [6400/28137]\n",
      "loss: 2.832671 [7680/28137]\n",
      "loss: 2.835662 [8960/28137]\n",
      "loss: 2.864237 [10240/28137]\n",
      "loss: 2.864661 [11520/28137]\n",
      "loss: 2.888954 [12800/28137]\n",
      "loss: 2.896357 [14080/28137]\n",
      "loss: 2.816955 [15360/28137]\n",
      "loss: 2.856391 [16640/28137]\n",
      "loss: 2.803767 [17920/28137]\n",
      "loss: 2.796595 [19200/28137]\n",
      "loss: 2.949944 [20480/28137]\n",
      "loss: 2.848594 [21760/28137]\n",
      "loss: 2.865152 [23040/28137]\n",
      "loss: 2.903319 [24320/28137]\n",
      "loss: 2.832639 [25600/28137]\n",
      "loss: 2.832716 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.852176, Accuracy: 2897/3725 (77.8%)\n",
      "\n",
      "\n",
      "[Epoch 6]\n",
      "loss: 2.848246 [0/28137]\n",
      "loss: 2.833201 [1280/28137]\n",
      "loss: 2.903107 [2560/28137]\n",
      "loss: 2.888056 [3840/28137]\n",
      "loss: 2.928719 [5120/28137]\n",
      "loss: 2.809724 [6400/28137]\n",
      "loss: 2.827636 [7680/28137]\n",
      "loss: 2.864009 [8960/28137]\n",
      "loss: 2.801461 [10240/28137]\n",
      "loss: 2.887007 [11520/28137]\n",
      "loss: 2.801817 [12800/28137]\n",
      "loss: 2.840854 [14080/28137]\n",
      "loss: 2.886908 [15360/28137]\n",
      "loss: 2.849449 [16640/28137]\n",
      "loss: 2.804399 [17920/28137]\n",
      "loss: 2.888039 [19200/28137]\n",
      "loss: 2.834988 [20480/28137]\n",
      "loss: 2.860116 [21760/28137]\n",
      "loss: 2.840300 [23040/28137]\n",
      "loss: 2.856735 [24320/28137]\n",
      "loss: 2.840308 [25600/28137]\n",
      "loss: 2.864893 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.852273, Accuracy: 2898/3725 (77.8%)\n",
      "\n",
      "\n",
      "[Epoch 7]\n",
      "loss: 2.840403 [0/28137]\n",
      "loss: 2.825103 [1280/28137]\n",
      "loss: 2.895182 [2560/28137]\n",
      "loss: 2.927735 [3840/28137]\n",
      "loss: 2.933813 [5120/28137]\n",
      "loss: 2.816651 [6400/28137]\n",
      "loss: 2.827375 [7680/28137]\n",
      "loss: 2.914317 [8960/28137]\n",
      "loss: 2.871436 [10240/28137]\n",
      "loss: 2.840450 [11520/28137]\n",
      "loss: 2.863686 [12800/28137]\n",
      "loss: 2.915060 [14080/28137]\n",
      "loss: 2.824672 [15360/28137]\n",
      "loss: 2.844927 [16640/28137]\n",
      "loss: 2.880044 [17920/28137]\n",
      "loss: 2.840256 [19200/28137]\n",
      "loss: 2.880329 [20480/28137]\n",
      "loss: 2.838191 [21760/28137]\n",
      "loss: 2.840268 [23040/28137]\n",
      "loss: 2.925722 [24320/28137]\n",
      "loss: 2.871476 [25600/28137]\n",
      "loss: 2.918139 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.850711, Accuracy: 2903/3725 (77.9%)\n",
      "\n",
      "\n",
      "[Epoch 8]\n",
      "loss: 2.903506 [0/28137]\n",
      "loss: 2.821601 [1280/28137]\n",
      "loss: 2.882194 [2560/28137]\n",
      "loss: 2.833138 [3840/28137]\n",
      "loss: 2.872044 [5120/28137]\n",
      "loss: 2.915656 [6400/28137]\n",
      "loss: 2.832235 [7680/28137]\n",
      "loss: 2.840273 [8960/28137]\n",
      "loss: 2.902572 [10240/28137]\n",
      "loss: 2.824995 [11520/28137]\n",
      "loss: 2.801181 [12800/28137]\n",
      "loss: 2.872972 [14080/28137]\n",
      "loss: 2.865457 [15360/28137]\n",
      "loss: 2.879426 [16640/28137]\n",
      "loss: 2.856236 [17920/28137]\n",
      "loss: 2.871561 [19200/28137]\n",
      "loss: 2.886887 [20480/28137]\n",
      "loss: 2.832721 [21760/28137]\n",
      "loss: 2.828876 [23040/28137]\n",
      "loss: 2.918766 [24320/28137]\n",
      "loss: 2.813167 [25600/28137]\n",
      "loss: 2.887522 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.850010, Accuracy: 2904/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 9]\n",
      "loss: 2.847889 [0/28137]\n",
      "loss: 2.769912 [1280/28137]\n",
      "loss: 2.904747 [2560/28137]\n",
      "loss: 2.888562 [3840/28137]\n",
      "loss: 2.863482 [5120/28137]\n",
      "loss: 2.871051 [6400/28137]\n",
      "loss: 2.840212 [7680/28137]\n",
      "loss: 2.933236 [8960/28137]\n",
      "loss: 2.816832 [10240/28137]\n",
      "loss: 2.871135 [11520/28137]\n",
      "loss: 2.816514 [12800/28137]\n",
      "loss: 2.816591 [14080/28137]\n",
      "loss: 2.800910 [15360/28137]\n",
      "loss: 2.839729 [16640/28137]\n",
      "loss: 2.785466 [17920/28137]\n",
      "loss: 2.878978 [19200/28137]\n",
      "loss: 2.886729 [20480/28137]\n",
      "loss: 2.847700 [21760/28137]\n",
      "loss: 2.847842 [23040/28137]\n",
      "loss: 2.903052 [24320/28137]\n",
      "loss: 2.878728 [25600/28137]\n",
      "loss: 2.820427 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.849847, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 10]\n",
      "loss: 2.855488 [0/28137]\n",
      "loss: 2.839886 [1280/28137]\n",
      "loss: 2.855962 [2560/28137]\n",
      "loss: 2.793249 [3840/28137]\n",
      "loss: 2.818948 [5120/28137]\n",
      "loss: 2.894879 [6400/28137]\n",
      "loss: 2.863884 [7680/28137]\n",
      "loss: 2.911508 [8960/28137]\n",
      "loss: 2.863427 [10240/28137]\n",
      "loss: 2.878283 [11520/28137]\n",
      "loss: 2.933979 [12800/28137]\n",
      "loss: 2.903628 [14080/28137]\n",
      "loss: 2.826122 [15360/28137]\n",
      "loss: 2.791759 [16640/28137]\n",
      "loss: 2.887366 [17920/28137]\n",
      "loss: 2.833482 [19200/28137]\n",
      "loss: 2.840781 [20480/28137]\n",
      "loss: 2.837514 [21760/28137]\n",
      "loss: 2.864120 [23040/28137]\n",
      "loss: 2.886861 [24320/28137]\n",
      "loss: 2.878721 [25600/28137]\n",
      "loss: 2.832087 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.849697, Accuracy: 2902/3725 (77.9%)\n",
      "\n",
      "\n",
      "[Epoch 11]\n",
      "loss: 2.808933 [0/28137]\n",
      "loss: 2.923514 [1280/28137]\n",
      "loss: 2.932823 [2560/28137]\n",
      "loss: 2.816764 [3840/28137]\n",
      "loss: 2.855540 [5120/28137]\n",
      "loss: 2.855790 [6400/28137]\n",
      "loss: 2.800941 [7680/28137]\n",
      "loss: 2.777808 [8960/28137]\n",
      "loss: 2.886347 [10240/28137]\n",
      "loss: 2.824612 [11520/28137]\n",
      "loss: 2.856146 [12800/28137]\n",
      "loss: 2.886414 [14080/28137]\n",
      "loss: 2.816603 [15360/28137]\n",
      "loss: 2.893945 [16640/28137]\n",
      "loss: 2.862867 [17920/28137]\n",
      "loss: 2.832453 [19200/28137]\n",
      "loss: 2.911126 [20480/28137]\n",
      "loss: 2.887613 [21760/28137]\n",
      "loss: 2.887130 [23040/28137]\n",
      "loss: 2.824683 [24320/28137]\n",
      "loss: 2.870697 [25600/28137]\n",
      "loss: 2.862991 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848985, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 12]\n",
      "loss: 2.886297 [0/28137]\n",
      "loss: 2.855146 [1280/28137]\n",
      "loss: 2.824345 [2560/28137]\n",
      "loss: 2.886095 [3840/28137]\n",
      "loss: 2.839768 [5120/28137]\n",
      "loss: 2.824240 [6400/28137]\n",
      "loss: 2.816462 [7680/28137]\n",
      "loss: 2.832365 [8960/28137]\n",
      "loss: 2.948172 [10240/28137]\n",
      "loss: 2.871528 [11520/28137]\n",
      "loss: 2.847196 [12800/28137]\n",
      "loss: 2.823905 [14080/28137]\n",
      "loss: 2.901002 [15360/28137]\n",
      "loss: 2.862266 [16640/28137]\n",
      "loss: 2.793204 [17920/28137]\n",
      "loss: 2.820988 [19200/28137]\n",
      "loss: 2.898697 [20480/28137]\n",
      "loss: 2.855203 [21760/28137]\n",
      "loss: 2.855896 [23040/28137]\n",
      "loss: 2.886477 [24320/28137]\n",
      "loss: 2.809013 [25600/28137]\n",
      "loss: 2.831924 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.849097, Accuracy: 2904/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 13]\n",
      "loss: 2.854835 [0/28137]\n",
      "loss: 2.831387 [1280/28137]\n",
      "loss: 2.885494 [2560/28137]\n",
      "loss: 2.916943 [3840/28137]\n",
      "loss: 2.839371 [5120/28137]\n",
      "loss: 2.862534 [6400/28137]\n",
      "loss: 2.832262 [7680/28137]\n",
      "loss: 2.862669 [8960/28137]\n",
      "loss: 2.785223 [10240/28137]\n",
      "loss: 2.932606 [11520/28137]\n",
      "loss: 2.854865 [12800/28137]\n",
      "loss: 2.909371 [14080/28137]\n",
      "loss: 2.785200 [15360/28137]\n",
      "loss: 2.862730 [16640/28137]\n",
      "loss: 2.808346 [17920/28137]\n",
      "loss: 2.886093 [19200/28137]\n",
      "loss: 2.909438 [20480/28137]\n",
      "loss: 2.872084 [21760/28137]\n",
      "loss: 2.847121 [23040/28137]\n",
      "loss: 2.769908 [24320/28137]\n",
      "loss: 2.823936 [25600/28137]\n",
      "loss: 2.909117 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848487, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 14]\n",
      "loss: 2.870141 [0/28137]\n",
      "loss: 2.886098 [1280/28137]\n",
      "loss: 2.854771 [2560/28137]\n",
      "loss: 2.862781 [3840/28137]\n",
      "loss: 2.870224 [5120/28137]\n",
      "loss: 2.877919 [6400/28137]\n",
      "loss: 2.862612 [7680/28137]\n",
      "loss: 2.893512 [8960/28137]\n",
      "loss: 2.839843 [10240/28137]\n",
      "loss: 2.885823 [11520/28137]\n",
      "loss: 2.862785 [12800/28137]\n",
      "loss: 2.870290 [14080/28137]\n",
      "loss: 2.916719 [15360/28137]\n",
      "loss: 2.800899 [16640/28137]\n",
      "loss: 2.932125 [17920/28137]\n",
      "loss: 2.854815 [19200/28137]\n",
      "loss: 2.831835 [20480/28137]\n",
      "loss: 2.808204 [21760/28137]\n",
      "loss: 2.893519 [23040/28137]\n",
      "loss: 2.870223 [24320/28137]\n",
      "loss: 2.892974 [25600/28137]\n",
      "loss: 2.846915 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848391, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 15]\n",
      "loss: 2.831322 [0/28137]\n",
      "loss: 2.831952 [1280/28137]\n",
      "loss: 2.800402 [2560/28137]\n",
      "loss: 2.862456 [3840/28137]\n",
      "loss: 2.816008 [5120/28137]\n",
      "loss: 2.800574 [6400/28137]\n",
      "loss: 2.816063 [7680/28137]\n",
      "loss: 2.824029 [8960/28137]\n",
      "loss: 2.854832 [10240/28137]\n",
      "loss: 2.862168 [11520/28137]\n",
      "loss: 2.823625 [12800/28137]\n",
      "loss: 2.924272 [14080/28137]\n",
      "loss: 2.839219 [15360/28137]\n",
      "loss: 2.854402 [16640/28137]\n",
      "loss: 2.854740 [17920/28137]\n",
      "loss: 2.901207 [19200/28137]\n",
      "loss: 2.877654 [20480/28137]\n",
      "loss: 2.870193 [21760/28137]\n",
      "loss: 2.885633 [23040/28137]\n",
      "loss: 2.878072 [24320/28137]\n",
      "loss: 2.877808 [25600/28137]\n",
      "loss: 2.955490 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848293, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 16]\n",
      "loss: 2.862148 [0/28137]\n",
      "loss: 2.823833 [1280/28137]\n",
      "loss: 2.854190 [2560/28137]\n",
      "loss: 2.839508 [3840/28137]\n",
      "loss: 2.893211 [5120/28137]\n",
      "loss: 2.823638 [6400/28137]\n",
      "loss: 2.846841 [7680/28137]\n",
      "loss: 2.862314 [8960/28137]\n",
      "loss: 2.807961 [10240/28137]\n",
      "loss: 2.808229 [11520/28137]\n",
      "loss: 2.807988 [12800/28137]\n",
      "loss: 2.870030 [14080/28137]\n",
      "loss: 2.831315 [15360/28137]\n",
      "loss: 2.831244 [16640/28137]\n",
      "loss: 2.854680 [17920/28137]\n",
      "loss: 2.838917 [19200/28137]\n",
      "loss: 2.947197 [20480/28137]\n",
      "loss: 2.877731 [21760/28137]\n",
      "loss: 2.869936 [23040/28137]\n",
      "loss: 2.862633 [24320/28137]\n",
      "loss: 2.869988 [25600/28137]\n",
      "loss: 2.839129 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848367, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 17]\n",
      "loss: 2.885677 [0/28137]\n",
      "loss: 2.862252 [1280/28137]\n",
      "loss: 2.885484 [2560/28137]\n",
      "loss: 2.823802 [3840/28137]\n",
      "loss: 2.815743 [5120/28137]\n",
      "loss: 2.823337 [6400/28137]\n",
      "loss: 2.862235 [7680/28137]\n",
      "loss: 2.831031 [8960/28137]\n",
      "loss: 2.862221 [10240/28137]\n",
      "loss: 2.924016 [11520/28137]\n",
      "loss: 2.893254 [12800/28137]\n",
      "loss: 2.808115 [14080/28137]\n",
      "loss: 2.877324 [15360/28137]\n",
      "loss: 2.862127 [16640/28137]\n",
      "loss: 2.823479 [17920/28137]\n",
      "loss: 2.839094 [19200/28137]\n",
      "loss: 2.846881 [20480/28137]\n",
      "loss: 2.900707 [21760/28137]\n",
      "loss: 2.846716 [23040/28137]\n",
      "loss: 2.900951 [24320/28137]\n",
      "loss: 2.846556 [25600/28137]\n",
      "loss: 2.885413 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848062, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 18]\n",
      "loss: 2.823555 [0/28137]\n",
      "loss: 2.823329 [1280/28137]\n",
      "loss: 2.838752 [2560/28137]\n",
      "loss: 2.884974 [3840/28137]\n",
      "loss: 2.808256 [5120/28137]\n",
      "loss: 2.823322 [6400/28137]\n",
      "loss: 2.854324 [7680/28137]\n",
      "loss: 2.939032 [8960/28137]\n",
      "loss: 2.854280 [10240/28137]\n",
      "loss: 2.924041 [11520/28137]\n",
      "loss: 2.846620 [12800/28137]\n",
      "loss: 2.869539 [14080/28137]\n",
      "loss: 2.877572 [15360/28137]\n",
      "loss: 2.838841 [16640/28137]\n",
      "loss: 2.838856 [17920/28137]\n",
      "loss: 2.831241 [19200/28137]\n",
      "loss: 2.815765 [20480/28137]\n",
      "loss: 2.831186 [21760/28137]\n",
      "loss: 2.916239 [23040/28137]\n",
      "loss: 2.854169 [24320/28137]\n",
      "loss: 2.846399 [25600/28137]\n",
      "loss: 2.815779 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.848074, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 19]\n",
      "loss: 2.807832 [0/28137]\n",
      "loss: 2.792594 [1280/28137]\n",
      "loss: 2.800028 [2560/28137]\n",
      "loss: 2.785264 [3840/28137]\n",
      "loss: 2.831291 [5120/28137]\n",
      "loss: 2.939016 [6400/28137]\n",
      "loss: 2.862197 [7680/28137]\n",
      "loss: 2.908376 [8960/28137]\n",
      "loss: 2.792613 [10240/28137]\n",
      "loss: 2.900869 [11520/28137]\n",
      "loss: 2.800220 [12800/28137]\n",
      "loss: 2.885271 [14080/28137]\n",
      "loss: 2.862185 [15360/28137]\n",
      "loss: 2.885327 [16640/28137]\n",
      "loss: 2.823288 [17920/28137]\n",
      "loss: 2.892735 [19200/28137]\n",
      "loss: 2.869733 [20480/28137]\n",
      "loss: 2.908431 [21760/28137]\n",
      "loss: 2.823460 [23040/28137]\n",
      "loss: 2.877264 [24320/28137]\n",
      "loss: 2.931459 [25600/28137]\n",
      "loss: 2.800148 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.847971, Accuracy: 2905/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 20]\n",
      "loss: 2.838722 [0/28137]\n",
      "loss: 2.800122 [1280/28137]\n",
      "loss: 2.915942 [2560/28137]\n",
      "loss: 2.846792 [3840/28137]\n",
      "loss: 2.854222 [5120/28137]\n",
      "loss: 2.838669 [6400/28137]\n",
      "loss: 2.885089 [7680/28137]\n",
      "loss: 2.869776 [8960/28137]\n",
      "loss: 2.807934 [10240/28137]\n",
      "loss: 2.846298 [11520/28137]\n",
      "loss: 2.838923 [12800/28137]\n",
      "loss: 2.831192 [14080/28137]\n",
      "loss: 2.800022 [15360/28137]\n",
      "loss: 2.877430 [16640/28137]\n",
      "loss: 2.869650 [17920/28137]\n",
      "loss: 2.831062 [19200/28137]\n",
      "loss: 2.885358 [20480/28137]\n",
      "loss: 2.853943 [21760/28137]\n",
      "loss: 2.885355 [23040/28137]\n",
      "loss: 2.908178 [24320/28137]\n",
      "loss: 2.838869 [25600/28137]\n",
      "loss: 2.792508 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.847952, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 21]\n",
      "loss: 2.885220 [0/28137]\n",
      "loss: 2.838678 [1280/28137]\n",
      "loss: 2.792478 [2560/28137]\n",
      "loss: 2.831154 [3840/28137]\n",
      "loss: 2.838649 [5120/28137]\n",
      "loss: 2.900472 [6400/28137]\n",
      "loss: 2.892708 [7680/28137]\n",
      "loss: 2.838953 [8960/28137]\n",
      "loss: 2.869715 [10240/28137]\n",
      "loss: 2.915640 [11520/28137]\n",
      "loss: 2.846303 [12800/28137]\n",
      "loss: 2.908375 [14080/28137]\n",
      "loss: 2.892669 [15360/28137]\n",
      "loss: 2.846519 [16640/28137]\n",
      "loss: 2.831023 [17920/28137]\n",
      "loss: 2.815556 [19200/28137]\n",
      "loss: 2.861964 [20480/28137]\n",
      "loss: 2.869614 [21760/28137]\n",
      "loss: 2.923584 [23040/28137]\n",
      "loss: 2.823218 [24320/28137]\n",
      "loss: 2.885133 [25600/28137]\n",
      "loss: 2.831032 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.847815, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 22]\n",
      "loss: 2.877136 [0/28137]\n",
      "loss: 2.846506 [1280/28137]\n",
      "loss: 2.885266 [2560/28137]\n",
      "loss: 2.807952 [3840/28137]\n",
      "loss: 2.869411 [5120/28137]\n",
      "loss: 2.931290 [6400/28137]\n",
      "loss: 2.846468 [7680/28137]\n",
      "loss: 2.861855 [8960/28137]\n",
      "loss: 2.861665 [10240/28137]\n",
      "loss: 2.841197 [11520/28137]\n",
      "loss: 2.893979 [12800/28137]\n",
      "loss: 2.856746 [14080/28137]\n",
      "loss: 2.847511 [15360/28137]\n",
      "loss: 2.855499 [16640/28137]\n",
      "loss: 2.832307 [17920/28137]\n",
      "loss: 2.913478 [19200/28137]\n",
      "loss: 2.866840 [20480/28137]\n",
      "loss: 2.813846 [21760/28137]\n",
      "loss: 2.913081 [23040/28137]\n",
      "loss: 2.793785 [24320/28137]\n",
      "loss: 2.824860 [25600/28137]\n",
      "loss: 2.877251 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.853890, Accuracy: 2891/3725 (77.6%)\n",
      "\n",
      "\n",
      "[Epoch 23]\n",
      "loss: 2.879967 [0/28137]\n",
      "loss: 2.849922 [1280/28137]\n",
      "loss: 2.793185 [2560/28137]\n",
      "loss: 2.871017 [3840/28137]\n",
      "loss: 2.844340 [5120/28137]\n",
      "loss: 2.893327 [6400/28137]\n",
      "loss: 2.893646 [7680/28137]\n",
      "loss: 2.823768 [8960/28137]\n",
      "loss: 2.847262 [10240/28137]\n",
      "loss: 2.886460 [11520/28137]\n",
      "loss: 2.847776 [12800/28137]\n",
      "loss: 2.862867 [14080/28137]\n",
      "loss: 2.807941 [15360/28137]\n",
      "loss: 2.893531 [16640/28137]\n",
      "loss: 2.846625 [17920/28137]\n",
      "loss: 2.885299 [19200/28137]\n",
      "loss: 2.870023 [20480/28137]\n",
      "loss: 2.838846 [21760/28137]\n",
      "loss: 2.815812 [23040/28137]\n",
      "loss: 2.846570 [24320/28137]\n",
      "loss: 2.892929 [25600/28137]\n",
      "loss: 2.831102 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.847798, Accuracy: 2906/3725 (78.0%)\n",
      "\n",
      "\n",
      "[Epoch 24]\n",
      "loss: 2.800020 [0/28137]\n",
      "loss: 2.846834 [1280/28137]\n",
      "loss: 2.946786 [2560/28137]\n",
      "loss: 2.823398 [3840/28137]\n",
      "loss: 2.862016 [5120/28137]\n",
      "loss: 2.846633 [6400/28137]\n",
      "loss: 2.892857 [7680/28137]\n",
      "loss: 2.846583 [8960/28137]\n",
      "loss: 2.862034 [10240/28137]\n",
      "loss: 2.838849 [11520/28137]\n",
      "loss: 2.869710 [12800/28137]\n",
      "loss: 2.777138 [14080/28137]\n",
      "loss: 2.885102 [15360/28137]\n",
      "loss: 2.869616 [16640/28137]\n",
      "loss: 2.854103 [17920/28137]\n",
      "loss: 2.842762 [19200/28137]\n",
      "loss: 2.748926 [20480/28137]\n",
      "loss: 2.862951 [21760/28137]\n",
      "loss: 2.873729 [23040/28137]\n",
      "loss: 2.863570 [24320/28137]\n",
      "loss: 2.785720 [25600/28137]\n",
      "loss: 2.763812 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.819601, Accuracy: 3015/3725 (80.9%)\n",
      "\n",
      "\n",
      "[Epoch 25]\n",
      "loss: 2.835980 [0/28137]\n",
      "loss: 2.839315 [1280/28137]\n",
      "loss: 2.831779 [2560/28137]\n",
      "loss: 2.754349 [3840/28137]\n",
      "loss: 2.840628 [5120/28137]\n",
      "loss: 2.792885 [6400/28137]\n",
      "loss: 2.831151 [7680/28137]\n",
      "loss: 2.815539 [8960/28137]\n",
      "loss: 2.761575 [10240/28137]\n",
      "loss: 2.831277 [11520/28137]\n",
      "loss: 2.846302 [12800/28137]\n",
      "loss: 2.846344 [14080/28137]\n",
      "loss: 2.815481 [15360/28137]\n",
      "loss: 2.792510 [16640/28137]\n",
      "loss: 2.815675 [17920/28137]\n",
      "loss: 2.808021 [19200/28137]\n",
      "loss: 2.823635 [20480/28137]\n",
      "loss: 2.839218 [21760/28137]\n",
      "loss: 2.808083 [23040/28137]\n",
      "loss: 2.892691 [24320/28137]\n",
      "loss: 2.854404 [25600/28137]\n",
      "loss: 2.800239 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.818016, Accuracy: 3018/3725 (81.0%)\n",
      "\n",
      "\n",
      "[Epoch 26]\n",
      "loss: 2.854323 [0/28137]\n",
      "loss: 2.746174 [1280/28137]\n",
      "loss: 2.846368 [2560/28137]\n",
      "loss: 2.846489 [3840/28137]\n",
      "loss: 2.885199 [5120/28137]\n",
      "loss: 2.846419 [6400/28137]\n",
      "loss: 2.764632 [7680/28137]\n",
      "loss: 2.810659 [8960/28137]\n",
      "loss: 2.803333 [10240/28137]\n",
      "loss: 2.826007 [11520/28137]\n",
      "loss: 2.785225 [12800/28137]\n",
      "loss: 2.855184 [14080/28137]\n",
      "loss: 2.762049 [15360/28137]\n",
      "loss: 2.741706 [16640/28137]\n",
      "loss: 2.871912 [17920/28137]\n",
      "loss: 2.800391 [19200/28137]\n",
      "loss: 2.797039 [20480/28137]\n",
      "loss: 2.754919 [21760/28137]\n",
      "loss: 2.763388 [23040/28137]\n",
      "loss: 2.792800 [24320/28137]\n",
      "loss: 2.831654 [25600/28137]\n",
      "loss: 2.813515 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.792357, Accuracy: 3118/3725 (83.7%)\n",
      "\n",
      "\n",
      "[Epoch 27]\n",
      "loss: 2.808732 [0/28137]\n",
      "loss: 2.870881 [1280/28137]\n",
      "loss: 2.801103 [2560/28137]\n",
      "loss: 2.800581 [3840/28137]\n",
      "loss: 2.824528 [5120/28137]\n",
      "loss: 2.762024 [6400/28137]\n",
      "loss: 2.808544 [7680/28137]\n",
      "loss: 2.785351 [8960/28137]\n",
      "loss: 2.777580 [10240/28137]\n",
      "loss: 2.816417 [11520/28137]\n",
      "loss: 2.800570 [12800/28137]\n",
      "loss: 2.808558 [14080/28137]\n",
      "loss: 2.808151 [15360/28137]\n",
      "loss: 2.816005 [16640/28137]\n",
      "loss: 2.808475 [17920/28137]\n",
      "loss: 2.816185 [19200/28137]\n",
      "loss: 2.801733 [20480/28137]\n",
      "loss: 2.869758 [21760/28137]\n",
      "loss: 2.777518 [23040/28137]\n",
      "loss: 2.746348 [24320/28137]\n",
      "loss: 2.823567 [25600/28137]\n",
      "loss: 2.831280 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.791140, Accuracy: 3120/3725 (83.8%)\n",
      "\n",
      "\n",
      "[Epoch 28]\n",
      "loss: 2.831218 [0/28137]\n",
      "loss: 2.785162 [1280/28137]\n",
      "loss: 2.823694 [2560/28137]\n",
      "loss: 2.769771 [3840/28137]\n",
      "loss: 2.792772 [5120/28137]\n",
      "loss: 2.808227 [6400/28137]\n",
      "loss: 2.746220 [7680/28137]\n",
      "loss: 2.815876 [8960/28137]\n",
      "loss: 2.831435 [10240/28137]\n",
      "loss: 2.785002 [11520/28137]\n",
      "loss: 2.769137 [12800/28137]\n",
      "loss: 2.800584 [14080/28137]\n",
      "loss: 2.831579 [15360/28137]\n",
      "loss: 2.808105 [16640/28137]\n",
      "loss: 2.793204 [17920/28137]\n",
      "loss: 2.800378 [19200/28137]\n",
      "loss: 2.761885 [20480/28137]\n",
      "loss: 2.777084 [21760/28137]\n",
      "loss: 2.846765 [23040/28137]\n",
      "loss: 2.792857 [24320/28137]\n",
      "loss: 2.792613 [25600/28137]\n",
      "loss: 2.808178 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.791117, Accuracy: 3120/3725 (83.8%)\n",
      "\n",
      "\n",
      "[Epoch 29]\n",
      "loss: 2.761787 [0/28137]\n",
      "loss: 2.808502 [1280/28137]\n",
      "loss: 2.815621 [2560/28137]\n",
      "loss: 2.792530 [3840/28137]\n",
      "loss: 2.754192 [5120/28137]\n",
      "loss: 2.792490 [6400/28137]\n",
      "loss: 2.777065 [7680/28137]\n",
      "loss: 2.823806 [8960/28137]\n",
      "loss: 2.792848 [10240/28137]\n",
      "loss: 2.846336 [11520/28137]\n",
      "loss: 2.792572 [12800/28137]\n",
      "loss: 2.807848 [14080/28137]\n",
      "loss: 2.777444 [15360/28137]\n",
      "loss: 2.776913 [16640/28137]\n",
      "loss: 2.800463 [17920/28137]\n",
      "loss: 2.769236 [19200/28137]\n",
      "loss: 2.769978 [20480/28137]\n",
      "loss: 2.769363 [21760/28137]\n",
      "loss: 2.792418 [23040/28137]\n",
      "loss: 2.792452 [24320/28137]\n",
      "loss: 2.777279 [25600/28137]\n",
      "loss: 2.854838 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.791001, Accuracy: 3120/3725 (83.8%)\n",
      "\n",
      "\n",
      "[Epoch 30]\n",
      "loss: 2.746290 [0/28137]\n",
      "loss: 2.761765 [1280/28137]\n",
      "loss: 2.838654 [2560/28137]\n",
      "loss: 2.769427 [3840/28137]\n",
      "loss: 2.831141 [5120/28137]\n",
      "loss: 2.769681 [6400/28137]\n",
      "loss: 2.738490 [7680/28137]\n",
      "loss: 2.807947 [8960/28137]\n",
      "loss: 2.823832 [10240/28137]\n",
      "loss: 2.846468 [11520/28137]\n",
      "loss: 2.761383 [12800/28137]\n",
      "loss: 2.846566 [14080/28137]\n",
      "loss: 2.807981 [15360/28137]\n",
      "loss: 2.808105 [16640/28137]\n",
      "loss: 2.823423 [17920/28137]\n",
      "loss: 2.838841 [19200/28137]\n",
      "loss: 2.815897 [20480/28137]\n",
      "loss: 2.784780 [21760/28137]\n",
      "loss: 2.792367 [23040/28137]\n",
      "loss: 2.839304 [24320/28137]\n",
      "loss: 2.799837 [25600/28137]\n",
      "loss: 2.800515 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.791017, Accuracy: 3120/3725 (83.8%)\n",
      "\n",
      "\n",
      "[Epoch 31]\n",
      "loss: 2.769234 [0/28137]\n",
      "loss: 2.846673 [1280/28137]\n",
      "loss: 2.792439 [2560/28137]\n",
      "loss: 2.823517 [3840/28137]\n",
      "loss: 2.792377 [5120/28137]\n",
      "loss: 2.771570 [6400/28137]\n",
      "loss: 2.747705 [7680/28137]\n",
      "loss: 2.794374 [8960/28137]\n",
      "loss: 2.809065 [10240/28137]\n",
      "loss: 2.771234 [11520/28137]\n",
      "loss: 2.787129 [12800/28137]\n",
      "loss: 2.708211 [14080/28137]\n",
      "loss: 2.793258 [15360/28137]\n",
      "loss: 2.771049 [16640/28137]\n",
      "loss: 2.785255 [17920/28137]\n",
      "loss: 2.762262 [19200/28137]\n",
      "loss: 2.823953 [20480/28137]\n",
      "loss: 2.738851 [21760/28137]\n",
      "loss: 2.774077 [23040/28137]\n",
      "loss: 2.738608 [24320/28137]\n",
      "loss: 2.785071 [25600/28137]\n",
      "loss: 2.792766 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.764166, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 32]\n",
      "loss: 2.754154 [0/28137]\n",
      "loss: 2.715559 [1280/28137]\n",
      "loss: 2.777159 [2560/28137]\n",
      "loss: 2.761902 [3840/28137]\n",
      "loss: 2.777633 [5120/28137]\n",
      "loss: 2.723573 [6400/28137]\n",
      "loss: 2.784965 [7680/28137]\n",
      "loss: 2.815545 [8960/28137]\n",
      "loss: 2.791730 [10240/28137]\n",
      "loss: 2.785005 [11520/28137]\n",
      "loss: 2.808096 [12800/28137]\n",
      "loss: 2.831605 [14080/28137]\n",
      "loss: 2.746607 [15360/28137]\n",
      "loss: 2.785239 [16640/28137]\n",
      "loss: 2.723198 [17920/28137]\n",
      "loss: 2.801144 [19200/28137]\n",
      "loss: 2.761729 [20480/28137]\n",
      "loss: 2.730915 [21760/28137]\n",
      "loss: 2.769624 [23040/28137]\n",
      "loss: 2.808249 [24320/28137]\n",
      "loss: 2.823446 [25600/28137]\n",
      "loss: 2.715301 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763998, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 33]\n",
      "loss: 2.769804 [0/28137]\n",
      "loss: 2.769306 [1280/28137]\n",
      "loss: 2.753514 [2560/28137]\n",
      "loss: 2.746139 [3840/28137]\n",
      "loss: 2.785025 [5120/28137]\n",
      "loss: 2.785029 [6400/28137]\n",
      "loss: 2.730712 [7680/28137]\n",
      "loss: 2.838737 [8960/28137]\n",
      "loss: 2.784801 [10240/28137]\n",
      "loss: 2.785133 [11520/28137]\n",
      "loss: 2.761947 [12800/28137]\n",
      "loss: 2.769526 [14080/28137]\n",
      "loss: 2.746138 [15360/28137]\n",
      "loss: 2.792417 [16640/28137]\n",
      "loss: 2.792896 [17920/28137]\n",
      "loss: 2.815793 [19200/28137]\n",
      "loss: 2.723011 [20480/28137]\n",
      "loss: 2.753814 [21760/28137]\n",
      "loss: 2.823603 [23040/28137]\n",
      "loss: 2.800092 [24320/28137]\n",
      "loss: 2.769634 [25600/28137]\n",
      "loss: 2.792413 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763932, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 34]\n",
      "loss: 2.785032 [0/28137]\n",
      "loss: 2.761408 [1280/28137]\n",
      "loss: 2.730614 [2560/28137]\n",
      "loss: 2.823302 [3840/28137]\n",
      "loss: 2.746427 [5120/28137]\n",
      "loss: 2.730711 [6400/28137]\n",
      "loss: 2.792156 [7680/28137]\n",
      "loss: 2.776950 [8960/28137]\n",
      "loss: 2.722975 [10240/28137]\n",
      "loss: 2.800424 [11520/28137]\n",
      "loss: 2.730780 [12800/28137]\n",
      "loss: 2.753906 [14080/28137]\n",
      "loss: 2.769392 [15360/28137]\n",
      "loss: 2.784990 [16640/28137]\n",
      "loss: 2.784487 [17920/28137]\n",
      "loss: 2.776913 [19200/28137]\n",
      "loss: 2.831382 [20480/28137]\n",
      "loss: 2.777208 [21760/28137]\n",
      "loss: 2.754097 [23040/28137]\n",
      "loss: 2.769421 [24320/28137]\n",
      "loss: 2.792462 [25600/28137]\n",
      "loss: 2.792550 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763841, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 35]\n",
      "loss: 2.830858 [0/28137]\n",
      "loss: 2.746029 [1280/28137]\n",
      "loss: 2.753953 [2560/28137]\n",
      "loss: 2.785074 [3840/28137]\n",
      "loss: 2.784905 [5120/28137]\n",
      "loss: 2.792864 [6400/28137]\n",
      "loss: 2.761527 [7680/28137]\n",
      "loss: 2.807947 [8960/28137]\n",
      "loss: 2.730477 [10240/28137]\n",
      "loss: 2.777279 [11520/28137]\n",
      "loss: 2.816062 [12800/28137]\n",
      "loss: 2.822990 [14080/28137]\n",
      "loss: 2.738349 [15360/28137]\n",
      "loss: 2.776742 [16640/28137]\n",
      "loss: 2.761853 [17920/28137]\n",
      "loss: 2.776894 [19200/28137]\n",
      "loss: 2.776682 [20480/28137]\n",
      "loss: 2.792047 [21760/28137]\n",
      "loss: 2.738413 [23040/28137]\n",
      "loss: 2.792701 [24320/28137]\n",
      "loss: 2.815959 [25600/28137]\n",
      "loss: 2.730644 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763795, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 36]\n",
      "loss: 2.738885 [0/28137]\n",
      "loss: 2.745973 [1280/28137]\n",
      "loss: 2.761315 [2560/28137]\n",
      "loss: 2.715089 [3840/28137]\n",
      "loss: 2.831257 [5120/28137]\n",
      "loss: 2.815921 [6400/28137]\n",
      "loss: 2.792236 [7680/28137]\n",
      "loss: 2.761795 [8960/28137]\n",
      "loss: 2.808225 [10240/28137]\n",
      "loss: 2.722627 [11520/28137]\n",
      "loss: 2.799884 [12800/28137]\n",
      "loss: 2.792488 [14080/28137]\n",
      "loss: 2.792800 [15360/28137]\n",
      "loss: 2.730608 [16640/28137]\n",
      "loss: 2.776757 [17920/28137]\n",
      "loss: 2.807981 [19200/28137]\n",
      "loss: 2.792099 [20480/28137]\n",
      "loss: 2.754071 [21760/28137]\n",
      "loss: 2.792251 [23040/28137]\n",
      "loss: 2.730528 [24320/28137]\n",
      "loss: 2.823483 [25600/28137]\n",
      "loss: 2.791994 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763794, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 37]\n",
      "loss: 2.776934 [0/28137]\n",
      "loss: 2.745952 [1280/28137]\n",
      "loss: 2.753702 [2560/28137]\n",
      "loss: 2.769269 [3840/28137]\n",
      "loss: 2.769495 [5120/28137]\n",
      "loss: 2.784602 [6400/28137]\n",
      "loss: 2.753422 [7680/28137]\n",
      "loss: 2.800266 [8960/28137]\n",
      "loss: 2.769258 [10240/28137]\n",
      "loss: 2.753698 [11520/28137]\n",
      "loss: 2.776817 [12800/28137]\n",
      "loss: 2.777191 [14080/28137]\n",
      "loss: 2.776854 [15360/28137]\n",
      "loss: 2.746306 [16640/28137]\n",
      "loss: 2.738107 [17920/28137]\n",
      "loss: 2.769245 [19200/28137]\n",
      "loss: 2.761346 [20480/28137]\n",
      "loss: 2.800302 [21760/28137]\n",
      "loss: 2.769232 [23040/28137]\n",
      "loss: 2.776705 [24320/28137]\n",
      "loss: 2.776817 [25600/28137]\n",
      "loss: 2.722828 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763781, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 38]\n",
      "loss: 2.761091 [0/28137]\n",
      "loss: 2.761430 [1280/28137]\n",
      "loss: 2.792471 [2560/28137]\n",
      "loss: 2.761211 [3840/28137]\n",
      "loss: 2.761697 [5120/28137]\n",
      "loss: 2.746296 [6400/28137]\n",
      "loss: 2.792438 [7680/28137]\n",
      "loss: 2.761227 [8960/28137]\n",
      "loss: 2.761325 [10240/28137]\n",
      "loss: 2.800021 [11520/28137]\n",
      "loss: 2.722948 [12800/28137]\n",
      "loss: 2.792405 [14080/28137]\n",
      "loss: 2.768919 [15360/28137]\n",
      "loss: 2.753568 [16640/28137]\n",
      "loss: 2.838507 [17920/28137]\n",
      "loss: 2.846813 [19200/28137]\n",
      "loss: 2.753757 [20480/28137]\n",
      "loss: 2.800234 [21760/28137]\n",
      "loss: 2.699695 [23040/28137]\n",
      "loss: 2.746203 [24320/28137]\n",
      "loss: 2.807651 [25600/28137]\n",
      "loss: 2.815351 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763633, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 39]\n",
      "loss: 2.699572 [0/28137]\n",
      "loss: 2.722944 [1280/28137]\n",
      "loss: 2.738083 [2560/28137]\n",
      "loss: 2.730711 [3840/28137]\n",
      "loss: 2.761246 [5120/28137]\n",
      "loss: 2.730603 [6400/28137]\n",
      "loss: 2.799873 [7680/28137]\n",
      "loss: 2.792312 [8960/28137]\n",
      "loss: 2.776725 [10240/28137]\n",
      "loss: 2.784469 [11520/28137]\n",
      "loss: 2.776896 [12800/28137]\n",
      "loss: 2.745950 [14080/28137]\n",
      "loss: 2.792198 [15360/28137]\n",
      "loss: 2.761320 [16640/28137]\n",
      "loss: 2.753521 [17920/28137]\n",
      "loss: 2.730529 [19200/28137]\n",
      "loss: 2.807604 [20480/28137]\n",
      "loss: 2.738118 [21760/28137]\n",
      "loss: 2.730624 [23040/28137]\n",
      "loss: 2.784670 [24320/28137]\n",
      "loss: 2.784282 [25600/28137]\n",
      "loss: 2.800327 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763595, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 40]\n",
      "loss: 2.784395 [0/28137]\n",
      "loss: 2.761178 [1280/28137]\n",
      "loss: 2.761337 [2560/28137]\n",
      "loss: 2.745909 [3840/28137]\n",
      "loss: 2.753464 [5120/28137]\n",
      "loss: 2.777209 [6400/28137]\n",
      "loss: 2.807529 [7680/28137]\n",
      "loss: 2.768893 [8960/28137]\n",
      "loss: 2.776645 [10240/28137]\n",
      "loss: 2.815049 [11520/28137]\n",
      "loss: 2.745829 [12800/28137]\n",
      "loss: 2.761343 [14080/28137]\n",
      "loss: 2.784229 [15360/28137]\n",
      "loss: 2.761061 [16640/28137]\n",
      "loss: 2.738084 [17920/28137]\n",
      "loss: 2.799664 [19200/28137]\n",
      "loss: 2.730440 [20480/28137]\n",
      "loss: 2.753511 [21760/28137]\n",
      "loss: 2.738106 [23040/28137]\n",
      "loss: 2.791983 [24320/28137]\n",
      "loss: 2.792190 [25600/28137]\n",
      "loss: 2.799940 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.763473, Accuracy: 3222/3725 (86.5%)\n",
      "\n",
      "\n",
      "[Epoch 41]\n",
      "loss: 2.807364 [0/28137]\n",
      "loss: 2.738145 [1280/28137]\n",
      "loss: 2.722598 [2560/28137]\n",
      "loss: 2.730263 [3840/28137]\n",
      "loss: 2.769079 [5120/28137]\n",
      "loss: 2.801363 [6400/28137]\n",
      "loss: 2.765095 [7680/28137]\n",
      "loss: 2.787759 [8960/28137]\n",
      "loss: 2.768025 [10240/28137]\n",
      "loss: 2.733991 [11520/28137]\n",
      "loss: 2.740330 [12800/28137]\n",
      "loss: 2.739015 [14080/28137]\n",
      "loss: 2.715746 [15360/28137]\n",
      "loss: 2.793217 [16640/28137]\n",
      "loss: 2.686271 [17920/28137]\n",
      "loss: 2.715388 [19200/28137]\n",
      "loss: 2.731350 [20480/28137]\n",
      "loss: 2.732800 [21760/28137]\n",
      "loss: 2.692401 [23040/28137]\n",
      "loss: 2.746142 [24320/28137]\n",
      "loss: 2.715151 [25600/28137]\n",
      "loss: 2.709795 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.738616, Accuracy: 3319/3725 (89.1%)\n",
      "\n",
      "\n",
      "[Epoch 42]\n",
      "loss: 2.723215 [0/28137]\n",
      "loss: 2.700665 [1280/28137]\n",
      "loss: 2.730603 [2560/28137]\n",
      "loss: 2.724671 [3840/28137]\n",
      "loss: 2.762182 [5120/28137]\n",
      "loss: 2.738616 [6400/28137]\n",
      "loss: 2.768947 [7680/28137]\n",
      "loss: 2.730735 [8960/28137]\n",
      "loss: 2.738835 [10240/28137]\n",
      "loss: 2.784751 [11520/28137]\n",
      "loss: 2.769322 [12800/28137]\n",
      "loss: 2.723026 [14080/28137]\n",
      "loss: 2.754178 [15360/28137]\n",
      "loss: 2.761581 [16640/28137]\n",
      "loss: 2.784943 [17920/28137]\n",
      "loss: 2.776899 [19200/28137]\n",
      "loss: 2.707565 [20480/28137]\n",
      "loss: 2.730868 [21760/28137]\n",
      "loss: 2.722642 [23040/28137]\n",
      "loss: 2.755521 [24320/28137]\n",
      "loss: 2.753732 [25600/28137]\n",
      "loss: 2.676581 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.737242, Accuracy: 3323/3725 (89.2%)\n",
      "\n",
      "\n",
      "[Epoch 43]\n",
      "loss: 2.761749 [0/28137]\n",
      "loss: 2.784734 [1280/28137]\n",
      "loss: 2.831011 [2560/28137]\n",
      "loss: 2.746683 [3840/28137]\n",
      "loss: 2.784518 [5120/28137]\n",
      "loss: 2.768839 [6400/28137]\n",
      "loss: 2.784665 [7680/28137]\n",
      "loss: 2.776786 [8960/28137]\n",
      "loss: 2.738108 [10240/28137]\n",
      "loss: 2.769006 [11520/28137]\n",
      "loss: 2.745008 [12800/28137]\n",
      "loss: 2.753615 [14080/28137]\n",
      "loss: 2.723100 [15360/28137]\n",
      "loss: 2.745788 [16640/28137]\n",
      "loss: 2.738013 [17920/28137]\n",
      "loss: 2.776793 [19200/28137]\n",
      "loss: 2.730509 [20480/28137]\n",
      "loss: 2.784425 [21760/28137]\n",
      "loss: 2.753366 [23040/28137]\n",
      "loss: 2.730545 [24320/28137]\n",
      "loss: 2.699582 [25600/28137]\n",
      "loss: 2.745776 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.736546, Accuracy: 3324/3725 (89.2%)\n",
      "\n",
      "\n",
      "[Epoch 44]\n",
      "loss: 2.707261 [0/28137]\n",
      "loss: 2.730457 [1280/28137]\n",
      "loss: 2.768917 [2560/28137]\n",
      "loss: 2.722771 [3840/28137]\n",
      "loss: 2.707178 [5120/28137]\n",
      "loss: 2.730343 [6400/28137]\n",
      "loss: 2.753539 [7680/28137]\n",
      "loss: 2.745835 [8960/28137]\n",
      "loss: 2.722584 [10240/28137]\n",
      "loss: 2.768832 [11520/28137]\n",
      "loss: 2.745796 [12800/28137]\n",
      "loss: 2.730250 [14080/28137]\n",
      "loss: 2.807342 [15360/28137]\n",
      "loss: 2.784106 [16640/28137]\n",
      "loss: 2.738036 [17920/28137]\n",
      "loss: 2.761581 [19200/28137]\n",
      "loss: 2.722769 [20480/28137]\n",
      "loss: 2.692002 [21760/28137]\n",
      "loss: 2.730568 [23040/28137]\n",
      "loss: 2.799812 [24320/28137]\n",
      "loss: 2.753483 [25600/28137]\n",
      "loss: 2.761477 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.736437, Accuracy: 3324/3725 (89.2%)\n",
      "\n",
      "\n",
      "[Epoch 45]\n",
      "loss: 2.745696 [0/28137]\n",
      "loss: 2.745781 [1280/28137]\n",
      "loss: 2.722559 [2560/28137]\n",
      "loss: 2.707173 [3840/28137]\n",
      "loss: 2.814980 [5120/28137]\n",
      "loss: 2.794098 [6400/28137]\n",
      "loss: 2.709646 [7680/28137]\n",
      "loss: 2.738775 [8960/28137]\n",
      "loss: 2.730652 [10240/28137]\n",
      "loss: 2.707520 [11520/28137]\n",
      "loss: 2.753492 [12800/28137]\n",
      "loss: 2.691967 [14080/28137]\n",
      "loss: 2.730248 [15360/28137]\n",
      "loss: 2.714933 [16640/28137]\n",
      "loss: 2.715007 [17920/28137]\n",
      "loss: 2.687296 [19200/28137]\n",
      "loss: 2.730465 [20480/28137]\n",
      "loss: 2.699448 [21760/28137]\n",
      "loss: 2.730509 [23040/28137]\n",
      "loss: 2.699579 [24320/28137]\n",
      "loss: 2.684016 [25600/28137]\n",
      "loss: 2.707191 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.717488, Accuracy: 3396/3725 (91.2%)\n",
      "\n",
      "\n",
      "[Epoch 46]\n",
      "loss: 2.676341 [0/28137]\n",
      "loss: 2.745721 [1280/28137]\n",
      "loss: 2.722511 [2560/28137]\n",
      "loss: 2.714773 [3840/28137]\n",
      "loss: 2.707158 [5120/28137]\n",
      "loss: 2.699447 [6400/28137]\n",
      "loss: 2.691842 [7680/28137]\n",
      "loss: 2.676314 [8960/28137]\n",
      "loss: 2.769083 [10240/28137]\n",
      "loss: 2.753351 [11520/28137]\n",
      "loss: 2.722744 [12800/28137]\n",
      "loss: 2.768771 [14080/28137]\n",
      "loss: 2.684096 [15360/28137]\n",
      "loss: 2.699483 [16640/28137]\n",
      "loss: 2.707124 [17920/28137]\n",
      "loss: 2.761062 [19200/28137]\n",
      "loss: 2.738080 [20480/28137]\n",
      "loss: 2.760880 [21760/28137]\n",
      "loss: 2.660917 [23040/28137]\n",
      "loss: 2.684150 [24320/28137]\n",
      "loss: 2.722607 [25600/28137]\n",
      "loss: 2.714969 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.717412, Accuracy: 3396/3725 (91.2%)\n",
      "\n",
      "\n",
      "[Epoch 47]\n",
      "loss: 2.722666 [0/28137]\n",
      "loss: 2.714887 [1280/28137]\n",
      "loss: 2.722548 [2560/28137]\n",
      "loss: 2.707103 [3840/28137]\n",
      "loss: 2.691741 [5120/28137]\n",
      "loss: 2.714817 [6400/28137]\n",
      "loss: 2.691710 [7680/28137]\n",
      "loss: 2.738067 [8960/28137]\n",
      "loss: 2.714799 [10240/28137]\n",
      "loss: 2.707205 [11520/28137]\n",
      "loss: 2.676363 [12800/28137]\n",
      "loss: 2.722568 [14080/28137]\n",
      "loss: 2.745664 [15360/28137]\n",
      "loss: 2.684056 [16640/28137]\n",
      "loss: 2.691682 [17920/28137]\n",
      "loss: 2.684039 [19200/28137]\n",
      "loss: 2.691751 [20480/28137]\n",
      "loss: 2.753383 [21760/28137]\n",
      "loss: 2.691769 [23040/28137]\n",
      "loss: 2.722584 [24320/28137]\n",
      "loss: 2.722478 [25600/28137]\n",
      "loss: 2.707176 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.717329, Accuracy: 3396/3725 (91.2%)\n",
      "\n",
      "\n",
      "[Epoch 48]\n",
      "loss: 2.699413 [0/28137]\n",
      "loss: 2.699408 [1280/28137]\n",
      "loss: 2.691855 [2560/28137]\n",
      "loss: 2.722498 [3840/28137]\n",
      "loss: 2.730260 [5120/28137]\n",
      "loss: 2.737863 [6400/28137]\n",
      "loss: 2.691650 [7680/28137]\n",
      "loss: 2.753231 [8960/28137]\n",
      "loss: 2.753444 [10240/28137]\n",
      "loss: 2.683990 [11520/28137]\n",
      "loss: 2.676346 [12800/28137]\n",
      "loss: 2.691678 [14080/28137]\n",
      "loss: 2.707264 [15360/28137]\n",
      "loss: 2.768699 [16640/28137]\n",
      "loss: 2.707070 [17920/28137]\n",
      "loss: 2.691753 [19200/28137]\n",
      "loss: 2.707083 [20480/28137]\n",
      "loss: 2.707119 [21760/28137]\n",
      "loss: 2.722527 [23040/28137]\n",
      "loss: 2.722460 [24320/28137]\n",
      "loss: 2.684038 [25600/28137]\n",
      "loss: 2.707075 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.717325, Accuracy: 3396/3725 (91.2%)\n",
      "\n",
      "\n",
      "[Epoch 49]\n",
      "loss: 2.691777 [0/28137]\n",
      "loss: 2.699432 [1280/28137]\n",
      "loss: 2.722459 [2560/28137]\n",
      "loss: 2.712009 [3840/28137]\n",
      "loss: 2.687134 [5120/28137]\n",
      "loss: 2.666481 [6400/28137]\n",
      "loss: 2.655529 [7680/28137]\n",
      "loss: 2.655025 [8960/28137]\n",
      "loss: 2.677771 [10240/28137]\n",
      "loss: 2.654957 [11520/28137]\n",
      "loss: 2.669204 [12800/28137]\n",
      "loss: 2.664906 [14080/28137]\n",
      "loss: 2.662598 [15360/28137]\n",
      "loss: 2.645780 [16640/28137]\n",
      "loss: 2.669075 [17920/28137]\n",
      "loss: 2.668797 [19200/28137]\n",
      "loss: 2.669343 [20480/28137]\n",
      "loss: 2.670242 [21760/28137]\n",
      "loss: 2.653609 [23040/28137]\n",
      "loss: 2.638149 [24320/28137]\n",
      "loss: 2.692616 [25600/28137]\n",
      "loss: 2.647068 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660400, Accuracy: 3612/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 50]\n",
      "loss: 2.669016 [0/28137]\n",
      "loss: 2.645958 [1280/28137]\n",
      "loss: 2.654444 [2560/28137]\n",
      "loss: 2.677363 [3840/28137]\n",
      "loss: 2.653359 [5120/28137]\n",
      "loss: 2.668882 [6400/28137]\n",
      "loss: 2.653493 [7680/28137]\n",
      "loss: 2.661220 [8960/28137]\n",
      "loss: 2.653470 [10240/28137]\n",
      "loss: 2.637927 [11520/28137]\n",
      "loss: 2.660958 [12800/28137]\n",
      "loss: 2.668855 [14080/28137]\n",
      "loss: 2.668853 [15360/28137]\n",
      "loss: 2.645579 [16640/28137]\n",
      "loss: 2.661035 [17920/28137]\n",
      "loss: 2.637882 [19200/28137]\n",
      "loss: 2.707629 [20480/28137]\n",
      "loss: 2.676515 [21760/28137]\n",
      "loss: 2.653498 [23040/28137]\n",
      "loss: 2.668810 [24320/28137]\n",
      "loss: 2.637902 [25600/28137]\n",
      "loss: 2.645575 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660016, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 51]\n",
      "loss: 2.661002 [0/28137]\n",
      "loss: 2.707418 [1280/28137]\n",
      "loss: 2.661146 [2560/28137]\n",
      "loss: 2.661143 [3840/28137]\n",
      "loss: 2.715219 [5120/28137]\n",
      "loss: 2.661123 [6400/28137]\n",
      "loss: 2.669393 [7680/28137]\n",
      "loss: 2.661030 [8960/28137]\n",
      "loss: 2.668807 [10240/28137]\n",
      "loss: 2.699684 [11520/28137]\n",
      "loss: 2.668875 [12800/28137]\n",
      "loss: 2.653335 [14080/28137]\n",
      "loss: 2.676590 [15360/28137]\n",
      "loss: 2.661050 [16640/28137]\n",
      "loss: 2.684157 [17920/28137]\n",
      "loss: 2.684235 [19200/28137]\n",
      "loss: 2.661081 [20480/28137]\n",
      "loss: 2.653397 [21760/28137]\n",
      "loss: 2.645605 [23040/28137]\n",
      "loss: 2.668702 [24320/28137]\n",
      "loss: 2.668813 [25600/28137]\n",
      "loss: 2.653294 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659930, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 52]\n",
      "loss: 2.668830 [0/28137]\n",
      "loss: 2.660951 [1280/28137]\n",
      "loss: 2.661154 [2560/28137]\n",
      "loss: 2.630150 [3840/28137]\n",
      "loss: 2.661001 [5120/28137]\n",
      "loss: 2.660998 [6400/28137]\n",
      "loss: 2.637848 [7680/28137]\n",
      "loss: 2.668897 [8960/28137]\n",
      "loss: 2.653258 [10240/28137]\n",
      "loss: 2.691793 [11520/28137]\n",
      "loss: 2.661043 [12800/28137]\n",
      "loss: 2.645569 [14080/28137]\n",
      "loss: 2.645677 [15360/28137]\n",
      "loss: 2.645588 [16640/28137]\n",
      "loss: 2.668856 [17920/28137]\n",
      "loss: 2.637855 [19200/28137]\n",
      "loss: 2.645569 [20480/28137]\n",
      "loss: 2.661003 [21760/28137]\n",
      "loss: 2.637889 [23040/28137]\n",
      "loss: 2.645633 [24320/28137]\n",
      "loss: 2.676423 [25600/28137]\n",
      "loss: 2.653280 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659917, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 53]\n",
      "loss: 2.660965 [0/28137]\n",
      "loss: 2.637854 [1280/28137]\n",
      "loss: 2.637969 [2560/28137]\n",
      "loss: 2.638032 [3840/28137]\n",
      "loss: 2.676650 [5120/28137]\n",
      "loss: 2.668930 [6400/28137]\n",
      "loss: 2.637856 [7680/28137]\n",
      "loss: 2.692234 [8960/28137]\n",
      "loss: 2.645744 [10240/28137]\n",
      "loss: 2.684228 [11520/28137]\n",
      "loss: 2.645723 [12800/28137]\n",
      "loss: 2.645579 [14080/28137]\n",
      "loss: 2.653391 [15360/28137]\n",
      "loss: 2.664163 [16640/28137]\n",
      "loss: 2.684719 [17920/28137]\n",
      "loss: 2.661462 [19200/28137]\n",
      "loss: 2.666072 [20480/28137]\n",
      "loss: 2.684109 [21760/28137]\n",
      "loss: 2.676871 [23040/28137]\n",
      "loss: 2.653554 [24320/28137]\n",
      "loss: 2.698188 [25600/28137]\n",
      "loss: 2.661104 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660907, Accuracy: 3612/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 54]\n",
      "loss: 2.661028 [0/28137]\n",
      "loss: 2.648880 [1280/28137]\n",
      "loss: 2.654197 [2560/28137]\n",
      "loss: 2.653671 [3840/28137]\n",
      "loss: 2.637932 [5120/28137]\n",
      "loss: 2.676671 [6400/28137]\n",
      "loss: 2.637953 [7680/28137]\n",
      "loss: 2.637990 [8960/28137]\n",
      "loss: 2.669130 [10240/28137]\n",
      "loss: 2.661158 [11520/28137]\n",
      "loss: 2.653296 [12800/28137]\n",
      "loss: 2.653327 [14080/28137]\n",
      "loss: 2.645593 [15360/28137]\n",
      "loss: 2.676708 [16640/28137]\n",
      "loss: 2.653552 [17920/28137]\n",
      "loss: 2.637866 [19200/28137]\n",
      "loss: 2.645677 [20480/28137]\n",
      "loss: 2.676538 [21760/28137]\n",
      "loss: 2.645803 [23040/28137]\n",
      "loss: 2.668996 [24320/28137]\n",
      "loss: 2.669073 [25600/28137]\n",
      "loss: 2.676672 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660512, Accuracy: 3611/3725 (96.9%)\n",
      "\n",
      "\n",
      "[Epoch 55]\n",
      "loss: 2.637943 [0/28137]\n",
      "loss: 2.668813 [1280/28137]\n",
      "loss: 2.645607 [2560/28137]\n",
      "loss: 2.669021 [3840/28137]\n",
      "loss: 2.661061 [5120/28137]\n",
      "loss: 2.668816 [6400/28137]\n",
      "loss: 2.653330 [7680/28137]\n",
      "loss: 2.676394 [8960/28137]\n",
      "loss: 2.653270 [10240/28137]\n",
      "loss: 2.661170 [11520/28137]\n",
      "loss: 2.676436 [12800/28137]\n",
      "loss: 2.676445 [14080/28137]\n",
      "loss: 2.645576 [15360/28137]\n",
      "loss: 2.661426 [16640/28137]\n",
      "loss: 2.692003 [17920/28137]\n",
      "loss: 2.684107 [19200/28137]\n",
      "loss: 2.645615 [20480/28137]\n",
      "loss: 2.653318 [21760/28137]\n",
      "loss: 2.645746 [23040/28137]\n",
      "loss: 2.668673 [24320/28137]\n",
      "loss: 2.661222 [25600/28137]\n",
      "loss: 2.660965 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659963, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 56]\n",
      "loss: 2.637865 [0/28137]\n",
      "loss: 2.676606 [1280/28137]\n",
      "loss: 2.653242 [2560/28137]\n",
      "loss: 2.660984 [3840/28137]\n",
      "loss: 2.645699 [5120/28137]\n",
      "loss: 2.645528 [6400/28137]\n",
      "loss: 2.668650 [7680/28137]\n",
      "loss: 2.645537 [8960/28137]\n",
      "loss: 2.660944 [10240/28137]\n",
      "loss: 2.653260 [11520/28137]\n",
      "loss: 2.668612 [12800/28137]\n",
      "loss: 2.684039 [14080/28137]\n",
      "loss: 2.668629 [15360/28137]\n",
      "loss: 2.668694 [16640/28137]\n",
      "loss: 2.668621 [17920/28137]\n",
      "loss: 2.699579 [19200/28137]\n",
      "loss: 2.676573 [20480/28137]\n",
      "loss: 2.645551 [21760/28137]\n",
      "loss: 2.653239 [23040/28137]\n",
      "loss: 2.645587 [24320/28137]\n",
      "loss: 2.660933 [25600/28137]\n",
      "loss: 2.645535 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659847, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 57]\n",
      "loss: 2.668638 [0/28137]\n",
      "loss: 2.653236 [1280/28137]\n",
      "loss: 2.645659 [2560/28137]\n",
      "loss: 2.645548 [3840/28137]\n",
      "loss: 2.660917 [5120/28137]\n",
      "loss: 2.668658 [6400/28137]\n",
      "loss: 2.660904 [7680/28137]\n",
      "loss: 2.653237 [8960/28137]\n",
      "loss: 2.653237 [10240/28137]\n",
      "loss: 2.684004 [11520/28137]\n",
      "loss: 2.645540 [12800/28137]\n",
      "loss: 2.645549 [14080/28137]\n",
      "loss: 2.653277 [15360/28137]\n",
      "loss: 2.660933 [16640/28137]\n",
      "loss: 2.668750 [17920/28137]\n",
      "loss: 2.661055 [19200/28137]\n",
      "loss: 2.707312 [20480/28137]\n",
      "loss: 2.676338 [21760/28137]\n",
      "loss: 2.684112 [23040/28137]\n",
      "loss: 2.660926 [24320/28137]\n",
      "loss: 2.691921 [25600/28137]\n",
      "loss: 2.653310 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659839, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 58]\n",
      "loss: 2.653229 [0/28137]\n",
      "loss: 2.676353 [1280/28137]\n",
      "loss: 2.637848 [2560/28137]\n",
      "loss: 2.645540 [3840/28137]\n",
      "loss: 2.645535 [5120/28137]\n",
      "loss: 2.660985 [6400/28137]\n",
      "loss: 2.653233 [7680/28137]\n",
      "loss: 2.668696 [8960/28137]\n",
      "loss: 2.660926 [10240/28137]\n",
      "loss: 2.653226 [11520/28137]\n",
      "loss: 2.661045 [12800/28137]\n",
      "loss: 2.653288 [14080/28137]\n",
      "loss: 2.668709 [15360/28137]\n",
      "loss: 2.691838 [16640/28137]\n",
      "loss: 2.668610 [17920/28137]\n",
      "loss: 2.707338 [19200/28137]\n",
      "loss: 2.637842 [20480/28137]\n",
      "loss: 2.653247 [21760/28137]\n",
      "loss: 2.645554 [23040/28137]\n",
      "loss: 2.637845 [24320/28137]\n",
      "loss: 2.676446 [25600/28137]\n",
      "loss: 2.668813 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659823, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 59]\n",
      "loss: 2.676440 [0/28137]\n",
      "loss: 2.637840 [1280/28137]\n",
      "loss: 2.661006 [2560/28137]\n",
      "loss: 2.668617 [3840/28137]\n",
      "loss: 2.645550 [5120/28137]\n",
      "loss: 2.668609 [6400/28137]\n",
      "loss: 2.668646 [7680/28137]\n",
      "loss: 2.668597 [8960/28137]\n",
      "loss: 2.660908 [10240/28137]\n",
      "loss: 2.645557 [11520/28137]\n",
      "loss: 2.668607 [12800/28137]\n",
      "loss: 2.660906 [14080/28137]\n",
      "loss: 2.660940 [15360/28137]\n",
      "loss: 2.637842 [16640/28137]\n",
      "loss: 2.645544 [17920/28137]\n",
      "loss: 2.691770 [19200/28137]\n",
      "loss: 2.637838 [20480/28137]\n",
      "loss: 2.668649 [21760/28137]\n",
      "loss: 2.668627 [23040/28137]\n",
      "loss: 2.676284 [24320/28137]\n",
      "loss: 2.645652 [25600/28137]\n",
      "loss: 2.676310 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659815, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 60]\n",
      "loss: 2.668624 [0/28137]\n",
      "loss: 2.653233 [1280/28137]\n",
      "loss: 2.645542 [2560/28137]\n",
      "loss: 2.653229 [3840/28137]\n",
      "loss: 2.637844 [5120/28137]\n",
      "loss: 2.676297 [6400/28137]\n",
      "loss: 2.653212 [7680/28137]\n",
      "loss: 2.668614 [8960/28137]\n",
      "loss: 2.660937 [10240/28137]\n",
      "loss: 2.637869 [11520/28137]\n",
      "loss: 2.661015 [12800/28137]\n",
      "loss: 2.699371 [14080/28137]\n",
      "loss: 2.645591 [15360/28137]\n",
      "loss: 2.661050 [16640/28137]\n",
      "loss: 2.653228 [17920/28137]\n",
      "loss: 2.668602 [19200/28137]\n",
      "loss: 2.676306 [20480/28137]\n",
      "loss: 2.660949 [21760/28137]\n",
      "loss: 2.645560 [23040/28137]\n",
      "loss: 2.683985 [24320/28137]\n",
      "loss: 2.645547 [25600/28137]\n",
      "loss: 2.707045 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659809, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 61]\n",
      "loss: 2.645522 [0/28137]\n",
      "loss: 2.660909 [1280/28137]\n",
      "loss: 2.660924 [2560/28137]\n",
      "loss: 2.684129 [3840/28137]\n",
      "loss: 2.660910 [5120/28137]\n",
      "loss: 2.684010 [6400/28137]\n",
      "loss: 2.699420 [7680/28137]\n",
      "loss: 2.676303 [8960/28137]\n",
      "loss: 2.676280 [10240/28137]\n",
      "loss: 2.653223 [11520/28137]\n",
      "loss: 2.660907 [12800/28137]\n",
      "loss: 2.660905 [14080/28137]\n",
      "loss: 2.668628 [15360/28137]\n",
      "loss: 2.660906 [16640/28137]\n",
      "loss: 2.645529 [17920/28137]\n",
      "loss: 2.653215 [19200/28137]\n",
      "loss: 2.676291 [20480/28137]\n",
      "loss: 2.645533 [21760/28137]\n",
      "loss: 2.660924 [23040/28137]\n",
      "loss: 2.660928 [24320/28137]\n",
      "loss: 2.684002 [25600/28137]\n",
      "loss: 2.676293 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659807, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 62]\n",
      "loss: 2.668696 [0/28137]\n",
      "loss: 2.668838 [1280/28137]\n",
      "loss: 2.668721 [2560/28137]\n",
      "loss: 2.676280 [3840/28137]\n",
      "loss: 2.661153 [5120/28137]\n",
      "loss: 2.630146 [6400/28137]\n",
      "loss: 2.668652 [7680/28137]\n",
      "loss: 2.645539 [8960/28137]\n",
      "loss: 2.668756 [10240/28137]\n",
      "loss: 2.653236 [11520/28137]\n",
      "loss: 2.645538 [12800/28137]\n",
      "loss: 2.637833 [14080/28137]\n",
      "loss: 2.653213 [15360/28137]\n",
      "loss: 2.645532 [16640/28137]\n",
      "loss: 2.660918 [17920/28137]\n",
      "loss: 2.660898 [19200/28137]\n",
      "loss: 2.691673 [20480/28137]\n",
      "loss: 2.684006 [21760/28137]\n",
      "loss: 2.637837 [23040/28137]\n",
      "loss: 2.668612 [24320/28137]\n",
      "loss: 2.653217 [25600/28137]\n",
      "loss: 2.653214 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659805, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 63]\n",
      "loss: 2.653344 [0/28137]\n",
      "loss: 2.653229 [1280/28137]\n",
      "loss: 2.660965 [2560/28137]\n",
      "loss: 2.676268 [3840/28137]\n",
      "loss: 2.645533 [5120/28137]\n",
      "loss: 2.668613 [6400/28137]\n",
      "loss: 2.668609 [7680/28137]\n",
      "loss: 2.645530 [8960/28137]\n",
      "loss: 2.660924 [10240/28137]\n",
      "loss: 2.661051 [11520/28137]\n",
      "loss: 2.653226 [12800/28137]\n",
      "loss: 2.637857 [14080/28137]\n",
      "loss: 2.660911 [15360/28137]\n",
      "loss: 2.645543 [16640/28137]\n",
      "loss: 2.660906 [17920/28137]\n",
      "loss: 2.668854 [19200/28137]\n",
      "loss: 2.668619 [20480/28137]\n",
      "loss: 2.676290 [21760/28137]\n",
      "loss: 2.653337 [23040/28137]\n",
      "loss: 2.645526 [24320/28137]\n",
      "loss: 2.660927 [25600/28137]\n",
      "loss: 2.645525 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659802, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 64]\n",
      "loss: 2.660901 [0/28137]\n",
      "loss: 2.676338 [1280/28137]\n",
      "loss: 2.653245 [2560/28137]\n",
      "loss: 2.653212 [3840/28137]\n",
      "loss: 2.660919 [5120/28137]\n",
      "loss: 2.683997 [6400/28137]\n",
      "loss: 2.660962 [7680/28137]\n",
      "loss: 2.645523 [8960/28137]\n",
      "loss: 2.653338 [10240/28137]\n",
      "loss: 2.668604 [11520/28137]\n",
      "loss: 2.653229 [12800/28137]\n",
      "loss: 2.637842 [14080/28137]\n",
      "loss: 2.645533 [15360/28137]\n",
      "loss: 2.653213 [16640/28137]\n",
      "loss: 2.645656 [17920/28137]\n",
      "loss: 2.683965 [19200/28137]\n",
      "loss: 2.668598 [20480/28137]\n",
      "loss: 2.668716 [21760/28137]\n",
      "loss: 2.668600 [23040/28137]\n",
      "loss: 2.691658 [24320/28137]\n",
      "loss: 2.676284 [25600/28137]\n",
      "loss: 2.668589 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659799, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 65]\n",
      "loss: 2.637830 [0/28137]\n",
      "loss: 2.660910 [1280/28137]\n",
      "loss: 2.668595 [2560/28137]\n",
      "loss: 2.676274 [3840/28137]\n",
      "loss: 2.668614 [5120/28137]\n",
      "loss: 2.661015 [6400/28137]\n",
      "loss: 2.660929 [7680/28137]\n",
      "loss: 2.653366 [8960/28137]\n",
      "loss: 2.660898 [10240/28137]\n",
      "loss: 2.653214 [11520/28137]\n",
      "loss: 2.653211 [12800/28137]\n",
      "loss: 2.653216 [14080/28137]\n",
      "loss: 2.660916 [15360/28137]\n",
      "loss: 2.653216 [16640/28137]\n",
      "loss: 2.683971 [17920/28137]\n",
      "loss: 2.676273 [19200/28137]\n",
      "loss: 2.707400 [20480/28137]\n",
      "loss: 2.653211 [21760/28137]\n",
      "loss: 2.660905 [23040/28137]\n",
      "loss: 2.660905 [24320/28137]\n",
      "loss: 2.668583 [25600/28137]\n",
      "loss: 2.683958 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659792, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 66]\n",
      "loss: 2.660890 [0/28137]\n",
      "loss: 2.660902 [1280/28137]\n",
      "loss: 2.645531 [2560/28137]\n",
      "loss: 2.668597 [3840/28137]\n",
      "loss: 2.630146 [5120/28137]\n",
      "loss: 2.683991 [6400/28137]\n",
      "loss: 2.645652 [7680/28137]\n",
      "loss: 2.637833 [8960/28137]\n",
      "loss: 2.645520 [10240/28137]\n",
      "loss: 2.676301 [11520/28137]\n",
      "loss: 2.676278 [12800/28137]\n",
      "loss: 2.660895 [14080/28137]\n",
      "loss: 2.653208 [15360/28137]\n",
      "loss: 2.661030 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.668603 [19200/28137]\n",
      "loss: 2.660906 [20480/28137]\n",
      "loss: 2.660913 [21760/28137]\n",
      "loss: 2.653208 [23040/28137]\n",
      "loss: 2.653211 [24320/28137]\n",
      "loss: 2.653219 [25600/28137]\n",
      "loss: 2.660902 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659800, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 67]\n",
      "loss: 2.668588 [0/28137]\n",
      "loss: 2.660896 [1280/28137]\n",
      "loss: 2.645532 [2560/28137]\n",
      "loss: 2.645523 [3840/28137]\n",
      "loss: 2.645521 [5120/28137]\n",
      "loss: 2.637899 [6400/28137]\n",
      "loss: 2.637832 [7680/28137]\n",
      "loss: 2.683965 [8960/28137]\n",
      "loss: 2.676293 [10240/28137]\n",
      "loss: 2.668574 [11520/28137]\n",
      "loss: 2.653211 [12800/28137]\n",
      "loss: 2.684110 [14080/28137]\n",
      "loss: 2.676412 [15360/28137]\n",
      "loss: 2.668595 [16640/28137]\n",
      "loss: 2.653336 [17920/28137]\n",
      "loss: 2.630147 [19200/28137]\n",
      "loss: 2.660895 [20480/28137]\n",
      "loss: 2.676535 [21760/28137]\n",
      "loss: 2.676277 [23040/28137]\n",
      "loss: 2.653208 [24320/28137]\n",
      "loss: 2.653212 [25600/28137]\n",
      "loss: 2.661027 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659794, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 68]\n",
      "loss: 2.668581 [0/28137]\n",
      "loss: 2.645523 [1280/28137]\n",
      "loss: 2.683961 [2560/28137]\n",
      "loss: 2.645647 [3840/28137]\n",
      "loss: 2.645522 [5120/28137]\n",
      "loss: 2.645534 [6400/28137]\n",
      "loss: 2.668593 [7680/28137]\n",
      "loss: 2.637835 [8960/28137]\n",
      "loss: 2.707022 [10240/28137]\n",
      "loss: 2.630146 [11520/28137]\n",
      "loss: 2.645520 [12800/28137]\n",
      "loss: 2.653208 [14080/28137]\n",
      "loss: 2.707031 [15360/28137]\n",
      "loss: 2.668582 [16640/28137]\n",
      "loss: 2.645523 [17920/28137]\n",
      "loss: 2.684097 [19200/28137]\n",
      "loss: 2.660900 [20480/28137]\n",
      "loss: 2.645523 [21760/28137]\n",
      "loss: 2.637838 [23040/28137]\n",
      "loss: 2.653204 [24320/28137]\n",
      "loss: 2.661030 [25600/28137]\n",
      "loss: 2.637832 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659806, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 69]\n",
      "loss: 2.637833 [0/28137]\n",
      "loss: 2.691644 [1280/28137]\n",
      "loss: 2.668595 [2560/28137]\n",
      "loss: 2.668584 [3840/28137]\n",
      "loss: 2.668581 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.653209 [7680/28137]\n",
      "loss: 2.660899 [8960/28137]\n",
      "loss: 2.668604 [10240/28137]\n",
      "loss: 2.668580 [11520/28137]\n",
      "loss: 2.676267 [12800/28137]\n",
      "loss: 2.683959 [14080/28137]\n",
      "loss: 2.660978 [15360/28137]\n",
      "loss: 2.645527 [16640/28137]\n",
      "loss: 2.637838 [17920/28137]\n",
      "loss: 2.653230 [19200/28137]\n",
      "loss: 2.645531 [20480/28137]\n",
      "loss: 2.668585 [21760/28137]\n",
      "loss: 2.668582 [23040/28137]\n",
      "loss: 2.653213 [24320/28137]\n",
      "loss: 2.645523 [25600/28137]\n",
      "loss: 2.645530 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659805, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 70]\n",
      "loss: 2.653226 [0/28137]\n",
      "loss: 2.630146 [1280/28137]\n",
      "loss: 2.668580 [2560/28137]\n",
      "loss: 2.637831 [3840/28137]\n",
      "loss: 2.653204 [5120/28137]\n",
      "loss: 2.637842 [6400/28137]\n",
      "loss: 2.653203 [7680/28137]\n",
      "loss: 2.676265 [8960/28137]\n",
      "loss: 2.660894 [10240/28137]\n",
      "loss: 2.653213 [11520/28137]\n",
      "loss: 2.660889 [12800/28137]\n",
      "loss: 2.653214 [14080/28137]\n",
      "loss: 2.645524 [15360/28137]\n",
      "loss: 2.668590 [16640/28137]\n",
      "loss: 2.660896 [17920/28137]\n",
      "loss: 2.637833 [19200/28137]\n",
      "loss: 2.660895 [20480/28137]\n",
      "loss: 2.668681 [21760/28137]\n",
      "loss: 2.660904 [23040/28137]\n",
      "loss: 2.661143 [24320/28137]\n",
      "loss: 2.645530 [25600/28137]\n",
      "loss: 2.653217 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659806, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 71]\n",
      "loss: 2.645525 [0/28137]\n",
      "loss: 2.637834 [1280/28137]\n",
      "loss: 2.653209 [2560/28137]\n",
      "loss: 2.676272 [3840/28137]\n",
      "loss: 2.637831 [5120/28137]\n",
      "loss: 2.660888 [6400/28137]\n",
      "loss: 2.676391 [7680/28137]\n",
      "loss: 2.653334 [8960/28137]\n",
      "loss: 2.668581 [10240/28137]\n",
      "loss: 2.676265 [11520/28137]\n",
      "loss: 2.684089 [12800/28137]\n",
      "loss: 2.668583 [14080/28137]\n",
      "loss: 2.653332 [15360/28137]\n",
      "loss: 2.668592 [16640/28137]\n",
      "loss: 2.660902 [17920/28137]\n",
      "loss: 2.660894 [19200/28137]\n",
      "loss: 2.645521 [20480/28137]\n",
      "loss: 2.676281 [21760/28137]\n",
      "loss: 2.660949 [23040/28137]\n",
      "loss: 2.637835 [24320/28137]\n",
      "loss: 2.661017 [25600/28137]\n",
      "loss: 2.653217 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659837, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 72]\n",
      "loss: 2.645647 [0/28137]\n",
      "loss: 2.653203 [1280/28137]\n",
      "loss: 2.645517 [2560/28137]\n",
      "loss: 2.660891 [3840/28137]\n",
      "loss: 2.653206 [5120/28137]\n",
      "loss: 2.645518 [6400/28137]\n",
      "loss: 2.660888 [7680/28137]\n",
      "loss: 2.691631 [8960/28137]\n",
      "loss: 2.660890 [10240/28137]\n",
      "loss: 2.683949 [11520/28137]\n",
      "loss: 2.653340 [12800/28137]\n",
      "loss: 2.676274 [14080/28137]\n",
      "loss: 2.653218 [15360/28137]\n",
      "loss: 2.637836 [16640/28137]\n",
      "loss: 2.653206 [17920/28137]\n",
      "loss: 2.660890 [19200/28137]\n",
      "loss: 2.676388 [20480/28137]\n",
      "loss: 2.645518 [21760/28137]\n",
      "loss: 2.653206 [23040/28137]\n",
      "loss: 2.676269 [24320/28137]\n",
      "loss: 2.668583 [25600/28137]\n",
      "loss: 2.653206 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659816, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 73]\n",
      "loss: 2.645517 [0/28137]\n",
      "loss: 2.676263 [1280/28137]\n",
      "loss: 2.661019 [2560/28137]\n",
      "loss: 2.660919 [3840/28137]\n",
      "loss: 2.676261 [5120/28137]\n",
      "loss: 2.637831 [6400/28137]\n",
      "loss: 2.653207 [7680/28137]\n",
      "loss: 2.676386 [8960/28137]\n",
      "loss: 2.637958 [10240/28137]\n",
      "loss: 2.668576 [11520/28137]\n",
      "loss: 2.668701 [12800/28137]\n",
      "loss: 2.645517 [14080/28137]\n",
      "loss: 2.645532 [15360/28137]\n",
      "loss: 2.683948 [16640/28137]\n",
      "loss: 2.668586 [17920/28137]\n",
      "loss: 2.660901 [19200/28137]\n",
      "loss: 2.653208 [20480/28137]\n",
      "loss: 2.676264 [21760/28137]\n",
      "loss: 2.653210 [23040/28137]\n",
      "loss: 2.660894 [24320/28137]\n",
      "loss: 2.653211 [25600/28137]\n",
      "loss: 2.660897 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659801, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 74]\n",
      "loss: 2.660896 [0/28137]\n",
      "loss: 2.660892 [1280/28137]\n",
      "loss: 2.653334 [2560/28137]\n",
      "loss: 2.668576 [3840/28137]\n",
      "loss: 2.676265 [5120/28137]\n",
      "loss: 2.668579 [6400/28137]\n",
      "loss: 2.645519 [7680/28137]\n",
      "loss: 2.653215 [8960/28137]\n",
      "loss: 2.668577 [10240/28137]\n",
      "loss: 2.637832 [11520/28137]\n",
      "loss: 2.660899 [12800/28137]\n",
      "loss: 2.676274 [14080/28137]\n",
      "loss: 2.676257 [15360/28137]\n",
      "loss: 2.707004 [16640/28137]\n",
      "loss: 2.683957 [17920/28137]\n",
      "loss: 2.660893 [19200/28137]\n",
      "loss: 2.668578 [20480/28137]\n",
      "loss: 2.660891 [21760/28137]\n",
      "loss: 2.637832 [23040/28137]\n",
      "loss: 2.653202 [24320/28137]\n",
      "loss: 2.668826 [25600/28137]\n",
      "loss: 2.676392 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659792, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 75]\n",
      "loss: 2.668576 [0/28137]\n",
      "loss: 2.653202 [1280/28137]\n",
      "loss: 2.683960 [2560/28137]\n",
      "loss: 2.653203 [3840/28137]\n",
      "loss: 2.653202 [5120/28137]\n",
      "loss: 2.699318 [6400/28137]\n",
      "loss: 2.653203 [7680/28137]\n",
      "loss: 2.661017 [8960/28137]\n",
      "loss: 2.668583 [10240/28137]\n",
      "loss: 2.645519 [11520/28137]\n",
      "loss: 2.660895 [12800/28137]\n",
      "loss: 2.653204 [14080/28137]\n",
      "loss: 2.660891 [15360/28137]\n",
      "loss: 2.668576 [16640/28137]\n",
      "loss: 2.653206 [17920/28137]\n",
      "loss: 2.660893 [19200/28137]\n",
      "loss: 2.645518 [20480/28137]\n",
      "loss: 2.653205 [21760/28137]\n",
      "loss: 2.676265 [23040/28137]\n",
      "loss: 2.676278 [24320/28137]\n",
      "loss: 2.653202 [25600/28137]\n",
      "loss: 2.660894 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659791, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 76]\n",
      "loss: 2.653203 [0/28137]\n",
      "loss: 2.653203 [1280/28137]\n",
      "loss: 2.676262 [2560/28137]\n",
      "loss: 2.645516 [3840/28137]\n",
      "loss: 2.668579 [5120/28137]\n",
      "loss: 2.645521 [6400/28137]\n",
      "loss: 2.676394 [7680/28137]\n",
      "loss: 2.645520 [8960/28137]\n",
      "loss: 2.661017 [10240/28137]\n",
      "loss: 2.653203 [11520/28137]\n",
      "loss: 2.676385 [12800/28137]\n",
      "loss: 2.676387 [14080/28137]\n",
      "loss: 2.668577 [15360/28137]\n",
      "loss: 2.676264 [16640/28137]\n",
      "loss: 2.653203 [17920/28137]\n",
      "loss: 2.691633 [19200/28137]\n",
      "loss: 2.653203 [20480/28137]\n",
      "loss: 2.645515 [21760/28137]\n",
      "loss: 2.645520 [23040/28137]\n",
      "loss: 2.660890 [24320/28137]\n",
      "loss: 2.660887 [25600/28137]\n",
      "loss: 2.668828 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659784, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 77]\n",
      "loss: 2.668582 [0/28137]\n",
      "loss: 2.676259 [1280/28137]\n",
      "loss: 2.668573 [2560/28137]\n",
      "loss: 2.668700 [3840/28137]\n",
      "loss: 2.653332 [5120/28137]\n",
      "loss: 2.653204 [6400/28137]\n",
      "loss: 2.645526 [7680/28137]\n",
      "loss: 2.661015 [8960/28137]\n",
      "loss: 2.660890 [10240/28137]\n",
      "loss: 2.676261 [11520/28137]\n",
      "loss: 2.645518 [12800/28137]\n",
      "loss: 2.637830 [14080/28137]\n",
      "loss: 2.645517 [15360/28137]\n",
      "loss: 2.653202 [16640/28137]\n",
      "loss: 2.645517 [17920/28137]\n",
      "loss: 2.660888 [19200/28137]\n",
      "loss: 2.676404 [20480/28137]\n",
      "loss: 2.660889 [21760/28137]\n",
      "loss: 2.637831 [23040/28137]\n",
      "loss: 2.653205 [24320/28137]\n",
      "loss: 2.630146 [25600/28137]\n",
      "loss: 2.637833 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659798, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 78]\n",
      "loss: 2.653337 [0/28137]\n",
      "loss: 2.645517 [1280/28137]\n",
      "loss: 2.661024 [2560/28137]\n",
      "loss: 2.683950 [3840/28137]\n",
      "loss: 2.668578 [5120/28137]\n",
      "loss: 2.660888 [6400/28137]\n",
      "loss: 2.691644 [7680/28137]\n",
      "loss: 2.653205 [8960/28137]\n",
      "loss: 2.653206 [10240/28137]\n",
      "loss: 2.660892 [11520/28137]\n",
      "loss: 2.653211 [12800/28137]\n",
      "loss: 2.653204 [14080/28137]\n",
      "loss: 2.645645 [15360/28137]\n",
      "loss: 2.691640 [16640/28137]\n",
      "loss: 2.661019 [17920/28137]\n",
      "loss: 2.661024 [19200/28137]\n",
      "loss: 2.668701 [20480/28137]\n",
      "loss: 2.676267 [21760/28137]\n",
      "loss: 2.668573 [23040/28137]\n",
      "loss: 2.645520 [24320/28137]\n",
      "loss: 2.684329 [25600/28137]\n",
      "loss: 2.645645 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659780, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 79]\n",
      "loss: 2.637832 [0/28137]\n",
      "loss: 2.653203 [1280/28137]\n",
      "loss: 2.660894 [2560/28137]\n",
      "loss: 2.653203 [3840/28137]\n",
      "loss: 2.653208 [5120/28137]\n",
      "loss: 2.653207 [6400/28137]\n",
      "loss: 2.653202 [7680/28137]\n",
      "loss: 2.668572 [8960/28137]\n",
      "loss: 2.653200 [10240/28137]\n",
      "loss: 2.645515 [11520/28137]\n",
      "loss: 2.653328 [12800/28137]\n",
      "loss: 2.653202 [14080/28137]\n",
      "loss: 2.645519 [15360/28137]\n",
      "loss: 2.660887 [16640/28137]\n",
      "loss: 2.660889 [17920/28137]\n",
      "loss: 2.637830 [19200/28137]\n",
      "loss: 2.684078 [20480/28137]\n",
      "loss: 2.653203 [21760/28137]\n",
      "loss: 2.645516 [23040/28137]\n",
      "loss: 2.653329 [24320/28137]\n",
      "loss: 2.645518 [25600/28137]\n",
      "loss: 2.653205 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659804, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 80]\n",
      "loss: 2.653204 [0/28137]\n",
      "loss: 2.630147 [1280/28137]\n",
      "loss: 2.653202 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.668573 [5120/28137]\n",
      "loss: 2.668574 [6400/28137]\n",
      "loss: 2.645517 [7680/28137]\n",
      "loss: 2.660889 [8960/28137]\n",
      "loss: 2.645518 [10240/28137]\n",
      "loss: 2.668581 [11520/28137]\n",
      "loss: 2.645516 [12800/28137]\n",
      "loss: 2.660890 [14080/28137]\n",
      "loss: 2.683946 [15360/28137]\n",
      "loss: 2.645519 [16640/28137]\n",
      "loss: 2.661015 [17920/28137]\n",
      "loss: 2.668574 [19200/28137]\n",
      "loss: 2.668579 [20480/28137]\n",
      "loss: 2.691630 [21760/28137]\n",
      "loss: 2.645517 [23040/28137]\n",
      "loss: 2.660894 [24320/28137]\n",
      "loss: 2.660888 [25600/28137]\n",
      "loss: 2.683953 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659792, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 81]\n",
      "loss: 2.660887 [0/28137]\n",
      "loss: 2.653203 [1280/28137]\n",
      "loss: 2.660889 [2560/28137]\n",
      "loss: 2.653204 [3840/28137]\n",
      "loss: 2.645519 [5120/28137]\n",
      "loss: 2.645645 [6400/28137]\n",
      "loss: 2.645516 [7680/28137]\n",
      "loss: 2.676394 [8960/28137]\n",
      "loss: 2.645519 [10240/28137]\n",
      "loss: 2.661014 [11520/28137]\n",
      "loss: 2.645521 [12800/28137]\n",
      "loss: 2.668571 [14080/28137]\n",
      "loss: 2.661015 [15360/28137]\n",
      "loss: 2.660887 [16640/28137]\n",
      "loss: 2.645517 [17920/28137]\n",
      "loss: 2.668573 [19200/28137]\n",
      "loss: 2.691758 [20480/28137]\n",
      "loss: 2.653206 [21760/28137]\n",
      "loss: 2.676259 [23040/28137]\n",
      "loss: 2.645518 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.668722 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659789, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 82]\n",
      "loss: 2.676263 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.676257 [2560/28137]\n",
      "loss: 2.668575 [3840/28137]\n",
      "loss: 2.676261 [5120/28137]\n",
      "loss: 2.645516 [6400/28137]\n",
      "loss: 2.660887 [7680/28137]\n",
      "loss: 2.645516 [8960/28137]\n",
      "loss: 2.645516 [10240/28137]\n",
      "loss: 2.653202 [11520/28137]\n",
      "loss: 2.653204 [12800/28137]\n",
      "loss: 2.645519 [14080/28137]\n",
      "loss: 2.637830 [15360/28137]\n",
      "loss: 2.653204 [16640/28137]\n",
      "loss: 2.668576 [17920/28137]\n",
      "loss: 2.645519 [19200/28137]\n",
      "loss: 2.676258 [20480/28137]\n",
      "loss: 2.660892 [21760/28137]\n",
      "loss: 2.653201 [23040/28137]\n",
      "loss: 2.676258 [24320/28137]\n",
      "loss: 2.668699 [25600/28137]\n",
      "loss: 2.676386 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659792, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 83]\n",
      "loss: 2.660887 [0/28137]\n",
      "loss: 2.660887 [1280/28137]\n",
      "loss: 2.645517 [2560/28137]\n",
      "loss: 2.691628 [3840/28137]\n",
      "loss: 2.645515 [5120/28137]\n",
      "loss: 2.645516 [6400/28137]\n",
      "loss: 2.653202 [7680/28137]\n",
      "loss: 2.637836 [8960/28137]\n",
      "loss: 2.668573 [10240/28137]\n",
      "loss: 2.645515 [11520/28137]\n",
      "loss: 2.668573 [12800/28137]\n",
      "loss: 2.668573 [14080/28137]\n",
      "loss: 2.645643 [15360/28137]\n",
      "loss: 2.653203 [16640/28137]\n",
      "loss: 2.660885 [17920/28137]\n",
      "loss: 2.645515 [19200/28137]\n",
      "loss: 2.653204 [20480/28137]\n",
      "loss: 2.660886 [21760/28137]\n",
      "loss: 2.637830 [23040/28137]\n",
      "loss: 2.653205 [24320/28137]\n",
      "loss: 2.637830 [25600/28137]\n",
      "loss: 2.668571 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659780, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 84]\n",
      "loss: 2.668571 [0/28137]\n",
      "loss: 2.668571 [1280/28137]\n",
      "loss: 2.668701 [2560/28137]\n",
      "loss: 2.691753 [3840/28137]\n",
      "loss: 2.683941 [5120/28137]\n",
      "loss: 2.653201 [6400/28137]\n",
      "loss: 2.676256 [7680/28137]\n",
      "loss: 2.699311 [8960/28137]\n",
      "loss: 2.676256 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.653205 [12800/28137]\n",
      "loss: 2.653203 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.660886 [16640/28137]\n",
      "loss: 2.637831 [17920/28137]\n",
      "loss: 2.645515 [19200/28137]\n",
      "loss: 2.676258 [20480/28137]\n",
      "loss: 2.653200 [21760/28137]\n",
      "loss: 2.637831 [23040/28137]\n",
      "loss: 2.668698 [24320/28137]\n",
      "loss: 2.683942 [25600/28137]\n",
      "loss: 2.653202 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659794, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 85]\n",
      "loss: 2.668574 [0/28137]\n",
      "loss: 2.668573 [1280/28137]\n",
      "loss: 2.660886 [2560/28137]\n",
      "loss: 2.660885 [3840/28137]\n",
      "loss: 2.653327 [5120/28137]\n",
      "loss: 2.668570 [6400/28137]\n",
      "loss: 2.637827 [7680/28137]\n",
      "loss: 2.668571 [8960/28137]\n",
      "loss: 2.645516 [10240/28137]\n",
      "loss: 2.653201 [11520/28137]\n",
      "loss: 2.676260 [12800/28137]\n",
      "loss: 2.668574 [14080/28137]\n",
      "loss: 2.668576 [15360/28137]\n",
      "loss: 2.653204 [16640/28137]\n",
      "loss: 2.645515 [17920/28137]\n",
      "loss: 2.645515 [19200/28137]\n",
      "loss: 2.660888 [20480/28137]\n",
      "loss: 2.653202 [21760/28137]\n",
      "loss: 2.668571 [23040/28137]\n",
      "loss: 2.668699 [24320/28137]\n",
      "loss: 2.676257 [25600/28137]\n",
      "loss: 2.637831 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659779, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 86]\n",
      "loss: 2.668575 [0/28137]\n",
      "loss: 2.653201 [1280/28137]\n",
      "loss: 2.691629 [2560/28137]\n",
      "loss: 2.660891 [3840/28137]\n",
      "loss: 2.668577 [5120/28137]\n",
      "loss: 2.653200 [6400/28137]\n",
      "loss: 2.653330 [7680/28137]\n",
      "loss: 2.645516 [8960/28137]\n",
      "loss: 2.668701 [10240/28137]\n",
      "loss: 2.653202 [11520/28137]\n",
      "loss: 2.637830 [12800/28137]\n",
      "loss: 2.676258 [14080/28137]\n",
      "loss: 2.637830 [15360/28137]\n",
      "loss: 2.676256 [16640/28137]\n",
      "loss: 2.645515 [17920/28137]\n",
      "loss: 2.645515 [19200/28137]\n",
      "loss: 2.683942 [20480/28137]\n",
      "loss: 2.661014 [21760/28137]\n",
      "loss: 2.653329 [23040/28137]\n",
      "loss: 2.660889 [24320/28137]\n",
      "loss: 2.660886 [25600/28137]\n",
      "loss: 2.676383 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.659791, Accuracy: 3613/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 87]\n",
      "loss: 2.660887 [0/28137]\n",
      "loss: 2.660886 [1280/28137]\n",
      "loss: 2.668571 [2560/28137]\n",
      "loss: 2.645516 [3840/28137]\n",
      "loss: 2.645517 [5120/28137]\n",
      "loss: 2.645521 [6400/28137]\n",
      "loss: 2.684106 [7680/28137]\n",
      "loss: 2.676657 [8960/28137]\n",
      "loss: 2.647411 [10240/28137]\n",
      "loss: 2.663480 [11520/28137]\n",
      "loss: 2.704969 [12800/28137]\n",
      "loss: 2.678689 [14080/28137]\n",
      "loss: 2.646655 [15360/28137]\n",
      "loss: 2.668830 [16640/28137]\n",
      "loss: 2.656999 [17920/28137]\n",
      "loss: 2.692085 [19200/28137]\n",
      "loss: 2.654458 [20480/28137]\n",
      "loss: 2.653444 [21760/28137]\n",
      "loss: 2.661345 [23040/28137]\n",
      "loss: 2.676466 [24320/28137]\n",
      "loss: 2.645880 [25600/28137]\n",
      "loss: 2.692102 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.661351, Accuracy: 3608/3725 (96.9%)\n",
      "\n",
      "\n",
      "[Epoch 88]\n",
      "loss: 2.653589 [0/28137]\n",
      "loss: 2.660958 [1280/28137]\n",
      "loss: 2.668814 [2560/28137]\n",
      "loss: 2.653390 [3840/28137]\n",
      "loss: 2.668835 [5120/28137]\n",
      "loss: 2.676403 [6400/28137]\n",
      "loss: 2.676364 [7680/28137]\n",
      "loss: 2.653237 [8960/28137]\n",
      "loss: 2.676548 [10240/28137]\n",
      "loss: 2.653252 [11520/28137]\n",
      "loss: 2.630160 [12800/28137]\n",
      "loss: 2.653230 [14080/28137]\n",
      "loss: 2.660958 [15360/28137]\n",
      "loss: 2.653265 [16640/28137]\n",
      "loss: 2.653236 [17920/28137]\n",
      "loss: 2.660992 [19200/28137]\n",
      "loss: 2.645536 [20480/28137]\n",
      "loss: 2.660933 [21760/28137]\n",
      "loss: 2.653262 [23040/28137]\n",
      "loss: 2.669006 [24320/28137]\n",
      "loss: 2.637862 [25600/28137]\n",
      "loss: 2.668609 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.660031, Accuracy: 3612/3725 (97.0%)\n",
      "\n",
      "\n",
      "[Epoch 89]\n",
      "loss: 2.660914 [0/28137]\n",
      "loss: 2.653227 [1280/28137]\n",
      "loss: 2.645524 [2560/28137]\n",
      "loss: 2.653245 [3840/28137]\n",
      "loss: 2.683989 [5120/28137]\n",
      "loss: 2.630524 [6400/28137]\n",
      "loss: 2.630944 [7680/28137]\n",
      "loss: 2.630166 [8960/28137]\n",
      "loss: 2.637958 [10240/28137]\n",
      "loss: 2.630165 [11520/28137]\n",
      "loss: 2.638335 [12800/28137]\n",
      "loss: 2.630163 [14080/28137]\n",
      "loss: 2.637645 [15360/28137]\n",
      "loss: 2.630167 [16640/28137]\n",
      "loss: 2.634135 [17920/28137]\n",
      "loss: 2.630242 [19200/28137]\n",
      "loss: 2.630148 [20480/28137]\n",
      "loss: 2.630150 [21760/28137]\n",
      "loss: 2.630153 [23040/28137]\n",
      "loss: 2.630202 [24320/28137]\n",
      "loss: 2.637756 [25600/28137]\n",
      "loss: 2.630151 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631842, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 90]\n",
      "loss: 2.630167 [0/28137]\n",
      "loss: 2.630231 [1280/28137]\n",
      "loss: 2.630152 [2560/28137]\n",
      "loss: 2.630152 [3840/28137]\n",
      "loss: 2.637971 [5120/28137]\n",
      "loss: 2.630146 [6400/28137]\n",
      "loss: 2.630157 [7680/28137]\n",
      "loss: 2.630166 [8960/28137]\n",
      "loss: 2.630150 [10240/28137]\n",
      "loss: 2.630162 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.637960 [14080/28137]\n",
      "loss: 2.630155 [15360/28137]\n",
      "loss: 2.630150 [16640/28137]\n",
      "loss: 2.630449 [17920/28137]\n",
      "loss: 2.630150 [19200/28137]\n",
      "loss: 2.630177 [20480/28137]\n",
      "loss: 2.630150 [21760/28137]\n",
      "loss: 2.630336 [23040/28137]\n",
      "loss: 2.636147 [24320/28137]\n",
      "loss: 2.630453 [25600/28137]\n",
      "loss: 2.630174 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.632157, Accuracy: 3718/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 91]\n",
      "loss: 2.637958 [0/28137]\n",
      "loss: 2.630382 [1280/28137]\n",
      "loss: 2.630167 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.630146 [5120/28137]\n",
      "loss: 2.630151 [6400/28137]\n",
      "loss: 2.637960 [7680/28137]\n",
      "loss: 2.630150 [8960/28137]\n",
      "loss: 2.630146 [10240/28137]\n",
      "loss: 2.630147 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.630149 [14080/28137]\n",
      "loss: 2.630148 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630147 [17920/28137]\n",
      "loss: 2.630152 [19200/28137]\n",
      "loss: 2.637959 [20480/28137]\n",
      "loss: 2.630156 [21760/28137]\n",
      "loss: 2.630146 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630146 [25600/28137]\n",
      "loss: 2.634600 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.632048, Accuracy: 3718/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 92]\n",
      "loss: 2.630156 [0/28137]\n",
      "loss: 2.630156 [1280/28137]\n",
      "loss: 2.630196 [2560/28137]\n",
      "loss: 2.638203 [3840/28137]\n",
      "loss: 2.630153 [5120/28137]\n",
      "loss: 2.630147 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630146 [8960/28137]\n",
      "loss: 2.630147 [10240/28137]\n",
      "loss: 2.630157 [11520/28137]\n",
      "loss: 2.637961 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630149 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630149 [17920/28137]\n",
      "loss: 2.630146 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630178 [23040/28137]\n",
      "loss: 2.630146 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630151 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631792, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 93]\n",
      "loss: 2.637959 [0/28137]\n",
      "loss: 2.637957 [1280/28137]\n",
      "loss: 2.637959 [2560/28137]\n",
      "loss: 2.630146 [3840/28137]\n",
      "loss: 2.630145 [5120/28137]\n",
      "loss: 2.630165 [6400/28137]\n",
      "loss: 2.630147 [7680/28137]\n",
      "loss: 2.630149 [8960/28137]\n",
      "loss: 2.637959 [10240/28137]\n",
      "loss: 2.630151 [11520/28137]\n",
      "loss: 2.637958 [12800/28137]\n",
      "loss: 2.630150 [14080/28137]\n",
      "loss: 2.630150 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630145 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630146 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630147 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631756, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 94]\n",
      "loss: 2.630150 [0/28137]\n",
      "loss: 2.630147 [1280/28137]\n",
      "loss: 2.630147 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.630145 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.637962 [7680/28137]\n",
      "loss: 2.630146 [8960/28137]\n",
      "loss: 2.630145 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.630148 [12800/28137]\n",
      "loss: 2.630151 [14080/28137]\n",
      "loss: 2.630146 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630150 [19200/28137]\n",
      "loss: 2.630146 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.637963 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631741, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 95]\n",
      "loss: 2.630146 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.630146 [2560/28137]\n",
      "loss: 2.637958 [3840/28137]\n",
      "loss: 2.630148 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.637957 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.630146 [12800/28137]\n",
      "loss: 2.637957 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630146 [17920/28137]\n",
      "loss: 2.637962 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.637958 [21760/28137]\n",
      "loss: 2.630153 [23040/28137]\n",
      "loss: 2.630146 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630146 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631706, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "[Epoch 96]\n",
      "loss: 2.630146 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.637957 [5120/28137]\n",
      "loss: 2.630146 [6400/28137]\n",
      "loss: 2.645770 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.630147 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.637961 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630147 [19200/28137]\n",
      "loss: 2.637957 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630146 [24320/28137]\n",
      "loss: 2.630148 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631699, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "[Epoch 97]\n",
      "loss: 2.630145 [0/28137]\n",
      "loss: 2.630146 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630148 [3840/28137]\n",
      "loss: 2.630147 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.630147 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630147 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630146 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631697, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "[Epoch 98]\n",
      "loss: 2.630145 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.637957 [5120/28137]\n",
      "loss: 2.637959 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.637957 [10240/28137]\n",
      "loss: 2.630148 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630145 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630149 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631717, Accuracy: 3719/3725 (99.8%)\n",
      "\n",
      "\n",
      "[Epoch 99]\n",
      "loss: 2.630145 [0/28137]\n",
      "loss: 2.630145 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.630145 [5120/28137]\n",
      "loss: 2.637957 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.630145 [8960/28137]\n",
      "loss: 2.630145 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.630145 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630146 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.637958 [17920/28137]\n",
      "loss: 2.637957 [19200/28137]\n",
      "loss: 2.630146 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.630145 [24320/28137]\n",
      "loss: 2.630149 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631673, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "[Epoch 100]\n",
      "loss: 2.630145 [0/28137]\n",
      "loss: 2.630147 [1280/28137]\n",
      "loss: 2.630145 [2560/28137]\n",
      "loss: 2.630145 [3840/28137]\n",
      "loss: 2.630145 [5120/28137]\n",
      "loss: 2.630145 [6400/28137]\n",
      "loss: 2.630145 [7680/28137]\n",
      "loss: 2.645770 [8960/28137]\n",
      "loss: 2.630145 [10240/28137]\n",
      "loss: 2.630145 [11520/28137]\n",
      "loss: 2.637957 [12800/28137]\n",
      "loss: 2.630145 [14080/28137]\n",
      "loss: 2.630145 [15360/28137]\n",
      "loss: 2.630145 [16640/28137]\n",
      "loss: 2.630145 [17920/28137]\n",
      "loss: 2.630147 [19200/28137]\n",
      "loss: 2.630145 [20480/28137]\n",
      "loss: 2.630145 [21760/28137]\n",
      "loss: 2.630145 [23040/28137]\n",
      "loss: 2.637958 [24320/28137]\n",
      "loss: 2.630145 [25600/28137]\n",
      "loss: 2.630145 [26880/28137]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 2.631676, Accuracy: 3720/3725 (99.9%)\n",
      "\n",
      "\n",
      "Done!\n",
      "Training time: 1996.3672\n"
     ]
    }
   ],
   "source": [
    "## Training Operation ##\n",
    "start = time.time()\n",
    "for t in range(epochs):\n",
    "  print(f\"\\n[Epoch {t+1}]\")\n",
    "  train(train_dataloader, model, loss_fn, optimizer)\n",
    "  validation(model, val_dataloader)\n",
    "print(\"\\nDone!\")\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: {:.4f}\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Test Result***\n",
      "Average loss: 2.631368, Accuracy: 3556/3560 (99.9%)\n",
      "\n",
      "Test time: 2.5128\n"
     ]
    }
   ],
   "source": [
    "## Test operation ##\n",
    "start = time.time()\n",
    "test(model, test_dataloader)\n",
    "end = time.time()\n",
    "print(\"Test time: {:.4f}\".format(end-start))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "torch.save(model, './model_231204_64x64.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
