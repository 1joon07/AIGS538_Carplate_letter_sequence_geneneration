{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, CenterCrop, Grayscale\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dataset as data\n",
    "import model as md\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "Batch_size = 32\n",
    "Optimizer_type = 'ADAM'\n",
    "Learning_rate = 1e-5\n",
    "Weight_decay = 0\n",
    "epochs = 15"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def Sample_visualize(dataloader) :\n",
    "  ## Visualize some preprocess images\n",
    "  ##\n",
    "  ## Input : dataloader of image dataset\n",
    "  ## Output : image plots\n",
    "\n",
    " dataiter = iter(dataloader)\n",
    " images, labels = next(dataiter)\n",
    " images = images.numpy()\n",
    " for i in range (2) :\n",
    "   plt.subplot(1,4,i+1)\n",
    "   plt.imshow(images[i].reshape(64,192), cmap='gray')\n",
    "   plt.xticks([])\n",
    "   plt.yticks([])\n",
    "\n",
    "   print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset', label_file='./CNN_generated_dataset/Labels.csv')\n",
    "train_loader = DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset_val', label_file='./CNN_generated_dataset_val/Labels.csv')\n",
    "val_loader = DataLoader(val_dataset, batch_size=Batch_size, shuffle=True)\n",
    "#\n",
    "# test_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset_test', label_file='./CNN_generated_dataset_test/Labels.csv')\n",
    "# test_loader = DataLoader(test_dataset, batch_size=Batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 0, 14, 20, 27, 26, 30,  9, 29, 27, 11, 21, 10, 25,  1, 11, 11, 14, 12,\n",
      "        19, 22, 34, 27, 20, 34, 12,  0,  7, 19,  5, 15, 26, 27]), tensor([ 4, 31, 30, 22, 16, 11,  8,  6,  3, 24, 19, 12, 15, 22, 14,  2, 23, 33,\n",
      "        23, 30, 12, 12,  2, 18, 34, 21, 18,  9, 21, 15, 19, 19]), tensor([ 2, 28, 30, 23, 25, 17, 10,  3,  2, 22,  7, 20, 26, 28, 22, 26, 32, 20,\n",
      "        27, 21, 11, 16,  0, 27, 33,  4, 18, 32,  4,  2, 15,  0]), tensor([32,  7, 21,  9, 17, 24,  4,  2,  4, 34, 13, 27, 34, 18, 31, 17,  5, 26,\n",
      "        21, 24, 16, 15,  8,  0, 10, 22, 25, 15, 24,  3, 13,  3]), tensor([18, 35, 12,  9, 35, 20, 31, 14, 34, 21,  3, 32, 35, 32, 24, 11,  3, 18,\n",
      "         1,  1,  1,  8,  0, 16, 34, 32, 22, 14, 35, 20, 29, 30]), tensor([12, 35,  5, 35, 35, 21, 30, 21, 32, 25, 27,  8, 35,  5, 30,  0, 28, 27,\n",
      "         7, 23, 20,  7,  2, 29, 35,  9, 21,  0, 35, 14, 22, 24]), tensor([12, 35,  6, 35, 35, 23, 35, 31,  3, 29, 12,  3, 35,  8, 13, 35,  1,  2,\n",
      "        35, 27, 35, 35,  0,  4, 35, 35, 22,  5, 35, 22,  4, 32]), tensor([19, 35, 19, 35, 35,  1, 35, 23, 11, 21,  9, 11, 35, 33, 32, 35, 35, 31,\n",
      "        35, 18, 35, 35, 10, 35, 35, 35,  0, 27, 35,  7, 33,  2]), tensor([27, 35, 35, 35, 35,  5, 35, 23, 35,  3, 10,  4, 35,  6, 34, 35, 35, 35,\n",
      "        35, 13, 35, 35,  3, 35, 35, 35, 14, 13, 35, 14, 33, 35]), tensor([ 9, 35, 35, 35, 35, 25, 35, 35, 35, 35, 35, 35, 35, 35, 12, 35, 35, 35,\n",
      "        35, 15, 35, 35, 19, 35, 35, 35, 23, 12, 35, 28, 35, 35]), tensor([35, 35, 35, 35, 35, 15, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
      "        35, 35, 35, 35, 35, 35, 35, 35, 28, 35, 35, 35, 35, 35])]\n",
      "[tensor([ 0, 14, 20, 27, 26, 30,  9, 29, 27, 11, 21, 10, 25,  1, 11, 11, 14, 12,\n",
      "        19, 22, 34, 27, 20, 34, 12,  0,  7, 19,  5, 15, 26, 27]), tensor([ 4, 31, 30, 22, 16, 11,  8,  6,  3, 24, 19, 12, 15, 22, 14,  2, 23, 33,\n",
      "        23, 30, 12, 12,  2, 18, 34, 21, 18,  9, 21, 15, 19, 19]), tensor([ 2, 28, 30, 23, 25, 17, 10,  3,  2, 22,  7, 20, 26, 28, 22, 26, 32, 20,\n",
      "        27, 21, 11, 16,  0, 27, 33,  4, 18, 32,  4,  2, 15,  0]), tensor([32,  7, 21,  9, 17, 24,  4,  2,  4, 34, 13, 27, 34, 18, 31, 17,  5, 26,\n",
      "        21, 24, 16, 15,  8,  0, 10, 22, 25, 15, 24,  3, 13,  3]), tensor([18, 35, 12,  9, 35, 20, 31, 14, 34, 21,  3, 32, 35, 32, 24, 11,  3, 18,\n",
      "         1,  1,  1,  8,  0, 16, 34, 32, 22, 14, 35, 20, 29, 30]), tensor([12, 35,  5, 35, 35, 21, 30, 21, 32, 25, 27,  8, 35,  5, 30,  0, 28, 27,\n",
      "         7, 23, 20,  7,  2, 29, 35,  9, 21,  0, 35, 14, 22, 24]), tensor([12, 35,  6, 35, 35, 23, 35, 31,  3, 29, 12,  3, 35,  8, 13, 35,  1,  2,\n",
      "        35, 27, 35, 35,  0,  4, 35, 35, 22,  5, 35, 22,  4, 32]), tensor([19, 35, 19, 35, 35,  1, 35, 23, 11, 21,  9, 11, 35, 33, 32, 35, 35, 31,\n",
      "        35, 18, 35, 35, 10, 35, 35, 35,  0, 27, 35,  7, 33,  2]), tensor([27, 35, 35, 35, 35,  5, 35, 23, 35,  3, 10,  4, 35,  6, 34, 35, 35, 35,\n",
      "        35, 13, 35, 35,  3, 35, 35, 35, 14, 13, 35, 14, 33, 35]), tensor([ 9, 35, 35, 35, 35, 25, 35, 35, 35, 35, 35, 35, 35, 35, 12, 35, 35, 35,\n",
      "        35, 15, 35, 35, 19, 35, 35, 35, 23, 12, 35, 28, 35, 35]), tensor([35, 35, 35, 35, 35, 15, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
      "        35, 35, 35, 35, 35, 35, 35, 35, 28, 35, 35, 35, 35, 35])]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sample_visualize(train_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 48, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(48, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=18720, out_features=100, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=100, out_features=6, bias=True)\n",
      "    (12): ReLU()\n",
      "  )\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout(p=0.25, inplace=False)\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout3): Dropout(p=0.25, inplace=False)\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout4): Dropout(p=0.25, inplace=False)\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout5): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=8448, out_features=1024, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = md.CNN(init_weights=False)\n",
    "model.to(DEVICE)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "if Optimizer_type == 'ADAM' :\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)\n",
    "elif Optimizer_type == 'SGD' :\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "## Training function ##\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  for batch_idx, (X,y) in enumerate(dataloader):\n",
    "\n",
    "    X = X.to(DEVICE)\n",
    "    pred0, pred1, pred2, pred3, pred4, pred5, pred6, pred7, pred8, pred9, pred10 = model(X)\n",
    "    # loss = 0.\n",
    "    # for idx in range(11):\n",
    "    #   y[idx] = y[idx].to(DEVICE)\n",
    "    #   loss += loss_fn(torch.tensor(pred[idx], dtype=torch.float32), y[idx])\n",
    "    for idx in range(11):\n",
    "      y[idx] = y[idx].to(DEVICE)\n",
    "\n",
    "    loss0 = loss_fn(pred0, y[0])\n",
    "    loss1 = loss_fn(pred1, y[1])\n",
    "    loss2 = loss_fn(pred2, y[2])\n",
    "    loss3 = loss_fn(pred3, y[3])\n",
    "    loss4 = loss_fn(pred4, y[4])\n",
    "    loss5 = loss_fn(pred5, y[5])\n",
    "    loss6 = loss_fn(pred6, y[6])\n",
    "    loss7 = loss_fn(pred7, y[7])\n",
    "    loss8 = loss_fn(pred8, y[8])\n",
    "    loss9 = loss_fn(pred9, y[9])\n",
    "    loss10 = loss_fn(pred10, y[10])\n",
    "    loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6 + loss7 + loss8 + loss9 + loss10\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.requires_grad_(True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 5 == 0:\n",
    "      print('loss: {:.6f} [{}/{}]'.format(loss.item(), batch_idx*len(X), len(dataloader.dataset)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "## Validation function ##\n",
    "def validation(model, valdata):\n",
    "  ## Input : trained model, validation data\n",
    "  ## Output : validation loss\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0\n",
    "  char_correct = 0\n",
    "  plate_correct = 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in valdata:\n",
    "      X = X.to(DEVICE)\n",
    "      for idx in range(11):\n",
    "        y[idx] = y[idx].to(DEVICE)\n",
    "      val_pred0, val_pred1, val_pred2, val_pred3, val_pred4, val_pred5, val_pred6, val_pred7, val_pred8, val_pred9, val_pred10 = model(X)\n",
    "\n",
    "      val_loss0 = loss_fn(val_pred0, y[0])\n",
    "      val_loss1 = loss_fn(val_pred1, y[1])\n",
    "      val_loss2 = loss_fn(val_pred2, y[2])\n",
    "      val_loss3 = loss_fn(val_pred3, y[3])\n",
    "      val_loss4 = loss_fn(val_pred4, y[4])\n",
    "      val_loss5 = loss_fn(val_pred5, y[5])\n",
    "      val_loss6 = loss_fn(val_pred6, y[6])\n",
    "      val_loss7 = loss_fn(val_pred7, y[7])\n",
    "      val_loss8 = loss_fn(val_pred8, y[8])\n",
    "      val_loss9 = loss_fn(val_pred9, y[9])\n",
    "      val_loss10 = loss_fn(val_pred10, y[10])\n",
    "\n",
    "      val_loss += val_loss0 + val_loss1 + val_loss2 + val_loss3 + val_loss4 + val_loss5 + val_loss6 + val_loss7 + val_loss8 + val_loss9 + val_loss10\n",
    "\n",
    "      val_pred0 = val_pred0.argmax(dim=-1, keepdim=True)\n",
    "      val_pred1 = val_pred1.argmax(dim=-1, keepdim=True)\n",
    "      val_pred2 = val_pred2.argmax(dim=-1, keepdim=True)\n",
    "      val_pred3 = val_pred3.argmax(dim=-1, keepdim=True)\n",
    "      val_pred4 = val_pred4.argmax(dim=-1, keepdim=True)\n",
    "      val_pred5 = val_pred5.argmax(dim=-1, keepdim=True)\n",
    "      val_pred6 = val_pred6.argmax(dim=-1, keepdim=True)\n",
    "      val_pred7 = val_pred7.argmax(dim=-1, keepdim=True)\n",
    "      val_pred8 = val_pred8.argmax(dim=-1, keepdim=True)\n",
    "      val_pred9 = val_pred9.argmax(dim=-1, keepdim=True)\n",
    "      val_pred10 = val_pred10.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "      char_correct += val_pred0.eq(y[0].view_as(val_pred0)).sum().item()\n",
    "      char_correct += val_pred1.eq(y[1].view_as(val_pred1)).sum().item()\n",
    "      char_correct += val_pred2.eq(y[2].view_as(val_pred2)).sum().item()\n",
    "      char_correct += val_pred3.eq(y[3].view_as(val_pred3)).sum().item()\n",
    "      char_correct += val_pred4.eq(y[4].view_as(val_pred4)).sum().item()\n",
    "      char_correct += val_pred5.eq(y[5].view_as(val_pred5)).sum().item()\n",
    "      char_correct += val_pred6.eq(y[6].view_as(val_pred6)).sum().item()\n",
    "      char_correct += val_pred7.eq(y[7].view_as(val_pred7)).sum().item()\n",
    "      char_correct += val_pred8.eq(y[8].view_as(val_pred8)).sum().item()\n",
    "      char_correct += val_pred9.eq(y[9].view_as(val_pred9)).sum().item()\n",
    "      char_correct += val_pred10.eq(y[10].view_as(val_pred10)).sum().item()\n",
    "\n",
    "      tensors = [val_pred0.eq(y[0].view_as(val_pred0)),\n",
    "                 val_pred1.eq(y[1].view_as(val_pred1)),\n",
    "                 val_pred2.eq(y[2].view_as(val_pred2)),\n",
    "                 val_pred3.eq(y[3].view_as(val_pred3)),\n",
    "                 val_pred4.eq(y[4].view_as(val_pred4)),\n",
    "                 val_pred5.eq(y[5].view_as(val_pred5)),\n",
    "                 val_pred6.eq(y[6].view_as(val_pred6)),\n",
    "                 val_pred7.eq(y[7].view_as(val_pred7)),\n",
    "                 val_pred8.eq(y[8].view_as(val_pred8)),\n",
    "                 val_pred9.eq(y[9].view_as(val_pred9)),\n",
    "                 val_pred10.eq(y[10].view_as(val_pred10))]\n",
    "\n",
    "      combined_tensor = torch.stack(tensors)\n",
    "      result = torch.all(combined_tensor, dim=0)\n",
    "      plate_correct = result.sum().item()\n",
    "\n",
    "  val_loss /= len(valdata.dataset)\n",
    "  print('\\n***Validation Result***\\nAverage loss: {:.6f}, Plate Accuracy: {}/{} ({:.1f}%), Character Accuracy: {}/{} ({:.1f}%)\\n'.format(val_loss,\n",
    "                                                                                                                                         plate_correct,\n",
    "                                                                                                                                         len(valdata.dataset),\n",
    "                                                                                                                                         100*plate_correct/len(valdata.dataset),\n",
    "                                                                                                                                         char_correct,\n",
    "                                                                                                                                         len(valdata.dataset)*11,\n",
    "                                                                                                                                         100*char_correct/(len(valdata.dataset)*11)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1]\n",
      "loss: 36.939278 [0/4000]\n",
      "loss: 36.064114 [160/4000]\n",
      "loss: 36.938988 [320/4000]\n",
      "loss: 36.845112 [480/4000]\n",
      "loss: 36.563747 [640/4000]\n",
      "loss: 36.438629 [800/4000]\n",
      "loss: 36.813511 [960/4000]\n",
      "loss: 36.469803 [1120/4000]\n",
      "loss: 36.719704 [1280/4000]\n",
      "loss: 36.625950 [1440/4000]\n",
      "loss: 36.407139 [1600/4000]\n",
      "loss: 36.813354 [1760/4000]\n",
      "loss: 36.594643 [1920/4000]\n",
      "loss: 37.282070 [2080/4000]\n",
      "loss: 37.000832 [2240/4000]\n",
      "loss: 37.000832 [2400/4000]\n",
      "loss: 36.813297 [2560/4000]\n",
      "loss: 36.688293 [2720/4000]\n",
      "loss: 36.844532 [2880/4000]\n",
      "loss: 36.813297 [3040/4000]\n",
      "loss: 36.157066 [3200/4000]\n",
      "loss: 36.438293 [3360/4000]\n",
      "loss: 35.688305 [3520/4000]\n",
      "loss: 36.813267 [3680/4000]\n",
      "loss: 37.375744 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.191509, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 2]\n",
      "loss: 36.813267 [0/4000]\n",
      "loss: 36.532013 [160/4000]\n",
      "loss: 36.969498 [320/4000]\n",
      "loss: 36.219513 [480/4000]\n",
      "loss: 36.219505 [640/4000]\n",
      "loss: 37.094482 [800/4000]\n",
      "loss: 37.250736 [960/4000]\n",
      "loss: 36.438236 [1120/4000]\n",
      "loss: 36.563248 [1280/4000]\n",
      "loss: 36.438251 [1440/4000]\n",
      "loss: 36.688240 [1600/4000]\n",
      "loss: 36.250748 [1760/4000]\n",
      "loss: 36.031990 [1920/4000]\n",
      "loss: 36.813225 [2080/4000]\n",
      "loss: 37.188225 [2240/4000]\n",
      "loss: 36.063240 [2400/4000]\n",
      "loss: 36.656979 [2560/4000]\n",
      "loss: 36.688225 [2720/4000]\n",
      "loss: 37.094463 [2880/4000]\n",
      "loss: 36.719475 [3040/4000]\n",
      "loss: 36.625725 [3200/4000]\n",
      "loss: 36.344475 [3360/4000]\n",
      "loss: 36.375729 [3520/4000]\n",
      "loss: 36.875717 [3680/4000]\n",
      "loss: 36.656967 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.189945, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 3]\n",
      "loss: 36.313225 [0/4000]\n",
      "loss: 36.469467 [160/4000]\n",
      "loss: 37.125710 [320/4000]\n",
      "loss: 36.688217 [480/4000]\n",
      "loss: 37.000706 [640/4000]\n",
      "loss: 36.500717 [800/4000]\n",
      "loss: 36.281963 [960/4000]\n",
      "loss: 37.031960 [1120/4000]\n",
      "loss: 36.625706 [1280/4000]\n",
      "loss: 36.969460 [1440/4000]\n",
      "loss: 36.500702 [1600/4000]\n",
      "loss: 36.063213 [1760/4000]\n",
      "loss: 36.469460 [1920/4000]\n",
      "loss: 36.531956 [2080/4000]\n",
      "loss: 36.719460 [2240/4000]\n",
      "loss: 36.656952 [2400/4000]\n",
      "loss: 36.469456 [2560/4000]\n",
      "loss: 37.438206 [2720/4000]\n",
      "loss: 36.781952 [2880/4000]\n",
      "loss: 36.406952 [3040/4000]\n",
      "loss: 36.313206 [3200/4000]\n",
      "loss: 37.281948 [3360/4000]\n",
      "loss: 36.750702 [3520/4000]\n",
      "loss: 36.781956 [3680/4000]\n",
      "loss: 36.594452 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.189632, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 4]\n",
      "loss: 37.281948 [0/4000]\n",
      "loss: 36.375698 [160/4000]\n",
      "loss: 35.844456 [320/4000]\n",
      "loss: 36.719448 [480/4000]\n",
      "loss: 36.500702 [640/4000]\n",
      "loss: 37.156944 [800/4000]\n",
      "loss: 36.156956 [960/4000]\n",
      "loss: 37.313194 [1120/4000]\n",
      "loss: 36.250698 [1280/4000]\n",
      "loss: 37.125694 [1440/4000]\n",
      "loss: 36.500694 [1600/4000]\n",
      "loss: 36.844448 [1760/4000]\n",
      "loss: 36.344448 [1920/4000]\n",
      "loss: 36.438198 [2080/4000]\n",
      "loss: 36.563202 [2240/4000]\n",
      "loss: 36.156948 [2400/4000]\n",
      "loss: 37.219444 [2560/4000]\n",
      "loss: 36.438194 [2720/4000]\n",
      "loss: 36.344444 [2880/4000]\n",
      "loss: 36.063190 [3040/4000]\n",
      "loss: 36.750694 [3200/4000]\n",
      "loss: 36.875694 [3360/4000]\n",
      "loss: 36.563194 [3520/4000]\n",
      "loss: 36.250702 [3680/4000]\n",
      "loss: 36.344444 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.191273, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 5]\n",
      "loss: 36.906940 [0/4000]\n",
      "loss: 37.063190 [160/4000]\n",
      "loss: 36.719444 [320/4000]\n",
      "loss: 36.938187 [480/4000]\n",
      "loss: 37.375690 [640/4000]\n",
      "loss: 36.063198 [800/4000]\n",
      "loss: 36.594444 [960/4000]\n",
      "loss: 37.188187 [1120/4000]\n",
      "loss: 36.875690 [1280/4000]\n",
      "loss: 36.906940 [1440/4000]\n",
      "loss: 36.875690 [1600/4000]\n",
      "loss: 36.813194 [1760/4000]\n",
      "loss: 36.938194 [1920/4000]\n",
      "loss: 36.750687 [2080/4000]\n",
      "loss: 37.219437 [2240/4000]\n",
      "loss: 36.594440 [2400/4000]\n",
      "loss: 36.938187 [2560/4000]\n",
      "loss: 36.688187 [2720/4000]\n",
      "loss: 36.906940 [2880/4000]\n",
      "loss: 36.531940 [3040/4000]\n",
      "loss: 36.844437 [3200/4000]\n",
      "loss: 36.938190 [3360/4000]\n",
      "loss: 37.531933 [3520/4000]\n",
      "loss: 36.438190 [3680/4000]\n",
      "loss: 36.688190 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.190569, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 6]\n",
      "loss: 37.031937 [0/4000]\n",
      "loss: 36.375687 [160/4000]\n",
      "loss: 36.969440 [320/4000]\n",
      "loss: 36.969437 [480/4000]\n",
      "loss: 36.969437 [640/4000]\n",
      "loss: 36.125687 [800/4000]\n",
      "loss: 36.531937 [960/4000]\n",
      "loss: 36.656937 [1120/4000]\n",
      "loss: 36.969437 [1280/4000]\n",
      "loss: 36.313190 [1440/4000]\n",
      "loss: 36.375690 [1600/4000]\n",
      "loss: 36.438187 [1760/4000]\n",
      "loss: 36.438190 [1920/4000]\n",
      "loss: 36.594437 [2080/4000]\n",
      "loss: 36.781937 [2240/4000]\n",
      "loss: 36.906937 [2400/4000]\n",
      "loss: 36.625690 [2560/4000]\n",
      "loss: 36.219440 [2720/4000]\n",
      "loss: 36.188187 [2880/4000]\n",
      "loss: 37.500687 [3040/4000]\n",
      "loss: 36.813187 [3200/4000]\n",
      "loss: 36.719437 [3360/4000]\n",
      "loss: 36.969437 [3520/4000]\n",
      "loss: 37.156937 [3680/4000]\n",
      "loss: 36.406937 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.190647, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 7]\n",
      "loss: 36.344440 [0/4000]\n",
      "loss: 36.000690 [160/4000]\n",
      "loss: 37.375687 [320/4000]\n",
      "loss: 36.469437 [480/4000]\n",
      "loss: 36.625687 [640/4000]\n",
      "loss: 37.469437 [800/4000]\n",
      "loss: 35.969440 [960/4000]\n",
      "loss: 36.531937 [1120/4000]\n",
      "loss: 36.438187 [1280/4000]\n",
      "loss: 37.344433 [1440/4000]\n",
      "loss: 36.625687 [1600/4000]\n",
      "loss: 36.750687 [1760/4000]\n",
      "loss: 37.000687 [1920/4000]\n",
      "loss: 36.719437 [2080/4000]\n",
      "loss: 37.500683 [2240/4000]\n",
      "loss: 36.344437 [2400/4000]\n",
      "loss: 37.031937 [2560/4000]\n",
      "loss: 37.063187 [2720/4000]\n",
      "loss: 36.594437 [2880/4000]\n",
      "loss: 36.594437 [3040/4000]\n",
      "loss: 37.063187 [3200/4000]\n",
      "loss: 37.094437 [3360/4000]\n",
      "loss: 36.188187 [3520/4000]\n",
      "loss: 37.000687 [3680/4000]\n",
      "loss: 37.344433 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.190100, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 8]\n",
      "loss: 36.813187 [0/4000]\n",
      "loss: 36.719437 [160/4000]\n",
      "loss: 36.625687 [320/4000]\n",
      "loss: 37.063187 [480/4000]\n",
      "loss: 37.063187 [640/4000]\n",
      "loss: 37.125683 [800/4000]\n",
      "loss: 36.844437 [960/4000]\n",
      "loss: 36.219437 [1120/4000]\n",
      "loss: 37.219433 [1280/4000]\n",
      "loss: 37.281933 [1440/4000]\n",
      "loss: 37.500683 [1600/4000]\n",
      "loss: 36.688187 [1760/4000]\n",
      "loss: 36.625687 [1920/4000]\n",
      "loss: 36.375687 [2080/4000]\n",
      "loss: 37.469437 [2240/4000]\n",
      "loss: 36.906933 [2400/4000]\n",
      "loss: 36.281937 [2560/4000]\n",
      "loss: 36.656937 [2720/4000]\n",
      "loss: 36.313183 [2880/4000]\n",
      "loss: 36.938183 [3040/4000]\n",
      "loss: 36.625687 [3200/4000]\n",
      "loss: 36.000687 [3360/4000]\n",
      "loss: 36.781937 [3520/4000]\n",
      "loss: 36.031937 [3680/4000]\n",
      "loss: 37.250683 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.189085, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 9]\n",
      "loss: 36.219437 [0/4000]\n",
      "loss: 36.281937 [160/4000]\n",
      "loss: 37.094437 [320/4000]\n",
      "loss: 36.563183 [480/4000]\n",
      "loss: 36.625687 [640/4000]\n",
      "loss: 36.969433 [800/4000]\n",
      "loss: 37.500683 [960/4000]\n",
      "loss: 36.844437 [1120/4000]\n",
      "loss: 37.563183 [1280/4000]\n",
      "loss: 36.750687 [1440/4000]\n",
      "loss: 37.688183 [1600/4000]\n",
      "loss: 36.625687 [1760/4000]\n",
      "loss: 37.188183 [1920/4000]\n",
      "loss: 36.344437 [2080/4000]\n",
      "loss: 36.438187 [2240/4000]\n",
      "loss: 36.563187 [2400/4000]\n",
      "loss: 36.250687 [2560/4000]\n",
      "loss: 36.219437 [2720/4000]\n",
      "loss: 36.125687 [2880/4000]\n",
      "loss: 37.063183 [3040/4000]\n",
      "loss: 37.000683 [3200/4000]\n",
      "loss: 36.719433 [3360/4000]\n",
      "loss: 37.063183 [3520/4000]\n",
      "loss: 36.781933 [3680/4000]\n",
      "loss: 36.250679 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.191819, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 10]\n",
      "loss: 36.250687 [0/4000]\n",
      "loss: 36.656937 [160/4000]\n",
      "loss: 36.625683 [320/4000]\n",
      "loss: 37.063183 [480/4000]\n",
      "loss: 36.781933 [640/4000]\n",
      "loss: 36.375687 [800/4000]\n",
      "loss: 36.250683 [960/4000]\n",
      "loss: 36.813183 [1120/4000]\n",
      "loss: 37.063183 [1280/4000]\n",
      "loss: 37.094433 [1440/4000]\n",
      "loss: 36.938183 [1600/4000]\n",
      "loss: 36.500687 [1760/4000]\n",
      "loss: 36.250683 [1920/4000]\n",
      "loss: 37.188183 [2080/4000]\n",
      "loss: 37.000679 [2240/4000]\n",
      "loss: 36.781937 [2400/4000]\n",
      "loss: 36.313187 [2560/4000]\n",
      "loss: 36.531937 [2720/4000]\n",
      "loss: 36.500687 [2880/4000]\n",
      "loss: 36.438183 [3040/4000]\n",
      "loss: 37.063175 [3200/4000]\n",
      "loss: 36.438179 [3360/4000]\n",
      "loss: 36.688179 [3520/4000]\n",
      "loss: 36.563187 [3680/4000]\n",
      "loss: 36.781929 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.190178, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 11]\n",
      "loss: 36.875683 [0/4000]\n",
      "loss: 37.063179 [160/4000]\n",
      "loss: 37.125679 [320/4000]\n",
      "loss: 36.406933 [480/4000]\n",
      "loss: 36.344433 [640/4000]\n",
      "loss: 36.656933 [800/4000]\n",
      "loss: 36.406929 [960/4000]\n",
      "loss: 37.250683 [1120/4000]\n",
      "loss: 37.031929 [1280/4000]\n",
      "loss: 36.875679 [1440/4000]\n",
      "loss: 36.438183 [1600/4000]\n",
      "loss: 36.531929 [1760/4000]\n",
      "loss: 37.219429 [1920/4000]\n",
      "loss: 36.781933 [2080/4000]\n",
      "loss: 36.875679 [2240/4000]\n",
      "loss: 36.375683 [2400/4000]\n",
      "loss: 37.250683 [2560/4000]\n",
      "loss: 36.563179 [2720/4000]\n",
      "loss: 36.313187 [2880/4000]\n",
      "loss: 36.219429 [3040/4000]\n",
      "loss: 36.938187 [3200/4000]\n",
      "loss: 36.469425 [3360/4000]\n",
      "loss: 36.500679 [3520/4000]\n",
      "loss: 36.156925 [3680/4000]\n",
      "loss: 36.781933 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.191428, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 12]\n",
      "loss: 37.000679 [0/4000]\n",
      "loss: 36.063179 [160/4000]\n",
      "loss: 37.031929 [320/4000]\n",
      "loss: 36.344437 [480/4000]\n",
      "loss: 36.750679 [640/4000]\n",
      "loss: 36.875675 [800/4000]\n",
      "loss: 36.344429 [960/4000]\n",
      "loss: 37.281929 [1120/4000]\n",
      "loss: 36.875679 [1280/4000]\n",
      "loss: 37.063183 [1440/4000]\n",
      "loss: 37.219429 [1600/4000]\n",
      "loss: 36.781925 [1760/4000]\n",
      "loss: 36.281929 [1920/4000]\n",
      "loss: 37.031933 [2080/4000]\n",
      "loss: 36.656929 [2240/4000]\n",
      "loss: 36.844429 [2400/4000]\n",
      "loss: 36.906929 [2560/4000]\n",
      "loss: 37.000675 [2720/4000]\n",
      "loss: 36.344429 [2880/4000]\n",
      "loss: 36.813175 [3040/4000]\n",
      "loss: 37.031925 [3200/4000]\n",
      "loss: 37.406929 [3360/4000]\n",
      "loss: 36.969425 [3520/4000]\n",
      "loss: 36.313179 [3680/4000]\n",
      "loss: 37.156925 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.191116, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 13]\n",
      "loss: 36.500679 [0/4000]\n",
      "loss: 36.688179 [160/4000]\n",
      "loss: 35.938179 [320/4000]\n",
      "loss: 36.563179 [480/4000]\n",
      "loss: 37.406929 [640/4000]\n",
      "loss: 36.188179 [800/4000]\n",
      "loss: 36.156925 [960/4000]\n",
      "loss: 36.688179 [1120/4000]\n",
      "loss: 36.906929 [1280/4000]\n",
      "loss: 36.250679 [1440/4000]\n",
      "loss: 36.750679 [1600/4000]\n",
      "loss: 36.969429 [1760/4000]\n",
      "loss: 35.844429 [1920/4000]\n",
      "loss: 36.656929 [2080/4000]\n",
      "loss: 36.375679 [2240/4000]\n",
      "loss: 36.844429 [2400/4000]\n",
      "loss: 37.313175 [2560/4000]\n",
      "loss: 36.844429 [2720/4000]\n",
      "loss: 36.844425 [2880/4000]\n",
      "loss: 37.250675 [3040/4000]\n",
      "loss: 36.969425 [3200/4000]\n",
      "loss: 36.469429 [3360/4000]\n",
      "loss: 37.125675 [3520/4000]\n",
      "loss: 36.281929 [3680/4000]\n",
      "loss: 36.906929 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.191506, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 14]\n",
      "loss: 36.500679 [0/4000]\n",
      "loss: 36.250675 [160/4000]\n",
      "loss: 36.875675 [320/4000]\n",
      "loss: 36.875675 [480/4000]\n",
      "loss: 36.531925 [640/4000]\n",
      "loss: 36.938175 [800/4000]\n",
      "loss: 37.094425 [960/4000]\n",
      "loss: 36.906925 [1120/4000]\n",
      "loss: 36.188179 [1280/4000]\n",
      "loss: 37.219425 [1440/4000]\n",
      "loss: 36.750675 [1600/4000]\n",
      "loss: 36.000675 [1760/4000]\n",
      "loss: 36.563179 [1920/4000]\n",
      "loss: 35.906925 [2080/4000]\n",
      "loss: 36.938175 [2240/4000]\n",
      "loss: 36.563175 [2400/4000]\n",
      "loss: 37.906925 [2560/4000]\n",
      "loss: 37.000675 [2720/4000]\n",
      "loss: 37.344429 [2880/4000]\n",
      "loss: 36.750675 [3040/4000]\n",
      "loss: 36.719429 [3200/4000]\n",
      "loss: 37.281925 [3360/4000]\n",
      "loss: 36.750675 [3520/4000]\n",
      "loss: 36.656925 [3680/4000]\n",
      "loss: 36.625679 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.190569, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "[Epoch 15]\n",
      "loss: 37.125675 [0/4000]\n",
      "loss: 36.906925 [160/4000]\n",
      "loss: 36.500679 [320/4000]\n",
      "loss: 37.063175 [480/4000]\n",
      "loss: 37.031925 [640/4000]\n",
      "loss: 37.000675 [800/4000]\n",
      "loss: 36.094425 [960/4000]\n",
      "loss: 36.750675 [1120/4000]\n",
      "loss: 36.375675 [1280/4000]\n",
      "loss: 37.594425 [1440/4000]\n",
      "loss: 36.594429 [1600/4000]\n",
      "loss: 37.125679 [1760/4000]\n",
      "loss: 36.313175 [1920/4000]\n",
      "loss: 36.906925 [2080/4000]\n",
      "loss: 37.625675 [2240/4000]\n",
      "loss: 36.906925 [2400/4000]\n",
      "loss: 36.250675 [2560/4000]\n",
      "loss: 37.219425 [2720/4000]\n",
      "loss: 36.688175 [2880/4000]\n",
      "loss: 37.156925 [3040/4000]\n",
      "loss: 36.781925 [3200/4000]\n",
      "loss: 35.906925 [3360/4000]\n",
      "loss: 36.688175 [3520/4000]\n",
      "loss: 36.500675 [3680/4000]\n",
      "loss: 36.750675 [3840/4000]\n",
      "\n",
      "***Validation Result***\n",
      "Average loss: 1.192678, Plate Accuracy: 0/400 (0.0%), Character Accuracy: 1431/4400 (32.5%)\n",
      "\n",
      "\n",
      "Done!\n",
      "Training time: 1146.8888\n"
     ]
    }
   ],
   "source": [
    "## Training Operation ##\n",
    "start = time.time()\n",
    "for t in range(epochs):\n",
    "  print(f\"\\n[Epoch {t+1}]\")\n",
    "  train(train_loader, model, loss_fn, optimizer)\n",
    "  validation(model, val_loader)\n",
    "print(\"\\nDone!\")\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: {:.4f}\".format(end-start))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
