{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, CenterCrop, Grayscale\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dataset as data\n",
    "import model as md\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "Batch_size = 32\n",
    "Optimizer_type = 'ADAM'\n",
    "Learning_rate = 1e-5\n",
    "Weight_decay = 0\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Sample_visualize(dataloader) :\n",
    "  ## Visualize some preprocess images\n",
    "  ##\n",
    "  ## Input : dataloader of image dataset\n",
    "  ## Output : image plots\n",
    "\n",
    " dataiter = iter(dataloader)\n",
    " images, labels = next(dataiter)\n",
    " # images = images.numpy()\n",
    " for i in range (2) :\n",
    "   plt.subplot(1,4,i+1)\n",
    "   plt.imshow(images[i].reshape((64, 192)), cmap='gray')\n",
    "   plt.xticks([])\n",
    "   plt.yticks([])\n",
    "   print(images.size())\n",
    "   print(labels)\n",
    "\n",
    "def visualize_dataset(dataset):\n",
    "  ## Visualize some preprocess images\n",
    "  ##\n",
    "  ## Input : DATASET of image dataset\n",
    "  ## Output : image plots\n",
    "  images, labels = dataset[0]\n",
    "  print(images.size())\n",
    "  images = images.numpy()\n",
    "  plt.imshow(images.reshape((64, 192)), cmap='gray')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset', label_file='./CNN_generated_dataset/Labels.csv')\n",
    "# train_loader = DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\n",
    "\n",
    "# val_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset_val', label_file='./CNN_generated_dataset_val/Labels.csv')\n",
    "# val_loader = DataLoader(val_dataset, batch_size=Batch_size, shuffle=True)\n",
    "#\n",
    "# test_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset_test', label_file='./CNN_generated_dataset_test/Labels.csv')\n",
    "# test_loader = DataLoader(test_dataset, batch_size=Batch_size, shuffle=True)\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "full_dataset = data.LicensePlateDataset(resize_size=(64, 192),directory='./CNN_generated_dataset', label_file='./CNN_generated_dataset/Labels.csv')\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 192])\n",
      "tensor([[ 8,  0, 18, 20, 11,  9,  1,  1,  5, 30, 24],\n",
      "        [13, 21, 15, 34, 27, 21, 20,  0, 26, 28, 34],\n",
      "        [19, 15, 22,  2, 12, 31, 24, 30, 27,  8, 26],\n",
      "        [ 6, 24, 26, 28,  2, 23, 17,  9, 29,  0,  4],\n",
      "        [ 5,  2,  7, 20, 24, 15,  4, 18, 13,  5, 14],\n",
      "        [10,  0, 30, 30, 25, 17, 21, 10,  5, 18, 18],\n",
      "        [27, 34, 15, 20, 18, 17, 33, 23, 19, 20, 31],\n",
      "        [17,  2, 24, 21, 11,  1, 15, 14, 15, 10, 22],\n",
      "        [15,  3,  2, 11, 10, 30, 22,  8,  9,  1, 12],\n",
      "        [ 7, 19,  6,  0, 26, 24,  4, 12, 34, 28, 12],\n",
      "        [34, 27, 10, 32, 13,  6, 16, 10, 23,  3,  7],\n",
      "        [16, 19, 14,  1,  5, 24, 24, 17, 10, 23, 24],\n",
      "        [16, 33, 33, 25,  4, 25, 10, 15, 24,  3, 15],\n",
      "        [31,  2, 14,  2, 14,  6, 19, 16,  1, 21, 11],\n",
      "        [ 5, 34, 11, 14, 12, 15, 23, 34, 12,  7,  5],\n",
      "        [ 5, 32,  9, 15, 15, 16, 22, 15,  4, 21, 10],\n",
      "        [21, 30,  3, 34, 14, 19,  1,  0, 17,  9, 30],\n",
      "        [ 0, 25, 29, 34, 27, 34, 31, 21, 22, 18, 30],\n",
      "        [28, 26, 16, 31,  1, 16,  7,  8, 27, 27, 20],\n",
      "        [ 9, 28,  2, 21, 19,  0,  0, 25, 23, 15, 11],\n",
      "        [ 6, 21,  6,  2, 21, 26, 16, 11, 26, 31, 26],\n",
      "        [18, 33, 15, 32, 12,  4, 34,  1, 20, 27, 14],\n",
      "        [22, 22, 33, 22,  6, 28,  9, 25,  2,  1,  3],\n",
      "        [23,  9, 22, 28, 27, 30, 19,  5, 32,  9, 25],\n",
      "        [ 5, 11, 34,  4, 11,  7, 19,  3, 14, 12, 17],\n",
      "        [16, 29,  7, 28, 17,  6, 19, 34, 20,  2, 17],\n",
      "        [26, 15, 13, 21, 17, 21, 29,  7, 14, 25, 24],\n",
      "        [34, 34, 25,  4, 18, 20,  0, 33, 21, 34, 32],\n",
      "        [12,  7,  7, 32, 12, 19, 21, 27,  7, 34, 26],\n",
      "        [10,  8, 24, 20, 12, 32, 31, 15, 21, 34, 10],\n",
      "        [20, 31,  7, 32, 32,  6, 23, 26,  2,  1, 31],\n",
      "        [25, 21, 22, 13,  4, 26,  8, 30, 21, 14,  5]])\n",
      "torch.Size([32, 1, 64, 192])\n",
      "tensor([[ 8,  0, 18, 20, 11,  9,  1,  1,  5, 30, 24],\n",
      "        [13, 21, 15, 34, 27, 21, 20,  0, 26, 28, 34],\n",
      "        [19, 15, 22,  2, 12, 31, 24, 30, 27,  8, 26],\n",
      "        [ 6, 24, 26, 28,  2, 23, 17,  9, 29,  0,  4],\n",
      "        [ 5,  2,  7, 20, 24, 15,  4, 18, 13,  5, 14],\n",
      "        [10,  0, 30, 30, 25, 17, 21, 10,  5, 18, 18],\n",
      "        [27, 34, 15, 20, 18, 17, 33, 23, 19, 20, 31],\n",
      "        [17,  2, 24, 21, 11,  1, 15, 14, 15, 10, 22],\n",
      "        [15,  3,  2, 11, 10, 30, 22,  8,  9,  1, 12],\n",
      "        [ 7, 19,  6,  0, 26, 24,  4, 12, 34, 28, 12],\n",
      "        [34, 27, 10, 32, 13,  6, 16, 10, 23,  3,  7],\n",
      "        [16, 19, 14,  1,  5, 24, 24, 17, 10, 23, 24],\n",
      "        [16, 33, 33, 25,  4, 25, 10, 15, 24,  3, 15],\n",
      "        [31,  2, 14,  2, 14,  6, 19, 16,  1, 21, 11],\n",
      "        [ 5, 34, 11, 14, 12, 15, 23, 34, 12,  7,  5],\n",
      "        [ 5, 32,  9, 15, 15, 16, 22, 15,  4, 21, 10],\n",
      "        [21, 30,  3, 34, 14, 19,  1,  0, 17,  9, 30],\n",
      "        [ 0, 25, 29, 34, 27, 34, 31, 21, 22, 18, 30],\n",
      "        [28, 26, 16, 31,  1, 16,  7,  8, 27, 27, 20],\n",
      "        [ 9, 28,  2, 21, 19,  0,  0, 25, 23, 15, 11],\n",
      "        [ 6, 21,  6,  2, 21, 26, 16, 11, 26, 31, 26],\n",
      "        [18, 33, 15, 32, 12,  4, 34,  1, 20, 27, 14],\n",
      "        [22, 22, 33, 22,  6, 28,  9, 25,  2,  1,  3],\n",
      "        [23,  9, 22, 28, 27, 30, 19,  5, 32,  9, 25],\n",
      "        [ 5, 11, 34,  4, 11,  7, 19,  3, 14, 12, 17],\n",
      "        [16, 29,  7, 28, 17,  6, 19, 34, 20,  2, 17],\n",
      "        [26, 15, 13, 21, 17, 21, 29,  7, 14, 25, 24],\n",
      "        [34, 34, 25,  4, 18, 20,  0, 33, 21, 34, 32],\n",
      "        [12,  7,  7, 32, 12, 19, 21, 27,  7, 34, 26],\n",
      "        [10,  8, 24, 20, 12, 32, 31, 15, 21, 34, 10],\n",
      "        [20, 31,  7, 32, 32,  6, 23, 26,  2,  1, 31],\n",
      "        [25, 21, 22, 13,  4, 26,  8, 30, 21, 14,  5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize_dataset(full_dataset)\n",
    "Sample_visualize(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 48, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(48, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=18720, out_features=100, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=100, out_features=6, bias=True)\n",
      "    (12): ReLU()\n",
      "  )\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout(p=0.25, inplace=False)\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout3): Dropout(p=0.25, inplace=False)\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout4): Dropout(p=0.25, inplace=False)\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout5): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=8448, out_features=1024, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (output0): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output1): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output2): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output3): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output4): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output5): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output6): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output7): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output8): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output9): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (output10): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = md.CNN(init_weights=True)\n",
    "model.to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 60, 188]           1,664\n",
      "       BatchNorm2d-2          [-1, 64, 60, 188]             128\n",
      "              ReLU-3          [-1, 64, 60, 188]               0\n",
      "         MaxPool2d-4           [-1, 64, 30, 94]               0\n",
      "           Dropout-5           [-1, 64, 30, 94]               0\n",
      "            Conv2d-6          [-1, 128, 28, 92]          73,856\n",
      "       BatchNorm2d-7          [-1, 128, 28, 92]             256\n",
      "              ReLU-8          [-1, 128, 28, 92]               0\n",
      "         MaxPool2d-9          [-1, 128, 14, 46]               0\n",
      "          Dropout-10          [-1, 128, 14, 46]               0\n",
      "           Conv2d-11          [-1, 256, 12, 44]         295,168\n",
      "      BatchNorm2d-12          [-1, 256, 12, 44]             512\n",
      "             ReLU-13          [-1, 256, 12, 44]               0\n",
      "        MaxPool2d-14           [-1, 256, 6, 22]               0\n",
      "          Dropout-15           [-1, 256, 6, 22]               0\n",
      "           Conv2d-16           [-1, 512, 6, 22]       1,180,160\n",
      "      BatchNorm2d-17           [-1, 512, 6, 22]           1,024\n",
      "             ReLU-18           [-1, 512, 6, 22]               0\n",
      "        MaxPool2d-19           [-1, 512, 3, 11]               0\n",
      "          Dropout-20           [-1, 512, 3, 11]               0\n",
      "           Conv2d-21           [-1, 256, 3, 11]       1,179,904\n",
      "      BatchNorm2d-22           [-1, 256, 3, 11]             512\n",
      "             ReLU-23           [-1, 256, 3, 11]               0\n",
      "          Dropout-24           [-1, 256, 3, 11]               0\n",
      "          Flatten-25                 [-1, 8448]               0\n",
      "           Linear-26                 [-1, 1024]       8,651,776\n",
      "             ReLU-27                 [-1, 1024]               0\n",
      "           Linear-28                   [-1, 37]          37,925\n",
      "          Softmax-29                   [-1, 37]               0\n",
      "           Linear-30                   [-1, 37]          37,925\n",
      "          Softmax-31                   [-1, 37]               0\n",
      "           Linear-32                   [-1, 37]          37,925\n",
      "          Softmax-33                   [-1, 37]               0\n",
      "           Linear-34                   [-1, 37]          37,925\n",
      "          Softmax-35                   [-1, 37]               0\n",
      "           Linear-36                   [-1, 37]          37,925\n",
      "          Softmax-37                   [-1, 37]               0\n",
      "           Linear-38                   [-1, 37]          37,925\n",
      "          Softmax-39                   [-1, 37]               0\n",
      "           Linear-40                   [-1, 37]          37,925\n",
      "          Softmax-41                   [-1, 37]               0\n",
      "           Linear-42                   [-1, 37]          37,925\n",
      "          Softmax-43                   [-1, 37]               0\n",
      "           Linear-44                   [-1, 37]          37,925\n",
      "          Softmax-45                   [-1, 37]               0\n",
      "           Linear-46                   [-1, 37]          37,925\n",
      "          Softmax-47                   [-1, 37]               0\n",
      "           Linear-48                   [-1, 37]          37,925\n",
      "          Softmax-49                   [-1, 37]               0\n",
      "================================================================\n",
      "Total params: 11,802,135\n",
      "Trainable params: 11,802,135\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 33.84\n",
      "Params size (MB): 45.02\n",
      "Estimated Total Size (MB): 78.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "\n",
    "torchsummary.summary(model,input_size=(1,64,192))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# from torch.autograd import Variable\n",
    "#\n",
    "# x = Variable(torch.randn(1, 1, 64, 192))\n",
    "#\n",
    "# make_dot(model(x), params=dict(model.named_parameters())).render(\"graph\", format=\"png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "if Optimizer_type == 'ADAM' :\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)\n",
    "elif Optimizer_type == 'SGD' :\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Training function ##\n",
    "# def train(dataloader, model, loss_fn, optimizer):\n",
    "#   model.train()\n",
    "#   for batch_idx, (X,y) in enumerate(dataloader):\n",
    "\n",
    "#     X = X.to(DEVICE)\n",
    "#     pred0, pred1, pred2, pred3, pred4, pred5, pred6, pred7, pred8, pred9, pred10 = model(X)\n",
    "#     # loss = 0.\n",
    "#     # for idx in range(11):\n",
    "#     #   y[idx] = y[idx].to(DEVICE)\n",
    "#     #   loss += loss_fn(torch.tensor(pred[idx], dtype=torch.float32), y[idx])\n",
    "#     for idx in range(11):\n",
    "#       y[idx] = y[idx].to(DEVICE)\n",
    "\n",
    "#     loss0 = loss_fn(pred0, y[0])\n",
    "#     loss1 = loss_fn(pred1, y[1])\n",
    "#     loss2 = loss_fn(pred2, y[2])\n",
    "#     loss3 = loss_fn(pred3, y[3])\n",
    "#     loss4 = loss_fn(pred4, y[4])\n",
    "#     loss5 = loss_fn(pred5, y[5])\n",
    "#     loss6 = loss_fn(pred6, y[6])\n",
    "#     loss7 = loss_fn(pred7, y[7])\n",
    "#     loss8 = loss_fn(pred8, y[8])\n",
    "#     loss9 = loss_fn(pred9, y[9])\n",
    "#     loss10 = loss_fn(pred10, y[10])\n",
    "#     loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6 + loss7 + loss8 + loss9 + loss10\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.requires_grad_(True)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if batch_idx % 5 == 0:\n",
    "#       print('loss: {:.6f} [{}/{}]'.format(loss.item(), batch_idx*len(X), len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Validation function ##\n",
    "# def validation(model, valdata):\n",
    "#   ## Input : trained model, validation data\n",
    "#   ## Output : validation loss\n",
    "\n",
    "#   model.eval()\n",
    "#   val_loss = 0\n",
    "#   char_correct = 0\n",
    "#   plate_correct = 0\n",
    "#   with torch.no_grad():\n",
    "#     for X, y in valdata:\n",
    "#       X = X.to(DEVICE)\n",
    "#       for idx in range(11):\n",
    "#         y[idx] = y[idx].to(DEVICE)\n",
    "#       val_pred0, val_pred1, val_pred2, val_pred3, val_pred4, val_pred5, val_pred6, val_pred7, val_pred8, val_pred9, val_pred10 = model(X)\n",
    "\n",
    "#       val_loss0 = loss_fn(val_pred0, y[0])\n",
    "#       val_loss1 = loss_fn(val_pred1, y[1])\n",
    "#       val_loss2 = loss_fn(val_pred2, y[2])\n",
    "#       val_loss3 = loss_fn(val_pred3, y[3])\n",
    "#       val_loss4 = loss_fn(val_pred4, y[4])\n",
    "#       val_loss5 = loss_fn(val_pred5, y[5])\n",
    "#       val_loss6 = loss_fn(val_pred6, y[6])\n",
    "#       val_loss7 = loss_fn(val_pred7, y[7])\n",
    "#       val_loss8 = loss_fn(val_pred8, y[8])\n",
    "#       val_loss9 = loss_fn(val_pred9, y[9])\n",
    "#       val_loss10 = loss_fn(val_pred10, y[10])\n",
    "\n",
    "#       val_loss += val_loss0 + val_loss1 + val_loss2 + val_loss3 + val_loss4 + val_loss5 + val_loss6 + val_loss7 + val_loss8 + val_loss9 + val_loss10\n",
    "\n",
    "#       val_pred0 = val_pred0.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred1 = val_pred1.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred2 = val_pred2.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred3 = val_pred3.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred4 = val_pred4.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred5 = val_pred5.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred6 = val_pred6.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred7 = val_pred7.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred8 = val_pred8.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred9 = val_pred9.argmax(dim=-1, keepdim=True)\n",
    "#       val_pred10 = val_pred10.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "#       char_correct += val_pred0.eq(y[0].view_as(val_pred0)).sum().item()\n",
    "#       char_correct += val_pred1.eq(y[1].view_as(val_pred1)).sum().item()\n",
    "#       char_correct += val_pred2.eq(y[2].view_as(val_pred2)).sum().item()\n",
    "#       char_correct += val_pred3.eq(y[3].view_as(val_pred3)).sum().item()\n",
    "#       char_correct += val_pred4.eq(y[4].view_as(val_pred4)).sum().item()\n",
    "#       char_correct += val_pred5.eq(y[5].view_as(val_pred5)).sum().item()\n",
    "#       char_correct += val_pred6.eq(y[6].view_as(val_pred6)).sum().item()\n",
    "#       char_correct += val_pred7.eq(y[7].view_as(val_pred7)).sum().item()\n",
    "#       char_correct += val_pred8.eq(y[8].view_as(val_pred8)).sum().item()\n",
    "#       char_correct += val_pred9.eq(y[9].view_as(val_pred9)).sum().item()\n",
    "#       char_correct += val_pred10.eq(y[10].view_as(val_pred10)).sum().item()\n",
    "\n",
    "#       tensors = [val_pred0.eq(y[0].view_as(val_pred0)),\n",
    "#                  val_pred1.eq(y[1].view_as(val_pred1)),\n",
    "#                  val_pred2.eq(y[2].view_as(val_pred2)),\n",
    "#                  val_pred3.eq(y[3].view_as(val_pred3)),\n",
    "#                  val_pred4.eq(y[4].view_as(val_pred4)),\n",
    "#                  val_pred5.eq(y[5].view_as(val_pred5)),\n",
    "#                  val_pred6.eq(y[6].view_as(val_pred6)),\n",
    "#                  val_pred7.eq(y[7].view_as(val_pred7)),\n",
    "#                  val_pred8.eq(y[8].view_as(val_pred8)),\n",
    "#                  val_pred9.eq(y[9].view_as(val_pred9)),\n",
    "#                  val_pred10.eq(y[10].view_as(val_pred10))]\n",
    "\n",
    "#       combined_tensor = torch.stack(tensors)\n",
    "#       result = torch.all(combined_tensor, dim=0)\n",
    "#       plate_correct = result.sum().item()\n",
    "\n",
    "#   val_loss /= len(valdata.dataset)\n",
    "#   print('\\n***Validation Result***\\nAverage loss: {:.6f}, Plate Accuracy: {}/{} ({:.1f}%), Character Accuracy: {}/{} ({:.1f}%)\\n'.format(val_loss,\n",
    "#                                                                                                                                          plate_correct,\n",
    "#                                                                                                                                          len(valdata.dataset),\n",
    "#                                                                                                                                          100*plate_correct/len(valdata.dataset),\n",
    "#                                                                                                                                          char_correct,\n",
    "#                                                                                                                                          len(valdata.dataset)*11,\n",
    "#                                                                                                                                          100*char_correct/(len(valdata.dataset)*11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Training Operation ##\n",
    "# start = time.time()\n",
    "# for t in range(epochs):\n",
    "#   print(f\"\\n[Epoch {t+1}]\")\n",
    "#   train(train_loader, model, loss_fn, optimizer)\n",
    "#   validation(model, val_loader)\n",
    "# print(\"\\nDone!\")\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Training time: {:.4f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (image, labels) in enumerate(dataloader):\n",
    "        image = image.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)  # size [batch_size, 11]\n",
    "        predictions = model(image)  # size [batch_size, 11, num_classes]\n",
    "        # plt.imshow(image.reshape((64, 192)), cmap='gray')\n",
    "        # print(labels)\n",
    "        # print(predictions)\n",
    "        loss = 0\n",
    "        for i in range(11):  # compute loss for each label \n",
    "\n",
    "            loss += loss_fn(predictions[:, i, :], labels[:, i])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 5 == 0:\n",
    "            print(f'Loss: {loss.item()} at batch {batch_idx}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validation(model, valdata, loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    char_correct = 0\n",
    "    plate_correct = 0\n",
    "    total_chars = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in valdata:\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE) # label size : [batch_size, 11 ]\n",
    "\n",
    "            predictions = model(image) #Â size [batch_size, 11, num_class]\n",
    "            for idx in range(11):\n",
    "                val_loss += loss_fn(predictions[:, idx, :], label[:, idx])\n",
    "                # accuracy character per character\n",
    "                char_pred = predictions[:, idx, :].argmax(dim=-1)  \n",
    "                char_correct += (char_pred == label[:, idx]).sum().item() \n",
    "                total_chars += label.size(0)\n",
    "            #accuracy full plate\n",
    "            plate_pred_correct = (predictions.argmax(dim=-1) == label).all(1)  \n",
    "            plate_correct += plate_pred_correct.sum().item()\n",
    "\n",
    "    val_loss /= len(valdata.dataset)\n",
    "    print('\\n***Validation Result***\\nAverage loss: {:.6f}, Plate Accuracy: {}/{} ({:.1f}%), Character Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        val_loss, plate_correct, len(valdata.dataset), 100. * plate_correct / len(valdata.dataset),\n",
    "        char_correct, total_chars, 100. * char_correct / total_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1]\n",
      "Loss: 39.7155876159668 at batch 0\n",
      "Loss: 39.72095489501953 at batch 5\n",
      "Loss: 39.71471405029297 at batch 10\n",
      "Loss: 39.722164154052734 at batch 15\n",
      "Loss: 39.717594146728516 at batch 20\n",
      "Loss: 39.722694396972656 at batch 25\n",
      "Loss: 39.716346740722656 at batch 30\n",
      "Loss: 39.71990203857422 at batch 35\n",
      "Loss: 39.71772003173828 at batch 40\n",
      "Loss: 39.72145080566406 at batch 45\n",
      "Loss: 39.71713638305664 at batch 50\n",
      "Loss: 39.71205139160156 at batch 55\n",
      "Loss: 39.71516036987305 at batch 60\n",
      "Loss: 39.71269226074219 at batch 65\n",
      "Loss: 39.71324157714844 at batch 70\n",
      "Loss: 39.71086883544922 at batch 75\n",
      "Loss: 39.71636962890625 at batch 80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m      4\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m[Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m   \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m   validation(model, val_loader, loss_fn)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mDone!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[13], line 6\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(dataloader, model, loss_fn, optimizer)\u001B[0m\n\u001B[0;32m      4\u001B[0m image \u001B[38;5;241m=\u001B[39m image\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[0;32m      5\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(DEVICE)  \u001B[38;5;66;03m# size [batch_size, 11]\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# size [batch_size, 11, num_classes]\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# plt.imshow(image.reshape((64, 192)), cmap='gray')\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# print(labels)\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# print(predictions)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\model.py:137\u001B[0m, in \u001B[0;36mCNN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;66;03m# x = self.stlayer(x)\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool1(x)\n\u001B[0;32m    139\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout1(x)\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "## Training Operation ##\n",
    "start = time.time()\n",
    "for t in range(epochs):\n",
    "  print(f\"\\n[Epoch {t+1}]\")\n",
    "  train(train_loader, model, loss_fn, optimizer)\n",
    "  validation(model, val_loader, loss_fn)\n",
    "print(\"\\nDone!\")\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: {:.4f}\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
