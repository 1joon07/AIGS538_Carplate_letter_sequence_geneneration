{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, CenterCrop, Grayscale\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dataset as data\n",
    "import model as md\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "Batch_size = 32\n",
    "Optimizer_type = 'ADAM'\n",
    "Learning_rate = 1e-5\n",
    "Weight_decay = 0\n",
    "epochs = 15"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def Sample_visualize(dataloader) :\n",
    "  ## Visualize some preprocess images\n",
    "  ##\n",
    "  ## Input : dataloader of image dataset\n",
    "  ## Output : image plots\n",
    "\n",
    " dataiter = iter(dataloader)\n",
    " images, labels = next(dataiter)\n",
    " images = images.numpy()\n",
    " for i in range (2) :\n",
    "   plt.subplot(1,4,i+1)\n",
    "   plt.imshow(images[i].reshape(64,192), cmap='gray')\n",
    "   plt.xticks([])\n",
    "   plt.yticks([])\n",
    "\n",
    "   print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "train_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset', label_file='./CNN_generated_dataset/Labels.csv')\n",
    "train_loader = DataLoader(train_dataset, batch_size=Batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset_val', label_file='./CNN_generated_dataset_val/Labels.csv')\n",
    "val_loader = DataLoader(val_dataset, batch_size=Batch_size, shuffle=True)\n",
    "#\n",
    "# test_dataset = data.LicensePlateDataset(directory='./CNN_generated_dataset_test', label_file='./CNN_generated_dataset_test/Labels.csv')\n",
    "# test_loader = DataLoader(test_dataset, batch_size=Batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 9, 20, 18,  3,  3, 14, 28,  4, 23, 24, 13,  2, 29, 15,  0, 22, 10, 19,\n",
      "        17, 22, 11, 24,  5, 19, 31, 25, 25, 21,  7, 13, 12, 19]), tensor([ 9, 13, 32,  7, 27,  4, 32, 13, 12, 29, 31, 15,  5,  2, 29,  7, 18, 17,\n",
      "         9, 31, 30,  8,  8, 29,  0, 19,  6, 21, 24, 24, 15,  3]), tensor([14, 10, 21, 17, 29,  1, 22,  2, 15, 10,  7, 18, 19,  7, 27, 22, 24,  5,\n",
      "        20,  7,  4, 32,  6, 25, 16, 32, 14, 31, 27, 27, 34, 15]), tensor([28,  3, 10, 16,  2, 34, 18, 13,  6,  8,  8, 33,  0, 28, 31, 34,  9, 26,\n",
      "        25,  5,  6, 13, 34,  2,  5,  4,  5, 14,  1,  5, 21,  2]), tensor([14, 27, 19,  0, 35, 35, 21,  6, 22, 13, 17,  4, 27, 31,  9, 16, 35, 35,\n",
      "        17, 28, 28,  0, 11, 35, 30, 22, 25, 32, 23,  9, 13, 13]), tensor([26,  2, 18, 21, 35, 35, 18, 27, 35, 22, 15, 24, 24, 28,  4, 14, 35, 35,\n",
      "        13, 33, 21, 23, 29, 35, 23, 23,  2, 15, 12, 20, 10, 10]), tensor([13, 35, 30, 35, 35, 35,  4,  7, 35, 21, 16,  9, 18, 27, 31,  9, 35, 35,\n",
      "        32,  0,  5, 35, 24, 35,  0, 20, 34, 18, 24, 18, 35, 14]), tensor([15, 35, 23, 35, 35, 35,  6, 25, 35, 35, 32, 33, 33, 24, 20, 34, 35, 35,\n",
      "        27, 33, 19, 35, 18, 35, 35, 14,  8, 34, 35, 12, 35,  5]), tensor([15, 35,  3, 35, 35, 35, 34, 22, 35, 35, 35, 35, 35, 20, 24, 16, 35, 35,\n",
      "        13, 21, 18, 35, 35, 35, 35, 14,  1, 35, 35, 19, 35,  0]), tensor([ 7, 35,  2, 35, 35, 35,  3, 18, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
      "         3, 35,  8, 35, 35, 35, 35, 35,  0, 35, 35, 19, 35, 35]), tensor([ 2, 35, 35, 35, 35, 35, 21, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
      "        35, 35, 35, 35, 35, 35, 35, 35, 31, 35, 35, 35, 35, 35])]\n",
      "[tensor([ 9, 20, 18,  3,  3, 14, 28,  4, 23, 24, 13,  2, 29, 15,  0, 22, 10, 19,\n",
      "        17, 22, 11, 24,  5, 19, 31, 25, 25, 21,  7, 13, 12, 19]), tensor([ 9, 13, 32,  7, 27,  4, 32, 13, 12, 29, 31, 15,  5,  2, 29,  7, 18, 17,\n",
      "         9, 31, 30,  8,  8, 29,  0, 19,  6, 21, 24, 24, 15,  3]), tensor([14, 10, 21, 17, 29,  1, 22,  2, 15, 10,  7, 18, 19,  7, 27, 22, 24,  5,\n",
      "        20,  7,  4, 32,  6, 25, 16, 32, 14, 31, 27, 27, 34, 15]), tensor([28,  3, 10, 16,  2, 34, 18, 13,  6,  8,  8, 33,  0, 28, 31, 34,  9, 26,\n",
      "        25,  5,  6, 13, 34,  2,  5,  4,  5, 14,  1,  5, 21,  2]), tensor([14, 27, 19,  0, 35, 35, 21,  6, 22, 13, 17,  4, 27, 31,  9, 16, 35, 35,\n",
      "        17, 28, 28,  0, 11, 35, 30, 22, 25, 32, 23,  9, 13, 13]), tensor([26,  2, 18, 21, 35, 35, 18, 27, 35, 22, 15, 24, 24, 28,  4, 14, 35, 35,\n",
      "        13, 33, 21, 23, 29, 35, 23, 23,  2, 15, 12, 20, 10, 10]), tensor([13, 35, 30, 35, 35, 35,  4,  7, 35, 21, 16,  9, 18, 27, 31,  9, 35, 35,\n",
      "        32,  0,  5, 35, 24, 35,  0, 20, 34, 18, 24, 18, 35, 14]), tensor([15, 35, 23, 35, 35, 35,  6, 25, 35, 35, 32, 33, 33, 24, 20, 34, 35, 35,\n",
      "        27, 33, 19, 35, 18, 35, 35, 14,  8, 34, 35, 12, 35,  5]), tensor([15, 35,  3, 35, 35, 35, 34, 22, 35, 35, 35, 35, 35, 20, 24, 16, 35, 35,\n",
      "        13, 21, 18, 35, 35, 35, 35, 14,  1, 35, 35, 19, 35,  0]), tensor([ 7, 35,  2, 35, 35, 35,  3, 18, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
      "         3, 35,  8, 35, 35, 35, 35, 35,  0, 35, 35, 19, 35, 35]), tensor([ 2, 35, 35, 35, 35, 35, 21, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,\n",
      "        35, 35, 35, 35, 35, 35, 35, 35, 31, 35, 35, 35, 35, 35])]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sample_visualize(train_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 48, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(48, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=18720, out_features=100, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=100, out_features=6, bias=True)\n",
      "    (12): ReLU()\n",
      "  )\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout(p=0.25, inplace=False)\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout3): Dropout(p=0.25, inplace=False)\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout4): Dropout(p=0.25, inplace=False)\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout5): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=8448, out_features=1024, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=37, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = md.CNN(init_weights=False)\n",
    "model.to(DEVICE)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "if Optimizer_type == 'ADAM' :\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)\n",
    "elif Optimizer_type == 'SGD' :\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = Learning_rate, weight_decay = Weight_decay)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "## Training function ##\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  for batch_idx, (X,y) in enumerate(dataloader):\n",
    "\n",
    "    X = X.to(DEVICE)\n",
    "    pred0, pred1, pred2, pred3, pred4, pred5, pred6, pred7, pred8, pred9, pred10 = model(X)\n",
    "    print(pred0)\n",
    "    # loss = 0.\n",
    "    # for idx in range(11):\n",
    "    #   y[idx] = y[idx].to(DEVICE)\n",
    "    #   loss += loss_fn(torch.tensor(pred[idx], dtype=torch.float32), y[idx])\n",
    "    for idx in range(11):\n",
    "      y[idx] = y[idx].to(DEVICE)\n",
    "\n",
    "    loss0 = loss_fn(pred0, y[0])\n",
    "    loss1 = loss_fn(pred1, y[1])\n",
    "    loss2 = loss_fn(pred2, y[2])\n",
    "    loss3 = loss_fn(pred3, y[3])\n",
    "    loss4 = loss_fn(pred4, y[4])\n",
    "    loss5 = loss_fn(pred5, y[5])\n",
    "    loss6 = loss_fn(pred6, y[6])\n",
    "    loss7 = loss_fn(pred7, y[7])\n",
    "    loss8 = loss_fn(pred8, y[8])\n",
    "    loss9 = loss_fn(pred9, y[9])\n",
    "    loss10 = loss_fn(pred10, y[10])\n",
    "    loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6 + loss7 + loss8 + loss9 + loss10\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.requires_grad_(True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 5 == 0:\n",
    "      print('loss: {:.6f} [{}/{}]'.format(loss.item(), batch_idx*len(X), len(dataloader.dataset)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "## Validation function ##\n",
    "def validation(model, valdata):\n",
    "  ## Input : trained model, validation data\n",
    "  ## Output : validation loss\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0\n",
    "  char_correct = 0\n",
    "  plate_correct = 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in valdata:\n",
    "      X = X.to(DEVICE)\n",
    "      for idx in range(11):\n",
    "        y[idx] = y[idx].to(DEVICE)\n",
    "      val_pred0, val_pred1, val_pred2, val_pred3, val_pred4, val_pred5, val_pred6, val_pred7, val_pred8, val_pred9, val_pred10 = model(X)\n",
    "\n",
    "      val_loss0 = loss_fn(val_pred0, y[0])\n",
    "      val_loss1 = loss_fn(val_pred1, y[1])\n",
    "      val_loss2 = loss_fn(val_pred2, y[2])\n",
    "      val_loss3 = loss_fn(val_pred3, y[3])\n",
    "      val_loss4 = loss_fn(val_pred4, y[4])\n",
    "      val_loss5 = loss_fn(val_pred5, y[5])\n",
    "      val_loss6 = loss_fn(val_pred6, y[6])\n",
    "      val_loss7 = loss_fn(val_pred7, y[7])\n",
    "      val_loss8 = loss_fn(val_pred8, y[8])\n",
    "      val_loss9 = loss_fn(val_pred9, y[9])\n",
    "      val_loss10 = loss_fn(val_pred10, y[10])\n",
    "\n",
    "      val_loss += val_loss0 + val_loss1 + val_loss2 + val_loss3 + val_loss4 + val_loss5 + val_loss6 + val_loss7 + val_loss8 + val_loss9 + val_loss10\n",
    "\n",
    "      val_pred0 = val_pred0.argmax(dim=-1, keepdim=True)\n",
    "      val_pred1 = val_pred1.argmax(dim=-1, keepdim=True)\n",
    "      val_pred2 = val_pred2.argmax(dim=-1, keepdim=True)\n",
    "      val_pred3 = val_pred3.argmax(dim=-1, keepdim=True)\n",
    "      val_pred4 = val_pred4.argmax(dim=-1, keepdim=True)\n",
    "      val_pred5 = val_pred5.argmax(dim=-1, keepdim=True)\n",
    "      val_pred6 = val_pred6.argmax(dim=-1, keepdim=True)\n",
    "      val_pred7 = val_pred7.argmax(dim=-1, keepdim=True)\n",
    "      val_pred8 = val_pred8.argmax(dim=-1, keepdim=True)\n",
    "      val_pred9 = val_pred9.argmax(dim=-1, keepdim=True)\n",
    "      val_pred10 = val_pred10.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "      char_correct += val_pred0.eq(y[0].view_as(val_pred0)).sum().item()\n",
    "      char_correct += val_pred1.eq(y[1].view_as(val_pred1)).sum().item()\n",
    "      char_correct += val_pred2.eq(y[2].view_as(val_pred2)).sum().item()\n",
    "      char_correct += val_pred3.eq(y[3].view_as(val_pred3)).sum().item()\n",
    "      char_correct += val_pred4.eq(y[4].view_as(val_pred4)).sum().item()\n",
    "      char_correct += val_pred5.eq(y[5].view_as(val_pred5)).sum().item()\n",
    "      char_correct += val_pred6.eq(y[6].view_as(val_pred6)).sum().item()\n",
    "      char_correct += val_pred7.eq(y[7].view_as(val_pred7)).sum().item()\n",
    "      char_correct += val_pred8.eq(y[8].view_as(val_pred8)).sum().item()\n",
    "      char_correct += val_pred9.eq(y[9].view_as(val_pred9)).sum().item()\n",
    "      char_correct += val_pred10.eq(y[10].view_as(val_pred10)).sum().item()\n",
    "\n",
    "      tensors = [val_pred0.eq(y[0].view_as(val_pred0)),\n",
    "                 val_pred1.eq(y[1].view_as(val_pred1)),\n",
    "                 val_pred2.eq(y[2].view_as(val_pred2)),\n",
    "                 val_pred3.eq(y[3].view_as(val_pred3)),\n",
    "                 val_pred4.eq(y[4].view_as(val_pred4)),\n",
    "                 val_pred5.eq(y[5].view_as(val_pred5)),\n",
    "                 val_pred6.eq(y[6].view_as(val_pred6)),\n",
    "                 val_pred7.eq(y[7].view_as(val_pred7)),\n",
    "                 val_pred8.eq(y[8].view_as(val_pred8)),\n",
    "                 val_pred9.eq(y[9].view_as(val_pred9)),\n",
    "                 val_pred10.eq(y[10].view_as(val_pred10))]\n",
    "\n",
    "      combined_tensor = torch.stack(tensors)\n",
    "      result = torch.all(combined_tensor, dim=0)\n",
    "      plate_correct = result.sum().item()\n",
    "\n",
    "  val_loss /= len(valdata.dataset)\n",
    "  print('\\n***Validation Result***\\nAverage loss: {:.6f}, Plate Accuracy: {}/{} ({:.1f}%), Character Accuracy: {}/{} ({:.1f}%)\\n'.format(val_loss,\n",
    "                                                                                                                                         plate_correct,\n",
    "                                                                                                                                         len(valdata.dataset),\n",
    "                                                                                                                                         100*plate_correct/len(valdata.dataset),\n",
    "                                                                                                                                         char_correct,\n",
    "                                                                                                                                         len(valdata.dataset)*11,\n",
    "                                                                                                                                         100*char_correct/(len(valdata.dataset)*11)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1]\n",
      "loss: 39.731819 [0/4000]\n",
      "loss: 39.525642 [160/4000]\n",
      "loss: 38.915668 [320/4000]\n",
      "loss: 38.065174 [480/4000]\n",
      "loss: 37.006145 [640/4000]\n",
      "loss: 36.784370 [800/4000]\n",
      "loss: 36.620777 [960/4000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m      4\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m[Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m   \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m   validation(model, val_loader)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mDone!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[20], line 29\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(dataloader, model, loss_fn, optimizer)\u001B[0m\n\u001B[0;32m     27\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     28\u001B[0m loss\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 29\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\AIGS538_Carplate_letter_sequence_geneneration\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "## Training Operation ##\n",
    "start = time.time()\n",
    "for t in range(epochs):\n",
    "  print(f\"\\n[Epoch {t+1}]\")\n",
    "  train(train_loader, model, loss_fn, optimizer)\n",
    "  validation(model, val_loader)\n",
    "print(\"\\nDone!\")\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training time: {:.4f}\".format(end-start))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
